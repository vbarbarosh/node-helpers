{
    "demos": [
        {
            "id": "demos-stream-xml-parse-index-js",
            "file": "demos/stream-xml-parse/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst format_bytes = require('@vbarbarosh/node-helpers/src/format_bytes');\nconst fs = require('fs');\nconst fs_size = require('@vbarbarosh/node-helpers/src/fs_size');\nconst stream = require('stream');\nconst stream_map = require('@vbarbarosh/node-helpers/src/stream_map');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\nconst stream_xml_parse = require('@vbarbarosh/node-helpers/src/stream_xml_parse');\n\ncli(main);\n\nasync function main()\n{\n    const input_file = '/tmp/psd7003.xml';\n    await stream.promises.pipeline(\n        fs.createReadStream(input_file),\n        stream_progress({total: await fs_size(input_file), user_friendly_status}),\n        stream_xml_parse(['ProteinDatabase', 'ProteinEntry']),\n        stream_map(v => `${JSON.stringify(v)}\\n`),\n        fs.createWriteStream('out.ndjson')\n    );\n}\n\nfunction user_friendly_status(s)\n{\n    console.log(s, `mem=${format_bytes(process.memoryUsage().heapUsed)}`);\n}\n"
        },
        {
            "id": "demos-stream-xml-parse-README-md",
            "file": "demos/stream-xml-parse/README.md",
            "contents": "```\ncd /tmp\nwget https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-logging1.xml.gz\nwget https://aiweb.cs.washington.edu/research/projects/xmltk/xmldata/data/pir/psd7003.xml.gz\ngunzip *.gz\n```\n"
        },
        {
            "id": "demos-stream-xml-analyze-url-index-js",
            "file": "demos/stream-xml-analyze-url/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst format_bytes = require('@vbarbarosh/node-helpers/src/format_bytes');\nconst http_get_stream = require('@vbarbarosh/node-helpers/src/http_get_stream');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\nconst stream = require('stream');\nconst stream_gunzip = require('@vbarbarosh/node-helpers/src/stream_gunzip');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\nconst stream_xml_analyze = require('@vbarbarosh/node-helpers/src/stream_xml_analyze');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    // const input_url = 'https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-logging1.xml.gz';\n    const input_url = 'https://aiweb.cs.washington.edu/research/projects/xmltk/xmldata/data/pir/psd7003.xml.gz';\n    await user_friendly_status(`🌎 Connecting to ${input_url}`);\n    const rs = await http_get_stream(input_url);\n    const [out] = await stream.compose(\n        rs,\n        stream_progress({total: rs.total, user_friendly_status}),\n        stream_gunzip(),\n        stream_xml_analyze()\n    ).toArray();\n\n    console.log(out);\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n\nfunction user_friendly_status(s)\n{\n    console.log(s, `mem=${format_bytes(process.memoryUsage().heapUsed)}`);\n}\n"
        },
        {
            "id": "demos-stream-xml-analyze-file-index-js",
            "file": "demos/stream-xml-analyze-file/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst format_bytes = require('@vbarbarosh/node-helpers/src/format_bytes');\nconst fs = require('fs');\nconst fs_size = require('@vbarbarosh/node-helpers/src/fs_size');\nconst stream = require('stream');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\nconst stream_xml_analyze = require('@vbarbarosh/node-helpers/src/stream_xml_analyze');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    // const input_url = '/tmp/enwiki-latest-pages-logging1.xml';\n    const input_file = '/tmp/psd7003.xml';\n\n    const [out] = await stream.compose(\n        fs.createReadStream(input_file),\n        stream_progress({total: await fs_size(input_file), user_friendly_status}),\n        stream_xml_analyze()\n    ).toArray();\n\n    console.log(out);\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n\nfunction user_friendly_status(s)\n{\n    console.log(s, `mem=${format_bytes(process.memoryUsage().heapUsed)}`);\n}\n"
        },
        {
            "id": "demos-stream-promises-finished-index-js",
            "file": "demos/stream-promises-finished/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst stream = require('stream');\nconst stream_each = require('@vbarbarosh/node-helpers/src/stream_each');\n\ncli(main);\n\nasync function main()\n{\n    const rs = stream.Readable.from([1,2,3,4,5]);\n    await stream.promises.finished(rs.pipe(stream_each(v => console.log(v))));\n    console.log('🎉 Done');\n}\n"
        },
        {
            "id": "demos-stream-progress-index-js",
            "file": "demos/stream-progress/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst stream = require('stream');\nconst stream_discard = require('@vbarbarosh/node-helpers/src/stream_discard');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\n\ncli(main);\n\nasync function main()\n{\n    const total = 1E7;\n    const rs = stream.Readable.from(gen(total));\n    await stream.promises.pipeline(\n        rs,\n        stream_progress({total, interval: 100}),\n        stream_discard()\n    );\n    console.log('🎉 Done');\n}\n\nasync function* gen(total)\n{\n    for (let i = 0; i < total; ++i) {\n        yield Buffer.from([i]);\n        if (i % 1E3 === 0) {\n            await Promise.delay(0);\n        }\n    }\n}\n"
        },
        {
            "id": "demos-stream-parse-csv-index-js",
            "file": "demos/stream-parse-csv/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst http_get_buffer = require('@vbarbarosh/node-helpers/src/http_get_buffer');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\nconst stream = require('stream');\nconst stream_parse_csv = require('@vbarbarosh/node-helpers/src/stream_parse_csv');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    const s = await http_get_buffer('https://www.bnm.md/en/export-official-exchange-rates?date=31.12.2024');\n\n    const rows = await stream.Readable.from(s).compose(stream_parse_csv({delimiter: ';', relax_column_count: true})).toArray();\n    if (rows.length === 1) {\n        throw new Error(rows[0][0]);\n    }\n\n    const out = {};\n    rows.forEach(function (cols) {\n        switch (cols.length) {\n        case 1:\n            break;\n        case 2:\n            out[cols[0]] = cols[1];\n            break;\n        case 5:\n            switch (cols[2]) {\n            case 'USD':\n            case 'EUR':\n                out[cols[2].toLowerCase()] = +cols[4].replace(',', '.');\n                break;\n            }\n            break;\n        default:\n            throw new Error(`Unrecognized number of columns: ${cols.length}`);\n        }\n    });\n    out.date = rows[0][1].replace(/^(\\d\\d).(\\d\\d).(\\d\\d\\d\\d)$/, '$3/$2/$1');\n    delete out.abbr;\n    delete out[''];\n    delete out['Data source:'];\n    delete out['Date:'];\n    delete out['Hour:'];\n\n    console.log(out);\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n"
        },
        {
            "id": "demos-stream-map-parallel-index-js",
            "file": "demos/stream-map-parallel/index.js",
            "contents": "const Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst random_int = require('@vbarbarosh/node-helpers/src/random_int');\nconst stream = require('stream');\nconst stream_chunk = require('@vbarbarosh/node-helpers/src/stream_chunk');\nconst stream_each = require('@vbarbarosh/node-helpers/src/stream_each');\nconst stream_map_parallel = require('@vbarbarosh/node-helpers/src/stream_map_parallel');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\n\ncli(main);\n\nasync function main()\n{\n    const input = Array(100).fill().map((v,i) => i);\n    await stream.promises.pipeline(\n        stream.Readable.from(input),\n        stream_map_parallel({\n            concurrency: 10,\n            handler: async function (item) {\n                await Promise.delay(random_int(100, 5000));\n                return item;\n            },\n        }),\n        stream_progress({\n            objectMode: true,\n            total: input.length,\n            user_friendly_status,\n        }),\n        stream_chunk(10),\n        stream_each(function (items) {\n            console.log(items);\n        }),\n    );\n    console.log('🎉 Done');\n}\n\nfunction user_friendly_status(s)\n{\n    console.log(s);\n}\n"
        },
        {
            "id": "demos-stream-map-flatten-index-js",
            "file": "demos/stream-map-flatten/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst stream = require('stream');\nconst stream_each = require('@vbarbarosh/node-helpers/src/stream_each');\nconst stream_map_flatten = require('@vbarbarosh/node-helpers/src/stream_map_flatten');\n\ncli(main);\n\nasync function main()\n{\n    await stream.promises.pipeline(\n        stream.Readable.from([1, 2, 3, 4, 5]),\n        // Fancy stream_filter\n        stream_map_flatten(function (item) {\n            if (item % 2 === 0) {\n                return [item];\n            }\n            return [];\n        }),\n        stream_each(function (items) {\n            console.log(items);\n        }),\n    );\n    console.log('🎉 Done');\n}\n"
        },
        {
            "id": "demos-stream-download-with-progress-and-md5-index-js",
            "file": "demos/stream-download-with-progress-and-md5/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fs = require('fs');\nconst http_get_stream = require('@vbarbarosh/node-helpers/src/http_get_stream');\nconst stream = require('stream');\nconst stream_hash = require('@vbarbarosh/node-helpers/src/stream_hash');\nconst stream_md5 = require('@vbarbarosh/node-helpers/src/stream_md5');\nconst stream_multiplex = require('@vbarbarosh/node-helpers/src/stream_multiplex');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\n\ncli(main);\n\nasync function main()\n{\n    // const url = 'https://software.download.prss.microsoft.com/dbazure/Win10_22H2_English_x64v1.iso?t=4bc6bf41-d6d8-4439-abd6-a6abae233f12&e=1707058894&h=6b7b041774d41dd6b7836069728776592b1347b39aabc0f7a00c361d59769cc3';\n    const url = 'https://releases.ubuntu.com/22.04.4/ubuntu-22.04.4-desktop-amd64.iso';\n\n    const rs = await http_get_stream(url);\n    await stream.promises.pipeline(\n        rs,\n        stream_progress({\n            total: rs.total,\n            user_friendly_status: s => console.log(`Downloading: ${s}`),\n        }),\n        stream_multiplex(\n            fs.createWriteStream('ubuntu-22.04.4-desktop-amd64.iso'),\n            stream.compose(stream_md5(), fs.createWriteStream('ubuntu-22.04.4-desktop-amd64.iso.md5')),\n            stream.compose(stream_hash('sha256'), fs.createWriteStream('ubuntu-22.04.4-desktop-amd64.iso.sha256')),\n            stream.compose(stream_hash('sha512'), fs.createWriteStream('ubuntu-22.04.4-desktop-amd64.iso.sha512'))\n        )\n    );\n\n    console.log('done');\n}\n"
        },
        {
            "id": "demos-stream-download-with-progress-index-js",
            "file": "demos/stream-download-with-progress/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst http_get_stream = require('@vbarbarosh/node-helpers/src/http_get_stream');\nconst stream = require('stream');\nconst stream_discard = require('@vbarbarosh/node-helpers/src/stream_discard');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\n\ncli(main);\n\nasync function main()\n{\n    // const url = 'https://software.download.prss.microsoft.com/dbazure/Win10_22H2_English_x64v1.iso?t=4bc6bf41-d6d8-4439-abd6-a6abae233f12&e=1707058894&h=6b7b041774d41dd6b7836069728776592b1347b39aabc0f7a00c361d59769cc3';\n    const url = 'https://releases.ubuntu.com/22.04.4/ubuntu-22.04.4-desktop-amd64.iso';\n\n    const rs = await http_get_stream(url);\n    await stream.promises.pipeline(\n        rs,\n        stream_progress({\n            total: rs.total,\n            user_friendly_status: s => console.log(`Downloading: ${s}`),\n        }),\n        stream_discard()\n    );\n\n    console.log('done');\n}\n"
        },
        {
            "id": "demos-stream-copy-file-with-progress-abort-timeout-index-js",
            "file": "demos/stream-copy-file-with-progress-abort-timeout/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fs_read_stream = require('@vbarbarosh/node-helpers/src/fs_read_stream');\nconst fs_size = require('@vbarbarosh/node-helpers/src/fs_size');\nconst fs_write_stream = require('@vbarbarosh/node-helpers/src/fs_write_stream');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\nconst stream = require('stream');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    const file = '/tmp/ubuntu-24.04.1-desktop-amd64.iso';\n    await stream.promises.pipeline(\n        fs_read_stream(file),\n        stream_progress({\n            total: await fs_size(file),\n            user_friendly_status: s => console.log(`Copying: ${s}`),\n        }),\n        fs_write_stream('a.iso'),\n        {signal: AbortSignal.timeout(1000)},\n    );\n\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n"
        },
        {
            "id": "demos-stream-copy-file-with-progress-abort-index-js",
            "file": "demos/stream-copy-file-with-progress-abort/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fs_read_stream = require('@vbarbarosh/node-helpers/src/fs_read_stream');\nconst fs_size = require('@vbarbarosh/node-helpers/src/fs_size');\nconst fs_write_stream = require('@vbarbarosh/node-helpers/src/fs_write_stream');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\nconst stream = require('stream');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    const ac = new AbortController();\n    setTimeout(() => ac.abort(), 1000);\n\n    const file = '/tmp/ubuntu-24.04.1-desktop-amd64.iso';\n    await stream.promises.pipeline(\n        fs_read_stream(file),\n        stream_progress({\n            total: await fs_size(file),\n            user_friendly_status: s => console.log(`Copying: ${s}`),\n        }),\n        fs_write_stream('a.iso'),\n        {signal: ac.signal},\n    );\n\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n"
        },
        {
            "id": "demos-stream-copy-file-with-progress-index-js",
            "file": "demos/stream-copy-file-with-progress/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fs_read_stream = require('@vbarbarosh/node-helpers/src/fs_read_stream');\nconst fs_size = require('@vbarbarosh/node-helpers/src/fs_size');\nconst fs_write_stream = require('@vbarbarosh/node-helpers/src/fs_write_stream');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\nconst stream = require('stream');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    const file = '/tmp/ubuntu-24.04.1-desktop-amd64.iso';\n    await stream.promises.pipeline(\n        fs_read_stream(file),\n        stream_progress({\n            total: await fs_size(file),\n            user_friendly_status: s => console.log(`Copying: ${s}`),\n        }),\n        fs_write_stream('a.iso'),\n    );\n\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n"
        },
        {
            "id": "demos-stream-chunk-index-js",
            "file": "demos/stream-chunk/index.js",
            "contents": "const cli = require('@vbarbarosh/node-helpers/src/cli');\nconst stream = require('stream');\nconst stream_chunk = require('@vbarbarosh/node-helpers/src/stream_chunk');\nconst stream_each = require('@vbarbarosh/node-helpers/src/stream_each');\nconst stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');\n\ncli(main);\n\nasync function main()\n{\n    const items = [\n        {id: 1},\n        {id: 2},\n        {id: 3},\n        {id: 4},\n        {id: 5},\n        {id: 6},\n        {id: 7},\n        {id: 8},\n        {id: 9},\n        {id: 10},\n    ];\n    await stream.promises.pipeline(\n        stream.Readable.from(items),\n        stream_progress({\n            objectMode: true,\n            total: items.length,\n            user_friendly_status: v => console.log(`[status] ${v}`),\n        }),\n        stream_chunk(3),\n        stream_each(function (item) {\n            console.log('[stream_each]', item);\n        }),\n    );\n    console.log('🎉 Done');\n}\n"
        },
        {
            "id": "demos-str-parse-kv-index-js",
            "file": "demos/str-parse-kv/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fs_read_utf8 = require('@vbarbarosh/node-helpers/src/fs_read_utf8');\nconst str_parse_kv = require('@vbarbarosh/node-helpers/src/str_parse_kv');\n\ncli(main);\n\nasync function main()\n{\n    const utf8 = await fs_read_utf8('/proc/self/status');\n    const kv = Object.fromEntries(utf8.split('\\n').map(str_parse_kv));\n    console.log(kv);\n}\n"
        },
        {
            "id": "demos-shell-ytdlp-progress-index-js",
            "file": "demos/shell-ytdlp-progress/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst shell_thru = require('@vbarbarosh/node-helpers/src/shell_thru');\nconst shell_ytdlp_progress = require('@vbarbarosh/node-helpers/src/shell_ytdlp_progress');\n\ncli(main);\n\nasync function main()\n{\n    const url = 'https://www.youtube.com/watch?v=jvUpiexGOaw';\n    // await shell_thru(['yt-dlp', url]).promise();\n    await shell_ytdlp_progress(['--limit-rate=100K', url], {\n        user_friendly_status: v => console.log(`Downloading: ${v}`),\n    });\n    user_friendly_status('🎉 Done');\n}\n\nfunction user_friendly_status(s)\n{\n    console.log(s);\n}\n"
        },
        {
            "id": "demos-shell-spawn-trycatch2-index-js",
            "file": "demos/shell-spawn-trycatch2/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst shell_spawn = require('@vbarbarosh/node-helpers/src/shell_spawn');\nconst stream_strpbrk = require('@vbarbarosh/node-helpers/src/stream_strpbrk');\n\ncli(main);\n\nasync function main()\n{\n    try {\n        const proc = await shell_spawn(['xfail']).init();\n        for await (const line of proc.stdout.pipe(stream_strpbrk('\\r\\n'))) {\n            console.log(line);\n        }\n        await proc.promise();\n        console.log('done');\n    }\n    catch (error) {\n        console.log('failed', error);\n    }\n}\n"
        },
        {
            "id": "demos-shell-spawn-trycatch-index-js",
            "file": "demos/shell-spawn-trycatch/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst shell_spawn = require('@vbarbarosh/node-helpers/src/shell_spawn');\n\ncli(main);\n\nasync function main()\n{\n    try {\n        await shell_spawn(['xfail']).promise();\n        console.log('done');\n    }\n    catch (error) {\n        console.log('failed', error);\n    }\n}\n"
        },
        {
            "id": "demos-shell-spawn-detached-proc2-js",
            "file": "demos/shell-spawn-detached/proc2.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst format_date = require('@vbarbarosh/node-helpers/src/format_date');\nconst fs_append = require('@vbarbarosh/node-helpers/src/fs_append');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    for (let i = 0; i < 10; ++i) {\n        await fs_append('logs.txt', `[${format_date(new Date())}] ${i}\\n`);\n        await Promise.delay(1000);\n    }\n\n    await fs_append('logs.txt', `[${format_date(new Date())}] 🎉 Done in ${perf_end_human(time0)}\\n`);\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n"
        },
        {
            "id": "demos-shell-spawn-detached-index-js",
            "file": "demos/shell-spawn-detached/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\nconst shell_spawn = require('@vbarbarosh/node-helpers/src/shell_spawn');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    const proc = shell_spawn(['node', 'proc2.js'], {cwd: __dirname, stdio: 'ignore', detached: true});\n    proc.unref();\n\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n"
        },
        {
            "id": "demos-shell-spawn-7z-extract-with-progress-index-js",
            "file": "demos/shell-spawn-7z-extract-with-progress/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst shell_spawn = require('@vbarbarosh/node-helpers/src/shell_spawn');\nconst stream_strpbrk = require('@vbarbarosh/node-helpers/src/stream_strpbrk');\n\ncli(main);\n\nasync function main()\n{\n    const proc = await shell_spawn(['7z', 'x', '-aoa', '-bsp1', '/path/to/file.zip']).init();\n    const lines = [];\n    try {\n        for await (const line of proc.stdout.pipe(stream_strpbrk('\\r\\n\\x08'))) {\n            lines.push(line);\n            const m = line.match(/^\\s*(\\d+%.*)\\s*$/);\n            if (m) {\n                console.log(`Extracting: ${m[1]}`);\n            }\n        }\n        await proc.promise();\n        console.log('done');\n    }\n    catch (error) {\n        console.log('FAILED');\n        console.log(`${error.message}\\n\\n${lines.join('\\n')}`);\n    }\n}\n"
        },
        {
            "id": "demos-shell-spawn-index-js",
            "file": "demos/shell-spawn/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst shell_spawn = require('@vbarbarosh/node-helpers/src/shell_spawn');\n\ncli(main);\n\nasync function main()\n{\n    // https://test-videos.co.uk/sintel/mp4-h264\n    await shell_spawn(['wget', '-O', 'a.mp4', 'https://test-videos.co.uk/vids/sintel/mp4/h264/360/Sintel_360_10s_10MB.mp4'], {stdio: 'inherit'}).promise();\n    await shell_spawn(['ffmpeg', '-i', 'a.mp4', '-filter:v', 'setpts=0.2*PTS', '-y', 'b.mp4'], {stdio: 'inherit'}).promise();\n    console.log('done');\n}\n"
        },
        {
            "id": "demos-shell-curl-progress-put-js",
            "file": "demos/shell-curl-progress/put.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst shell_curl_progress = require('@vbarbarosh/node-helpers/src/shell_curl_progress');\n\ncli(main);\n\nasync function main()\n{\n    // docker run --rm -p 3000:3000 vbarbarosh/dev-proxy\n    const url = 'http://127.0.0.1:3000/null';\n\n    await shell_curl_progress(['curl', '-sfS', url, '-T', 'a.iso'], {\n        user_friendly_status: s => user_friendly_status(`Uploading: ${s}`),\n    });\n\n    user_friendly_status('🎉 Done');\n}\n\nfunction user_friendly_status(s)\n{\n    console.log(s);\n}\n"
        },
        {
            "id": "demos-shell-curl-progress-get-js",
            "file": "demos/shell-curl-progress/get.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst shell_curl_progress = require('@vbarbarosh/node-helpers/src/shell_curl_progress');\n\ncli(main);\n\nasync function main()\n{\n    const url = 'https://mirror.mangohost.net/ubuntu-releases/24.04.1/ubuntu-24.04.1-desktop-amd64.iso';\n\n    await shell_curl_progress(['curl', '-sfS', url, '-o', 'a.iso'], {\n        user_friendly_status: s => user_friendly_status(`Downloading: ${s}`),\n    });\n\n    user_friendly_status('🎉 Done');\n}\n\nfunction user_friendly_status(s)\n{\n    console.log(s);\n}\n"
        },
        {
            "id": "demos-shell-index-js",
            "file": "demos/shell/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst shell = require('@vbarbarosh/node-helpers/src/shell');\n\ncli(main);\n\nasync function main()\n{\n    console.log('node version:', await shell(['node', '--version']));\n    console.log('curl', await shell(['curl', '-sf', '-I', 'https://example.com']));\n    console.log('tree', await shell(['tree']));\n    console.log('false', await shell(['false']));\n}\n"
        },
        {
            "id": "demos-perf-measure-human-index-js",
            "file": "demos/perf-measure-human/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst perf_measure_human = require('@vbarbarosh/node-helpers/src/perf_measure_human');\n\ncli(main);\n\nasync function main()\n{\n    console.log(`🎉 Finished in ${await perf_measure_human(() => Promise.delay(100))}`);\n}\n"
        },
        {
            "id": "demos-perf-end-ms-index-js",
            "file": "demos/perf-end-ms/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst perf_end_ms = require('@vbarbarosh/node-helpers/src/perf_end_ms');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    await Promise.delay(100);\n\n    console.log(`🎉 Finished in ${perf_end_ms(time0)}ms`);\n}\n"
        },
        {
            "id": "demos-perf-end-human-index-js",
            "file": "demos/perf-end-human/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    await Promise.delay(100);\n\n    console.log(`🎉 Finished in ${perf_end_human(time0)}`);\n}\n"
        },
        {
            "id": "demos-make-progress-index-js",
            "file": "demos/make-progress/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst format_percents = require('@vbarbarosh/node-helpers/src/format_percents');\nconst make_progress = require('@vbarbarosh/node-helpers/src/make_progress');\n\ncli(main);\n\nasync function main()\n{\n    const p = make_progress(1000);\n    for (let i = 0; i < 1000; ++i) {\n        await Promise.delay(Math.random()*25);\n        p.add(1);\n        console.log(`${p.done} of ${p.total} ${format_percents(p.percents)} at ${p.rate.toFixed(2)}/s ETA ${p.eta.toFixed(2)}s duration=${p.duration.toFixed(2)}s`);\n    }\n}\n"
        },
        {
            "id": "demos-linux-process-tree2-index-js",
            "file": "demos/linux-process-tree2/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fs_read_utf8 = require('@vbarbarosh/node-helpers/src/fs_read_utf8');\nconst fs_readdir = require('@vbarbarosh/node-helpers/src/fs_readdir');\nconst str_parse_kv = require('@vbarbarosh/node-helpers/src/str_parse_kv');\nconst tree_from_array = require('@vbarbarosh/tree/src/tree_from_array');\nconst tree_print = require('@vbarbarosh/tree/src/tree_print');\n\ncli(main);\n\nasync function main()\n{\n    const nodes = [];\n    await Promise.map(fs_readdir('/proc'), async function (pid) {\n        if (!pid.match(/^[0-9]+$/)) {\n            return;\n        }\n        // https://docs.kernel.org/filesystems/proc.html#id10\n        // https://docs.kernel.org/filesystems/proc.html#id12\n        const utf8 = await fs_read_utf8(`/proc/${pid}/status`);\n        const status = Object.fromEntries(utf8.split('\\n').map(str_parse_kv));\n        nodes.push({id: status.Pid, parent_id: status.PPid, title: `[${status.Pid}, ${status.State}] ${status.Name}`});\n    });\n    console.log(tree_print(tree_from_array(nodes)));\n}\n"
        },
        {
            "id": "demos-linux-process-tree-index-js",
            "file": "demos/linux-process-tree/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fs_read_utf8 = require('@vbarbarosh/node-helpers/src/fs_read_utf8');\nconst shell = require('@vbarbarosh/node-helpers/src/shell');\nconst tree_from_array = require('@vbarbarosh/tree/src/tree_from_array');\nconst tree_print = require('@vbarbarosh/tree/src/tree_print');\n\ncli(main);\n\nasync function main()\n{\n    const pstree = await shell(['ps', '-eo', 'pid,ppid']);\n    const nodes = pstree.split('\\n').slice(1, -1).map(function (line) {\n        const [id, parent_id] = line.trim().split(/\\s+/).map(v => +v);\n        return {id, parent_id};\n    });\n    await Promise.map(nodes, async function (node) {\n        try {\n            const comm = await fs_read_utf8(`/proc/${node.id}/comm`)\n            node.title = `[${node.id}] ${comm.trim()}`;\n        }\n        catch {\n            node.title = `[${node.id}] ?`;\n        }\n    });\n    console.log(tree_print(tree_from_array(nodes)));\n}\n"
        },
        {
            "id": "demos-http-server-echo-index-js",
            "file": "demos/http-server-echo/index.js",
            "contents": "#!/usr/bin/env node\n\n// https://stackoverflow.com/a/46787467\n\nconst Throttle = require('throttle');\nconst http = require('http');\n\nconst server = http.createServer(function (req, res) {\n    console.log(req.method, req.url, req.headers);\n    console.log();\n\n    const url = new URL(`http://localhost:3000${req.url}`);\n    if (url.pathname == '/redirect' && url.searchParams.has('url')) {\n        res.statusCode = 302;\n        res.setHeader('Location', url.searchParams.get('url'));\n        res.end();\n        return;\n    }\n\n    res.statusCode = 200;\n    req.headers['content-type'] && res.setHeader('Content-Type', req.headers['content-type']);\n    req.headers['content-length'] && res.setHeader('Content-Length', req.headers['content-length']);\n\n    // noinspection JSCheckFunctionSignatures\n    req.pipe(new Throttle(5*1024*1024)).pipe(res);\n});\n\nserver.listen(3000, function () {\n    const {address, port} = this.address();\n    console.log(`Server running at ${address}:${port}`);\n    console.log();\n});\n"
        },
        {
            "id": "demos-http-put-file-progress-index-js",
            "file": "demos/http-put-file-progress/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst crypto_hash_md5 = require('@vbarbarosh/node-helpers/src/crypto_hash_md5');\nconst crypto_hash_sha256 = require('@vbarbarosh/node-helpers/src/crypto_hash_sha256');\nconst format_thousands = require('@vbarbarosh/node-helpers/src/format_thousands');\nconst http_put_file = require('@vbarbarosh/node-helpers/src/http_put_file');\n\ncli(main);\n\nasync function main()\n{\n    const tmp = await http_put_file('http://127.0.0.1:3000', '/lipsum/random.100M', {\n        progress_upload: function (delta, ready, total) {\n            if (total) {\n                console.log(new Date(), `progress_upload ${format_thousands(ready)} of ${format_thousands(total)} [+${format_thousands(delta)}] ${(ready/total*100).toFixed(2)}%`);\n            }\n            else {\n                console.log(new Date(), `progress_upload ${format_thousands(ready)} of n/a [+${format_thousands(delta)}]`);\n            }\n        },\n        progress_download: function (delta, ready, total) {\n            if (total) {\n                console.log(new Date(), `progress_download ${format_thousands(ready)} of ${format_thousands(total)} [+${format_thousands(delta)}] ${(ready/total*100).toFixed(2)}%`);\n            }\n            else {\n                console.log(new Date(), `progress_download ${format_thousands(ready)} of n/a [+${format_thousands(delta)}]`);\n            }\n        },\n    });\n    console.log(crypto_hash_md5(tmp.data).toString('hex'));\n    console.log(crypto_hash_sha256(tmp.data).toString('hex'));\n}\n"
        },
        {
            "id": "demos-fs-walk-index-js",
            "file": "demos/fs-walk/index.js",
            "contents": "#!/usr/bin/env node\n\nconst array_sum = require('@vbarbarosh/node-helpers/src/array_sum');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fcmpx = require('@vbarbarosh/node-helpers/src/fcmpx');\nconst format_bytes = require('@vbarbarosh/node-helpers/src/format_bytes');\nconst format_progress_kilo = require('@vbarbarosh/node-helpers/src/format_progress_kilo');\nconst format_thousands = require('@vbarbarosh/node-helpers/src/format_thousands');\nconst fs_lstat = require('@vbarbarosh/node-helpers/src/fs_lstat');\nconst fs_path_join = require('@vbarbarosh/node-helpers/src/fs_path_join');\nconst fs_readdir = require('@vbarbarosh/node-helpers/src/fs_readdir');\nconst make_progress = require('@vbarbarosh/node-helpers/src/make_progress');\n\ncli(main);\n\nasync function main()\n{\n    let delta = 0;\n    let last_progress = 0;\n\n    const p = make_progress();\n    const pending = ['/usr/share'];\n    const items = [];\n    const errors = [];\n    while (pending.length) {\n        try {\n            const path = pending.pop();\n            const lstat = await fs_lstat(path);\n            lstat.path = path;\n            items.push(lstat);\n            if (lstat.isDirectory()) {\n                if (path === '/dev' || path === '/proc') {\n                    continue;\n                }\n                const basenames = await fs_readdir(path);\n                basenames.forEach(v => pending.push(fs_path_join(path, v)));\n            }\n            delta++;\n            if (Date.now() - last_progress > 1000) {\n                p.add(delta);\n                delta = 0;\n                last_progress = Date.now();\n                console.log(format_progress_kilo(p), mem_info());\n            }\n        }\n        catch (error) {\n            console.log(`⚠️ ${error.message}`);\n            errors.push(error);\n        }\n    }\n\n    p.add(delta);\n    console.log(format_progress_kilo(p), mem_info());\n\n    // 14.83M of ~ at 49.58K/s duration=00:05:18 7.75GB\n    // 14.86M of ~ at 35.44K/s duration=00:05:22 7.83GB\n    // 14.89M of ~ at 34.12K/s duration=00:05:23 7.86GB\n    // 14.94M of ~ at 34.73K/s duration=00:05:24 7.85GB\n    // 14.94M of ~ at 34.74K/s duration=00:05:24\n    //\n    // Total errors: 2\n    // Total files: 12,569,653\n    // Total directories: 2,049,624\n    // Total bytes: 709.59GB\n\n    console.log();\n    console.log(`Total errors: ${format_thousands(errors.length)}`);\n    console.log(`Total files: ${format_thousands(items.filter(v => v.isFile()).length)}`);\n    console.log(`Total directories: ${format_thousands(items.filter(v => v.isDirectory()).length)}`);\n    console.log(`Total bytes: ${format_bytes(array_sum(items.map(v => v.size)))}`);\n    console.log();\n    console.log(items.sort(fcmpx('-size')).slice(0, 10).map(v => [format_bytes(v.size), v.path]));\n\n    console.log('🎉 Done');\n}\n\nfunction mem_info()\n{\n    const m = process.memoryUsage();\n    return format_bytes(m.rss);\n}"
        },
        {
            "id": "demos-fs-rmf-index-js",
            "file": "demos/fs-rmf/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fs_rmf = require('@vbarbarosh/node-helpers/src/fs_rmf');\n\ncli(main);\n\nasync function main()\n{\n    await fs_rmf('a');\n}\n"
        },
        {
            "id": "demos-fs-copy-recursively2-index-js",
            "file": "demos/fs-copy-recursively2/index.js",
            "contents": "#!/usr/bin/env node\n\nconst NotImplemented = require('@vbarbarosh/node-helpers/src/errors/NotImplemented');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fs = require('fs');\nconst fs_copy_excl = require('@vbarbarosh/node-helpers/src/fs_copy_excl');\nconst fs_lstat = require('@vbarbarosh/node-helpers/src/fs_lstat');\nconst fs_mkdir = require('@vbarbarosh/node-helpers/src/fs_mkdir');\nconst fs_path_join = require('@vbarbarosh/node-helpers/src/fs_path_join');\nconst fs_path_relative = require('@vbarbarosh/node-helpers/src/fs_path_relative');\nconst fs_readdir = require('@vbarbarosh/node-helpers/src/fs_readdir');\nconst fs_rmrf = require('@vbarbarosh/node-helpers/src/fs_rmrf');\nconst parallel = require('@vbarbarosh/node-helpers/src/parallel');\n\ncli(main);\n\nasync function main()\n{\n    await fs_rmrf('out', (v,p) => console.log(v, p));\n\n    const source_dir = '/usr/share';\n\n    console.log('Reading source dir...');\n    const items = await fs_lstat_walk(source_dir);\n\n    console.log('Copying...');\n    await parallel2({\n        concurrency: 1,\n        items,\n        fn: async function (lstat) {\n            const output_file = fs_path_join('out', fs_path_relative(source_dir, lstat.path));\n            if (lstat.isDirectory()) {\n                console.log('mkdir', output_file);\n                await fs_mkdir(output_file);\n            }\n            else if (lstat.isFile()) {\n                console.log('cp', lstat.path, '->', output_file);\n                await fs_copy_excl(lstat.path, output_file);\n            }\n            else if (lstat.isSymbolicLink()) {\n                const target = await fs.promises.readlink(lstat.path)\n                console.log('ln -s', output_file, '->', target);\n                await fs.promises.symlink(target, output_file);\n            }\n            else {\n                throw new NotImplemented();\n            }\n        },\n    })\n}\n\nasync function parallel2({items, concurrency, fn})\n{\n    let i = 0;\n    await parallel({\n        concurrency,\n        spawn: function () {\n            if (i >= items.length) {\n                return null;\n            }\n            return fn(items[i++]);\n        },\n    });\n}\n\nasync function fs_lstat_walk(path = '.')\n{\n    const out = [];\n    for (const queue = [path]; queue.length; ) {\n        const p = queue.pop();\n        const lstat = await fs_lstat(p);\n        lstat.path = p;\n        out.push(lstat);\n        if (lstat.isDirectory()) {\n            const names = await fs_readdir(p);\n            queue.push(...names.map(v => fs_path_join(p, v)));\n        }\n    }\n    out.sort((a,b) => a.path.localeCompare(b.path));\n    return out;\n}\n"
        },
        {
            "id": "demos-fs-copy-recursively-index-js",
            "file": "demos/fs-copy-recursively/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst countdown = require('@vbarbarosh/node-helpers/src/countdown');\nconst format_bytes = require('@vbarbarosh/node-helpers/src/format_bytes');\nconst format_progress_bytes = require('@vbarbarosh/node-helpers/src/format_progress_bytes');\nconst format_progress_kilo = require('@vbarbarosh/node-helpers/src/format_progress_kilo');\nconst format_thousands = require('@vbarbarosh/node-helpers/src/format_thousands');\nconst fs = require('fs');\nconst fs_lstat = require('@vbarbarosh/node-helpers/src/fs_lstat');\nconst fs_mkdir = require('@vbarbarosh/node-helpers/src/fs_mkdir');\nconst fs_path_join = require('@vbarbarosh/node-helpers/src/fs_path_join');\nconst fs_read_stream = require('@vbarbarosh/node-helpers/src/fs_read_stream');\nconst fs_readdir = require('@vbarbarosh/node-helpers/src/fs_readdir');\nconst fs_rmrf = require('@vbarbarosh/node-helpers/src/fs_rmrf');\nconst fs_write_stream = require('@vbarbarosh/node-helpers/src/fs_write_stream');\nconst make_progress = require('@vbarbarosh/node-helpers/src/make_progress');\nconst msval = require('@vbarbarosh/node-helpers/src/msval');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\nconst stream = require('stream');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n    const path = '/usr/share';\n\n    const ac = new AbortController();\n    setTimeout(() => ac.abort(), 1500);\n\n    const files = await fs_walk({\n        path: '/usr/share',\n        user_friendly_status: s => console.log(`Reading files: ${s}`),\n        signal: ac.signal,\n    });\n\n    console.log();\n    console.log('Total files:', format_thousands(files.length));\n    console.log('Total bytes:', format_bytes(files.reduce((a,v) => a + v.lstat.size, 0)));\n    console.log();\n\n    await fs_rmrf('/tmp/a');\n    await fs_copy_recursively({\n        files,\n        base: path,\n        dest: '/tmp/a',\n        user_friendly_status: s => console.log(`Copying files: ${s}`),\n        signal: ac.signal,\n    });\n\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n\nasync function fs_walk({path, user_friendly_status, signal})\n{\n    const base = path;\n    const out = [];\n    const p = make_progress();\n    const pending = [path];\n    let delta = 0;\n    let last_progress = 0;\n    while (pending.length) {\n        if (signal) {\n            signal.throwIfAborted();\n        }\n        const path = pending.pop();\n        const lstat = await fs_lstat(path);\n        out.push({base, path, lstat});\n        if (lstat.isDirectory()) {\n            const basenames = await fs_readdir(path);\n            basenames.forEach(v => pending.push(fs_path_join(path, v)));\n        }\n        delta++;\n        if (Date.now() - last_progress > 1000) {\n            p.add(delta);\n            delta = 0;\n            last_progress = Date.now();\n            user_friendly_status(format_progress_kilo(p));\n        }\n    }\n    p.add(delta);\n    user_friendly_status(format_progress_kilo(p));\n    return out;\n}\n\nasync function fs_copy_recursively({files, dest, user_friendly_status, signal})\n{\n    let delta = 0;\n    const p = make_progress(files.reduce((a,v) => a + v.lstat.size, 0));\n    await countdown({\n        signal,\n        timeout: msval(0, 5, 0, 0),\n        tick_ms: 100,\n        tick: function () {\n            p.add(delta);\n            delta = 0;\n            user_friendly_status(format_progress_bytes(p));\n        },\n        fn: async function () {\n            for (let i = 0; i < files.length; ++i) {\n                if (signal) {\n                    signal.throwIfAborted();\n                }\n                const file = files[i];\n                const path_base = file.path.slice(file.base.length + 1);\n                const path_in = file.path;\n                const path_out = fs_path_join(dest, path_base);\n                // file.lstat.isBlockDevice()\n                // file.lstat.isCharacterDevice()\n                // file.lstat.isDirectory()\n                // file.lstat.isFIFO()\n                // file.lstat.isFile()\n                // file.lstat.isSocket()\n                // file.lstat.isSymbolicLink()\n                if (file.lstat.isFile()) {\n                    await stream.promises.pipeline(\n                        fs_read_stream(path_in),\n                        stream_tap2(buf => delta += buf.length),\n                        fs_write_stream(path_out, {flags: 'wx'}),\n                        {signal},\n                    );\n                    continue;\n                }\n                if (file.lstat.isDirectory()) {\n                    await fs_mkdir(path_out);\n                    delta += file.lstat.size;\n                    continue;\n                }\n                if (file.lstat.isSymbolicLink()) {\n                    await fs.promises.symlink(await fs.promises.readlink(path_in), path_out);\n                    delta += file.lstat.size;\n                    continue;\n                }\n                throw new Error(`Invalid file type: ${path_in}`);\n            }\n        },\n    });\n    p.add(delta);\n    delta = 0;\n    user_friendly_status(format_progress_bytes(p));\n}\n\nfunction stream_tap2(fn)\n{\n    return new stream.Transform({\n        transform: async function (item, encoding, callback) {\n            try {\n                await fn(item);\n                this.push(item, encoding);\n                callback();\n            }\n            catch (error) {\n                callback(error);\n            }\n        },\n    });\n}\n"
        },
        {
            "id": "demos-format-hrtime-index-js",
            "file": "demos/format-hrtime/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst format_hrtime = require('@vbarbarosh/node-helpers/src/format_hrtime');\n\ncli(main);\n\nasync function main()\n{\n    const hrtime0 = process.hrtime();\n\n    await Promise.delay(100);\n\n    console.log(`Finished in ${format_hrtime(process.hrtime(hrtime0))}`);\n}\n"
        },
        {
            "id": "demos-fastdl-sftp-index-js",
            "file": "demos/fastdl-sftp/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fastdl = require('@vbarbarosh/node-helpers/src/fastdl');\nconst fs_path_basename = require('@vbarbarosh/node-helpers/src/fs_path_basename');\nconst sftp_get_stream_range = require('@vbarbarosh/node-helpers/src/sftp_get_stream_range');\n\ncli(main);\n\nasync function main()\n{\n    const url = 'sftp://username:password@domain.com/path/to/file/a.zip';\n    await fastdl({\n        file: fs_path_basename(new URL(url).pathname),\n        read_stream_with_range: (first, last) => sftp_get_stream_range(url, first, last),\n        concurrency: 200,\n        user_friendly_status: s => console.log(`[fastdl] ${s}`),\n    });\n    console.log('done');\n}\n"
        },
        {
            "id": "demos-fastdl-index-js",
            "file": "demos/fastdl/index.js",
            "contents": "#!/usr/bin/env node\n\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst fastdl = require('@vbarbarosh/node-helpers/src/fastdl');\nconst http_get_stream_range = require('@vbarbarosh/node-helpers/src/http_get_stream_range');\n\ncli(main);\n\nasync function main()\n{\n    // a435f6f393dda581172490eda9f683c32e495158a780b5a1de422ee77d98e909 *ubuntu-22.04.3-desktop-amd64.iso\n    // a6f470ca6d331eb353b815c043e327a347f594f37ff525f17764738fe812852e\n    // const url = 'https://software.download.prss.microsoft.com/dbazure/Win10_22H2_English_x64v1.iso?t=4bc6bf41-d6d8-4439-abd6-a6abae233f12&e=1707058894&h=6b7b041774d41dd6b7836069728776592b1347b39aabc0f7a00c361d59769cc3';\n\n    // docker run --rm -p 3000:3000 vbarbarosh/dev-proxy\n    const url = 'http://127.0.0.1:3000/proxy?url=https://releases.ubuntu.com/22.04.4/ubuntu-22.04.4-desktop-amd64.iso&throttle=256k';\n\n    await fastdl({\n        file: 'ubuntu-22.04.3-desktop-amd64.iso',\n        concurrency: 10,\n        read_stream_with_range: (first, last) => http_get_stream_range(url, first, last),\n        user_friendly_status: s => console.log(`[fastdl] ${s}`),\n    });\n    console.log('done');\n}\n"
        },
        {
            "id": "demos-custom-watchdog-index-js",
            "file": "demos/custom-watchdog/index.js",
            "contents": "const HeartbeatServer = require('@vbarbarosh/node-helpers/src/HeartbeatServer');\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst now_human = require('@vbarbarosh/node-helpers/src/now_human');\nconst pid_exists = require('@vbarbarosh/node-helpers/src/pid_exists');\nconst pid_kill_grace = require('@vbarbarosh/node-helpers/src/pid_kill_grace');\nconst shell_spawn = require('@vbarbarosh/node-helpers/src/shell_spawn');\n\n// Ctrl-C should gracefully terminate a child process and close heartbeat server\n// Test\n// - heartbeat server starts failed\n// - heartbeat server does not close connection\n// - heartbeat server sends 1G of data\n// - child spawn failed\n// - child receives no valid WATCHDOG_SOCKET\n// - child does not send heartbeat\n// - child spawns several children\n\ncli(main);\n\nasync function main()\n{\n    const args = process.argv.slice(2);\n\n    const heartbeat_server = new HeartbeatServer();\n    try {\n        console.log('socket_path', heartbeat_server.socket_path);\n        const env = {...process.env, WATCHDOG_SOCKET: heartbeat_server.socket_path};\n        const proc = await shell_spawn(args, {stdio: 'inherit', env}).init();\n        try {\n            heartbeat_server.on('heartbeat', () => console.log(`[${now_human()}] ❤️`))\n            await Promise.race([Promise.delay(10000), heartbeat_server.promise(), proc.promise()]);\n        }\n        finally {\n            if (pid_exists(proc.pid)) {\n                console.log('Terminating child process...');\n                await pid_kill_grace(proc.pid, {\n                    log: s => console.log(`[${now_human()}][pid_kill_grace] ${s}`),\n                });\n            }\n        }\n    }\n    finally {\n        console.log('Closing heartbeat server...');\n        await heartbeat_server.dispose();\n    }\n\n    console.log('🎉 Done');\n}\n"
        },
        {
            "id": "demos-custom-watchdog-errors-never-ping",
            "file": "demos/custom-watchdog/errors/never-ping",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst now_human = require('@vbarbarosh/node-helpers/src/now_human');\n\ncli(main);\n\nasync function main()\n{\n    for (let iter = 1, last = 100; iter <= last; ++iter) {\n        console.log(`[${now_human()}][never-ping] ${iter} of ${last}`);\n        await Promise.delay(1000);\n    }\n}\n"
        },
        {
            "id": "demos-custom-watchdog-errors-ignore-sigterm",
            "file": "demos/custom-watchdog/errors/ignore-sigterm",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst now_human = require('@vbarbarosh/node-helpers/src/now_human');\n\ncli(main);\n\nasync function main()\n{\n    process.on('SIGTERM', function () {\n        console.log(`[${now_human()}][ignore-sigterm] SIGTERM, ignoring...`);\n    });\n    process.on('SIGINT', function () {\n        console.log(`[${now_human()}][ignore-sigterm] SIGINT, ignoring...`);\n    });\n\n    for (let iter = 1, last = 100; iter <= last; ++iter) {\n        console.log(`[${now_human()}][ignore-sigterm] ${iter} of ${last}`);\n        await Promise.delay(1000);\n    }\n}\n"
        },
        {
            "id": "demos-custom-watchdog-clients-client-sh",
            "file": "demos/custom-watchdog/clients/client.sh",
            "contents": "#!/bin/bash\n\n# http://www.gnu.org/software/bash/manual/bash.html#The-Set-Builtin\n# http://redsymbol.net/articles/unofficial-bash-strict-mode\nset -o nounset -o errexit -o pipefail\n\nscript=`realpath $0`\nscriptdir=`dirname $script`\nscriptname=`basename $script`\n\nBLACK=\"\\e[30m\" RED=\"\\e[31m\" GREEN=\"\\e[32m\" YELLOW=\"\\e[33m\" BLUE=\"\\e[34m\"\nPURPLE=\"\\e[35m\" CYAN=\"\\e[36m\" WHITE=\"\\e[37m\" RESET=\"\\e[0m\"\n\nEXIT_MESSAGE=\"${RED}bin/templ failed${RESET}\"\n\n# http://redsymbol.net/articles/bash-exit-traps/\n# http://redsymbol.net/articles/unofficial-bash-strict-mode/#essential-cleanup\ntrap 'echo -e \"$EXIT_MESSAGE\"' EXIT\n\nwhile true; do\n    if test -S \"$WATCHDOG_SOCKET\"; then\n        # Send empty string and read response\n        RESPONSE=$(echo -ne 'ping' | nc -U \"$WATCHDOG_SOCKET\" 2> /dev/null)\n        if [[ \"$RESPONSE\" == \"OK\" ]]; then\n            echo \"[client.sh] $(date '+%F %T') - OK\"\n        else\n            echo \"[client.sh] $(date '+%F %T') - FAIL (no OK)\"\n        fi\n    else\n        echo \"[client.sh] $(date '+%F %T') - FAIL (socket missing)\"\n    fi\n    sleep 1\ndone\n\nEXIT_MESSAGE=\"${GREEN}child.sh succeeded${RESET}\"\n"
        },
        {
            "id": "demos-custom-watchdog-clients-client-php",
            "file": "demos/custom-watchdog/clients/client.php",
            "contents": "<?php\n\nmain();\n\nfunction main()\n{\n    for ($i = 0; $i < 100; ++$i) {\n        echo sprintf(\"[client.php] %s\\n\", json_encode(ping(getenv('WATCHDOG_SOCKET'))));\n        sleep(1);\n    }\n}\n\nfunction ping(string $socket_path, string $data = 'PING', int $timeout_ms = 1000): string\n{\n    $client = stream_socket_client(\"unix://$socket_path\", $error_code, $error_message, $timeout_ms/1000);\n    if (!$client) {\n        throw new RuntimeException(\"Connection failed: $error_code: $error_message\");\n    }\n    try {\n        stream_set_timeout($client, $timeout_ms/1000, ($timeout_ms % 1000)*1000);\n        if (fwrite($client, $data) === false) {\n            throw new RuntimeException('Failed to write to socket');\n        }\n        return stream_get_contents($client); // ⚠️ Blocking read\n    }\n    finally {\n        fclose($client);\n    }\n}\n"
        },
        {
            "id": "demos-custom-watchdog-clients-client-js",
            "file": "demos/custom-watchdog/clients/client.js",
            "contents": "const Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst ping_socket = require('@vbarbarosh/node-helpers/src/ping_socket');\n\ncli(main);\n\nasync function main()\n{\n    for (let i = 0; i < 100; ++i) {\n        console.log('[client]', i);\n        await ping_socket(process.env.WATCHDOG_SOCKET);\n        await Promise.delay(1000);\n    }\n}\n"
        },
        {
            "id": "demos-custom-heartbeat-server-index-js",
            "file": "demos/custom-heartbeat-server/index.js",
            "contents": "const HeartbeatServer = require('@vbarbarosh/node-helpers/src/HeartbeatServer');\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst now_atom = require('@vbarbarosh/node-helpers/src/now_atom');\nconst ping_socket = require('@vbarbarosh/node-helpers/src/ping_socket');\n\ncli(main);\n\nasync function main()\n{\n    const timer = setInterval(tick, 900);\n    const heartbeat_server = new HeartbeatServer();\n    try {\n        console.log('socket_path', heartbeat_server.socket_path);\n        heartbeat_server.on('heartbeat', () => console.log(`[${now_atom()}] heartbeat`))\n        await Promise.race([Promise.delay(10000), heartbeat_server.promise()]);\n    }\n    finally {\n        clearInterval(timer);\n        await heartbeat_server.dispose();\n    }\n    console.log('🎉 Done');\n\n    async function tick() {\n        const response = await ping_socket(heartbeat_server.socket_path);\n        console.log(response.toString());\n    }\n}\n"
        },
        {
            "id": "demos-countdown-fn-index-js",
            "file": "demos/countdown-fn/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst countdown = require('@vbarbarosh/node-helpers/src/countdown');\nconst format_ms = require('@vbarbarosh/node-helpers/src/format_ms');\nconst format_ms3 = require('@vbarbarosh/node-helpers/src/format_ms3');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    await countdown({\n        timeout: 5000,\n        tick_ms: 500,\n        tick: function (ctx) {\n            console.log(`[${format_ms3(ctx.time_elapsed)}][tick] remain=${format_ms(ctx.time_remained)}`);\n        },\n        fn: async function () {\n            await Promise.delay(3000);\n        },\n    });\n\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n"
        },
        {
            "id": "demos-countdown-index-js",
            "file": "demos/countdown/index.js",
            "contents": "#!/usr/bin/env node\n\nconst Promise = require('bluebird');\nconst cli = require('@vbarbarosh/node-helpers/src/cli');\nconst countdown = require('@vbarbarosh/node-helpers/src/countdown');\nconst format_ms = require('@vbarbarosh/node-helpers/src/format_ms');\nconst format_ms3 = require('@vbarbarosh/node-helpers/src/format_ms3');\nconst perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');\nconst perf_start = require('@vbarbarosh/node-helpers/src/perf_start');\n\ncli(main);\n\nasync function main()\n{\n    const time0 = perf_start();\n\n    await countdown({\n        value: Promise.delay(3000),\n        timeout: 5000,\n        tick_ms: 500,\n        tick: function (ctx) {\n            console.log(`[${format_ms3(ctx.time_elapsed)}][tick] remain=${format_ms(ctx.time_remained)}`);\n        },\n    });\n\n    console.log(`🎉 Done in ${perf_end_human(time0)}`);\n}\n"
        }
    ],
    "src": [
        {
            "id": "HeartbeatServer",
            "name": "HeartbeatServer",
            "file": "src/HeartbeatServer.js",
            "require": "const HeartbeatServer = require('@vbarbarosh/node-helpers/src/HeartbeatServer');",
            "source_code": "const EventEmitter = require('events');\nconst Promise = require('bluebird');\nconst fs = require('fs');\nconst fs_path_join = require('./fs_path_join');\nconst fs_rmf = require('./fs_rmf');\nconst net = require('net');\nconst now_fs = require('./now_fs');\nconst os = require('os');\n\nclass HeartbeatServer extends EventEmitter\n{\n    #socket_path;\n    #last_ping = Date.now();\n    #interval_ms;\n    #promise;\n    #reject;\n    #timer;\n    #server;\n\n    constructor(interval_ms = 5000) {\n        super();\n        this.#interval_ms = interval_ms;\n        this.#init();\n    }\n\n    #init() {\n        const _this = this;\n\n        this.#timer = setInterval(() => this.#tick(), this.#interval_ms);\n\n        // Put socket on tmpfs to avoid slow disks.\n        this.#socket_path = fs.existsSync('/dev/shm')\n            ? fs_path_join('/dev/shm', `watchdog-${process.pid}-${now_fs()}.sock`)\n            : fs_path_join(os.tmpdir(), `watchdog-${process.pid}-${now_fs()}.sock`);\n\n        this.#promise = new Promise((resolve, reject) => {\n            this.#reject = reject;\n        });\n\n        this.#server = net.createServer(function (socket) {\n            socket.setEncoding('utf8');\n            socket.on('error', function (error) {\n                _this.#reject(new Error(`Client Socket Failed: ${error.message}`));\n            });\n            socket.on('end', function () {\n                _this.#last_ping = Date.now();\n                _this.emit('heartbeat');\n            });\n            socket.on('data', function () {\n                // Not really interested in any data\n            });\n            socket.end('OK');\n        });\n        this.#server.on('error', function (error) {\n            _this.#reject(new Error(`Server Failed: ${error.message}`));\n        });\n        this.#server.on('close', function () {\n            _this.#reject(new Error(`Server Closed`));\n        });\n        this.#server.listen(this.#socket_path, function () {\n            // started = true;\n        });\n    }\n\n    #tick() {\n        if (this.#last_ping + this.#interval_ms < Date.now()) {\n            clearInterval(this.#timer);\n            this.#timer = null;\n            this.#reject(new Error(`No heartbeat for the last ${this.#interval_ms}ms`));\n        }\n    }\n\n    get socket_path() {\n        return this.#socket_path;\n    }\n\n    promise() {\n        return this.#promise;\n    }\n\n    async dispose() {\n        if (this.#timer) {\n            clearInterval(this.#timer);\n            this.#timer = null;\n        }\n        try {\n            const _this = this;\n            await new Promise(function (resolve, reject) {\n                _this.#server.removeAllListeners();\n                _this.#server.close(error => error ? reject(error) : resolve());\n            });\n        }\n        finally {\n            await fs_rmf(this.#socket_path);\n        }\n    }\n}\n\nmodule.exports = HeartbeatServer;\n",
            "markdown": null
        },
        {
            "id": "array_chunk",
            "name": "array_chunk",
            "file": "src/array_chunk.js",
            "require": "const array_chunk = require('@vbarbarosh/node-helpers/src/array_chunk');",
            "source_code": "/**\n * Split an array into chunks.\n *\n * @param array\n * @param limit\n * @returns {*[]}\n */\nfunction array_chunk(array = [], limit = 1)\n{\n    if (limit < 1) {\n        throw new Error('Limit value should be greater than 1');\n    }\n\n    const out = [];\n    for (let i = 0, end = array.length; i < end; i += limit) {\n        out.push(array.slice(i, i + limit));\n    }\n    return out;\n}\n\nmodule.exports = array_chunk;\n",
            "markdown": null
        },
        {
            "id": "array_gcd",
            "name": "array_gcd",
            "file": "src/array_gcd.js",
            "require": "const array_gcd = require('@vbarbarosh/node-helpers/src/array_gcd');",
            "source_code": "// https://stackoverflow.com/a/39764792/1478566\nfunction array_gcd(array, fn = Number)\n{\n    return array.reduce((a,b) => gcd(fn(a), fn(b)));\n}\n\n// https://stackoverflow.com/a/39764792/1478566\nfunction gcd(a, b)\n{\n    if (b) {\n        return gcd(b, a % b);\n    }\n    return a;\n}\n\nmodule.exports = array_gcd;\n",
            "markdown": null
        },
        {
            "id": "array_group",
            "name": "array_group",
            "file": "src/array_group.js",
            "require": "const array_group = require('@vbarbarosh/node-helpers/src/array_group');",
            "source_code": "/**\n * Group items by a common key and return an array of groups.\n *\n * @alternative Map.groupBy(items, fn)\n */\nfunction array_group(array, fn)\n{\n    const map = new Map();\n    array.forEach(function (item) {\n        const key = fn(item);\n        if (!map.has(key)) {\n            map.set(key, {key, items: []});\n        }\n        map.get(key).items.push(item);\n    });\n    return map.values().toArray();\n}\n\nmodule.exports = array_group;\n",
            "markdown": null
        },
        {
            "id": "array_group_map",
            "name": "array_group_map",
            "file": "src/array_group_map.js",
            "require": "const array_group_map = require('@vbarbarosh/node-helpers/src/array_group_map');",
            "source_code": "/**\n * Group items by common key and return an object of items grouped by key.\n *\n * @param array\n * @param fn\n * @returns {{}}\n */\nfunction array_group_map(array, fn)\n{\n    const out = {};\n    array.forEach(function (item) {\n        const key = fn(item);\n        out[key] = out[key] || {key, items: []};\n        out[key].items.push(item);\n    });\n    return out;\n}\n\nmodule.exports = array_group_map;\n",
            "markdown": null
        },
        {
            "id": "array_index",
            "name": "array_index",
            "file": "src/array_index.js",
            "require": "const array_index = require('@vbarbarosh/node-helpers/src/array_index');",
            "source_code": "const identity = require('./identity');\n\n/**\n * Usage:\n *     array_index(items, v => v.name)\n *\n * Seems, there is a native way to do it:\n *     Object.fromEntries(items.map(v => [v.name, v]));\n */\nfunction array_index(array, fn = identity)\n{\n    const out = {};\n    array.forEach(v => out[fn(v)] = v);\n    return out;\n}\n\nmodule.exports = array_index;\n",
            "markdown": null
        },
        {
            "id": "array_max",
            "name": "array_max",
            "file": "src/array_max.js",
            "require": "const array_max = require('@vbarbarosh/node-helpers/src/array_max');",
            "source_code": "const identity = require('./identity');\n\n/**\n * Returns the first element in the array with the maximal weight\n */\nfunction array_max(array, fn = identity)\n{\n    let out = null;\n    let max = null;\n    array.forEach(function (item, i) {\n        const weight = fn(item);\n        if (i === 0 || max < weight) {\n            max = weight;\n            out = item;\n        }\n    });\n    return out;\n}\n\nmodule.exports = array_max;\n",
            "markdown": "Returns the first element in the array with the maximal weight.\n"
        },
        {
            "id": "array_min",
            "name": "array_min",
            "file": "src/array_min.js",
            "require": "const array_min = require('@vbarbarosh/node-helpers/src/array_min');",
            "source_code": "const identity = require('./identity');\n\n/**\n * Returns the first element in the array with the minimal weight\n */\nfunction array_min(array, fn = identity)\n{\n    let out = null;\n    let min = null;\n    array.forEach(function (item, i) {\n        const weight = fn(item);\n        if (i === 0 || min > weight) {\n            min = weight;\n            out = item;\n        }\n    });\n    return out;\n}\n\nmodule.exports = array_min;\n",
            "markdown": "Returns the first element in the array with the minimal weight.\n"
        },
        {
            "id": "array_permutations",
            "name": "array_permutations",
            "file": "src/array_permutations.js",
            "require": "const array_permutations = require('@vbarbarosh/node-helpers/src/array_permutations');",
            "source_code": "// https://stackoverflow.com/a/37580979/23502239\nfunction array_permutations(array, k = array.length)\n{\n    if (k !== array.length) {\n        return array_permutations_k(array, k);\n    }\n\n    let length = array.length;\n    let out = [array.slice()];\n    let c = new Array(length).fill(0);\n    let i = 1, kk, p;\n\n    while (i < length) {\n        if (c[i] < i) {\n            kk = i % 2 && c[i];\n            p = array[i];\n            array[i] = array[kk];\n            array[kk] = p;\n            ++c[i];\n            i = 1;\n            out.push(array.slice());\n        }\n        else {\n            c[i] = 0;\n            ++i;\n        }\n    }\n    return out;\n}\n\nfunction array_permutations_k(array, k)\n{\n    if (k === 0) {\n        return [\n            []\n        ];\n    }\n    if (array.length < k) {\n        return [];\n    }\n\n    const out = [];\n    for (let i = 0; i < array.length; i++) {\n        const rest = array.slice(0, i).concat(array.slice(i + 1));\n        for (const perm of array_permutations(rest, k - 1)) {\n            out.push([array[i], ...perm]);\n        }\n    }\n    return out;\n}\n\nmodule.exports = array_permutations;\n",
            "markdown": null
        },
        {
            "id": "array_shuffle",
            "name": "array_shuffle",
            "file": "src/array_shuffle.js",
            "require": "const array_shuffle = require('@vbarbarosh/node-helpers/src/array_shuffle');",
            "source_code": "/**\n * Shuffles an array using Durstenfeld shuffle algorithm.\n *\n * Note: This function performs shuffle in-place. In order\n * to get a shuffled copy use call slice before calling, e.g.\n * array_shuffle(items.slice()).\n *\n * @param array\n * @returns array\n * @link https://stackoverflow.com/a/6274381/1478566\n * @link https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle\n */\nfunction array_shuffle(array)\n{\n    for (let i = array.length; --i > 0; ) {\n        const j = Math.floor(Math.random() * (i + 1));\n        const x = array[i];\n        array[i] = array[j];\n        array[j] = x;\n    }\n    return array;\n}\n\nmodule.exports = array_shuffle;\n",
            "markdown": "Shuffles an array using Durstenfeld shuffle algorithm.\n\nNote: This function performs shuffle in-place. To get a shuffled copy\nuse call slice before calling, e.g. `array_shuffle(items.slice())`.\n "
        },
        {
            "id": "array_sort",
            "name": "array_sort",
            "file": "src/array_sort.js",
            "require": "const array_sort = require('@vbarbarosh/node-helpers/src/array_sort');",
            "source_code": "const fcmp_default = require('./fcmp_default');\nconst fcmp_tuples = require('./fcmp_tuples');\n\n/**\n * Sorts an array in place by the result of applying `fn` to each item,\n * using `fcmp` to compare the results.\n *\n * array_sort(items, v => [v.name])\n * array_sort(items, v => [v.age, v.name])\n */\nfunction array_sort(array, mapper, fcmp = fcmp_default)\n{\n    const keys = new Map();\n    return array.sort(function (a, b) {\n        if (!keys.has(a)) {\n            keys.set(a, mapper(a));\n        }\n        if (!keys.has(b)) {\n            keys.set(b, mapper(b));\n        }\n        return fcmp_tuples(keys.get(a), keys.get(b), fcmp);\n    });\n}\n\n// function array_sort(array, fn = identity, fcmp = fcmp_default)\n// {\n//     return array.sort(function (a, b) {\n//         return fcmp(fn(a), fn(b));\n//     });\n// }\n\nmodule.exports = array_sort;\n",
            "markdown": null
        },
        {
            "id": "array_sort_other",
            "name": "array_sort_other",
            "file": "src/array_sort_other.js",
            "require": "const array_sort_other = require('@vbarbarosh/node-helpers/src/array_sort_other');",
            "source_code": "const fcmp_default = require('./fcmp_default');\n\n/**\n * Sort items in an `array` at the same order as in `other`. Values which\n * are not in the `other` are added to the end of the result defined by `fcmp`.\n *\n * @param array\n * @param fn\n * @param other\n * @param fcmp\n * @returns {*}\n */\nfunction array_sort_other(array, fn, other, fcmp = fcmp_default)\n{\n    const other_map = {};\n    other.forEach((v,i) => other_map[v] = i + 1);\n    return array.sort(function (a, b) {\n        const ax = other_map[fn(a)];\n        const bx = other_map[fn(b)];\n        if (ax && bx) {\n            return ax - bx;\n        }\n        if (ax) {\n            return -1;\n        }\n        if (bx) {\n            return 1;\n        }\n        return fcmp(a, b);\n    });\n}\n\nmodule.exports = array_sort_other;\n",
            "markdown": null
        },
        {
            "id": "array_sum",
            "name": "array_sum",
            "file": "src/array_sum.js",
            "require": "const array_sum = require('@vbarbarosh/node-helpers/src/array_sum');",
            "source_code": "function array_sum(array, fn = Number)\n{\n    let out = 0;\n    array.forEach(function (item) {\n        out += fn(item);\n    });\n    return out;\n}\n\nmodule.exports = array_sum;\n",
            "markdown": null
        },
        {
            "id": "array_unique",
            "name": "array_unique",
            "file": "src/array_unique.js",
            "require": "const array_unique = require('@vbarbarosh/node-helpers/src/array_unique');",
            "source_code": "const identity = require('./identity');\n\n/**\n * Return unique values; if a value occurs multiple times, keep the first one.\n */\nfunction array_unique(values, fn = identity)\n{\n    const set = new Set();\n    return values.filter(function (item) {\n        const key = fn(item);\n        if (set.has(key)) {\n            return false;\n        }\n        set.add(key);\n        return true;\n    });\n}\n\nmodule.exports = array_unique;\n",
            "markdown": "Return unique values; if a value occurs multiple times, keep the first one.\n"
        },
        {
            "id": "array_unique_last",
            "name": "array_unique_last",
            "file": "src/array_unique_last.js",
            "require": "const array_unique_last = require('@vbarbarosh/node-helpers/src/array_unique_last');",
            "source_code": "const identity = require('./identity');\n\n/**\n * Return unique values; if a value occurs multiple times, keep the last one.\n */\nfunction array_unique_last(array, fn = identity)\n{\n    const out = [];\n    const set = new Set();\n    for (let i = array.length; --i >= 0; ) {\n        const item = array[i];\n        const key = fn(item);\n        if (!set.has(key)) {\n            set.add(key);\n            out.push(item);\n        }\n    }\n    return out.reverse();\n}\n\nmodule.exports = array_unique_last;\n",
            "markdown": "Return unique values; if a value occurs multiple times, keep the last one.\n"
        },
        {
            "id": "assert_valid_expires_at",
            "name": "assert_valid_expires_at",
            "file": "src/assert_valid_expires_at.js",
            "require": "const assert_valid_expires_at = require('@vbarbarosh/node-helpers/src/assert_valid_expires_at');",
            "source_code": "/**\n * Ensures that the provided value is a date pointing to the future.\n */\nfunction assert_valid_expires_at(expires_at)\n{\n    if (expires_at instanceof Date) {\n        if (expires_at.getTime() > Date.now()) {\n            return;\n        }\n    }\n    throw new Error('Invalid value for expires_at; it should be a Date object pointing to the future.');\n}\n\nmodule.exports = assert_valid_expires_at;\n",
            "markdown": null
        },
        {
            "id": "cli",
            "name": "cli",
            "file": "src/cli.js",
            "require": "const cli = require('@vbarbarosh/node-helpers/src/cli');",
            "source_code": "/**\n * Entry point for Node CLI apps\n */\nfunction cli(main)\n{\n    // https://stackoverflow.com/a/46916601/1478566\n    const timer = setInterval(v => v, 1E9);\n\n    Promise.resolve(main()).then(resolve, reject);\n\n    function resolve() {\n        clearInterval(timer);\n    }\n    function reject(error) {\n        clearInterval(timer);\n        console.error(error);\n        process.exit(1);\n    }\n}\n\nmodule.exports = cli;\n",
            "markdown": null
        },
        {
            "id": "const_stream",
            "name": "const_stream",
            "file": "src/const_stream.js",
            "require": "const const_stream = require('@vbarbarosh/node-helpers/src/const_stream');",
            "source_code": "// Since Node.js streams cannot emit `null` values (it's an eof mark),\n// this is a workaround.\n\nconst const_stream = {\n    null: Symbol('stream[null]'),\n};\n\nmodule.exports = const_stream;\n",
            "markdown": null
        },
        {
            "id": "const_type",
            "name": "const_type",
            "file": "src/const_type.js",
            "require": "const const_type = require('@vbarbarosh/node-helpers/src/const_type');",
            "source_code": "const const_type = {\n    null: 'null',\n    undefined: 'undefined',\n    boolean: 'boolean',\n    number: 'number',\n    bigint: 'bigint',\n    nan: 'nan',\n    neg_inf: '-inf',\n    pos_inf: '+inf',\n    string: 'string',\n    symbol: 'symbol',\n    function: 'function',\n    object: 'object',\n    array: 'array',\n};\n\nmodule.exports = const_type;\n",
            "markdown": null
        },
        {
            "id": "countdown",
            "name": "countdown",
            "file": "src/countdown.js",
            "require": "const countdown = require('@vbarbarosh/node-helpers/src/countdown');",
            "source_code": "const Promise = require('bluebird');\n\n/**\n * Wait for a promise/value to be settled. Meanwhile, call `tick` function every `tick_ms` milliseconds.\n * After `timeout` seconds, reject with 'Timeout' error.\n *\n * @see user_friendly_status\n * @see progress\n */\nfunction countdown(ctx)\n{\n    let done = false;\n    let timer = null;\n    return new Promise(function (resolve, reject) {\n        ctx.value = ctx.fn ? Promise.method(ctx.fn).call() : Promise.resolve(ctx.value);\n        ctx.timeout = ctx.timeout || 0; // ⚠️ Rename to timeout_ms\n        ctx.time_now = new Date();\n        ctx.time_begin = new Date();\n        ctx.time_end = Date.now() + ctx.timeout;\n        ctx.tick_ms = ctx.tick_ms || 1000;\n        ctx.tick = ctx.tick || function () {};\n        ctx.resolve = function (value) {\n            if (done) {\n                throw new Error('Already settled');\n            }\n            done = true;\n            clearInterval(timer);\n            resolve(value);\n        };\n        ctx.reject = function (error) {\n            if (done) {\n                throw new Error('Already settled');\n            }\n            done = true;\n            clearInterval(timer);\n            reject(error);\n        };\n        timer = setInterval(tick, ctx.tick_ms);\n        ctx.value.then(ctx.resolve, ctx.reject);\n        tick();\n        function tick() {\n            ctx.time_now = Date.now();\n            ctx.time_elapsed = ctx.time_now - ctx.time_begin;\n            ctx.time_remained = Math.max(0, ctx.time_end - ctx.time_now);\n            ctx.tick(ctx);\n            if (!ctx.time_remained) {\n                ctx.reject(new Error('Timeout'));\n            }\n        }\n    });\n}\n\nmodule.exports = countdown;\n",
            "markdown": null
        },
        {
            "id": "crypto_decrypt_aes256",
            "name": "crypto_decrypt_aes256",
            "file": "src/crypto_decrypt_aes256.js",
            "require": "const crypto_decrypt_aes256 = require('@vbarbarosh/node-helpers/src/crypto_decrypt_aes256');",
            "source_code": "const crypto = require('crypto');\n\n/**\n * @link https://nodejs.org/api/crypto.html#crypto_class_cipher\n * @link https://attacomsian.com/blog/nodejs-encrypt-decrypt-data\n */\nfunction crypto_decrypt_aes256(password, ivenc)\n{\n    const key = crypto.createHash('sha256').update(password).digest();\n    const iv = ivenc.slice(1, ivenc[0] + 1);\n    const enc = ivenc.slice(ivenc[0] + 1);\n    const decipher = crypto.createDecipheriv('aes-256-ctr', key, iv);\n    return Buffer.concat([decipher.update(enc), decipher.final()]);\n}\n\nmodule.exports = crypto_decrypt_aes256;\n",
            "markdown": null
        },
        {
            "id": "crypto_encrypt_aes256",
            "name": "crypto_encrypt_aes256",
            "file": "src/crypto_encrypt_aes256.js",
            "require": "const crypto_encrypt_aes256 = require('@vbarbarosh/node-helpers/src/crypto_encrypt_aes256');",
            "source_code": "const crypto = require('crypto');\n\n/**\n * @link https://nodejs.org/api/crypto.html#crypto_class_cipher\n * @link https://attacomsian.com/blog/nodejs-encrypt-decrypt-data\n */\nfunction crypto_encrypt_aes256(password, data)\n{\n    const iv = crypto.randomBytes(16);\n    const key = crypto.createHash('sha256').update(password).digest();\n    const cipher = crypto.createCipheriv('aes-256-ctr', key, iv);\n    if (iv.length > 255) {\n        throw new Error('iv size is too big');\n    }\n    return Buffer.concat([Buffer.from([iv.length]), iv, cipher.update(data), cipher.final()]);\n}\n\nmodule.exports = crypto_encrypt_aes256;\n",
            "markdown": null
        },
        {
            "id": "crypto_hash_md5",
            "name": "crypto_hash_md5",
            "file": "src/crypto_hash_md5.js",
            "require": "const crypto_hash_md5 = require('@vbarbarosh/node-helpers/src/crypto_hash_md5');",
            "source_code": "const crypto = require('crypto');\n\n/**\n *\n * @param data\n * @returns {Buffer}\n * @link https://nodejs.org/en/knowledge/cryptography/how-to-use-crypto-module/#how-to-calculate-hashes-with-crypto\n */\nfunction crypto_hash_md5(data)\n{\n    return crypto.createHash('md5').update(data).digest();\n}\n\nmodule.exports = crypto_hash_md5;\n",
            "markdown": null
        },
        {
            "id": "crypto_hash_sha256",
            "name": "crypto_hash_sha256",
            "file": "src/crypto_hash_sha256.js",
            "require": "const crypto_hash_sha256 = require('@vbarbarosh/node-helpers/src/crypto_hash_sha256');",
            "source_code": "const crypto = require('crypto');\n\n/**\n *\n * @param data\n * @returns {Buffer}\n * @link https://nodejs.org/en/knowledge/cryptography/how-to-use-crypto-module/#how-to-calculate-hashes-with-crypto\n */\nfunction crypto_hash_sha256(data)\n{\n    return crypto.createHash('sha256').update(data).digest();\n}\n\nmodule.exports = crypto_hash_sha256;\n",
            "markdown": null
        },
        {
            "id": "crypto_hmac_sha256",
            "name": "crypto_hmac_sha256",
            "file": "src/crypto_hmac_sha256.js",
            "require": "const crypto_hmac_sha256 = require('@vbarbarosh/node-helpers/src/crypto_hmac_sha256');",
            "source_code": "const crypto = require('crypto');\n\n/**\n *\n * @param password\n * @param data\n * @returns {Buffer}\n * @link https://nodejs.org/en/knowledge/cryptography/how-to-use-crypto-module/#hmac\n */\nfunction crypto_hmac_sha256(password, data)\n{\n    return crypto.createHmac('sha256', password).update(data).digest();\n}\n\nmodule.exports = crypto_hmac_sha256;\n",
            "markdown": null
        },
        {
            "id": "date_add_hours",
            "name": "date_add_hours",
            "file": "src/date_add_hours.js",
            "require": "const date_add_hours = require('@vbarbarosh/node-helpers/src/date_add_hours');",
            "source_code": "function date_add_hours(date, hours)\n{\n    date.setHours(date.getHours() + hours);\n    return date;\n}\n\nmodule.exports = date_add_hours;\n",
            "markdown": null
        },
        {
            "id": "date_add_milliseconds",
            "name": "date_add_milliseconds",
            "file": "src/date_add_milliseconds.js",
            "require": "const date_add_milliseconds = require('@vbarbarosh/node-helpers/src/date_add_milliseconds');",
            "source_code": "function date_add_milliseconds(date, milliseconds)\n{\n    date.setMilliseconds(date.getMilliseconds() + milliseconds);\n    return date;\n}\n\nmodule.exports = date_add_milliseconds;\n",
            "markdown": null
        },
        {
            "id": "date_add_minutes",
            "name": "date_add_minutes",
            "file": "src/date_add_minutes.js",
            "require": "const date_add_minutes = require('@vbarbarosh/node-helpers/src/date_add_minutes');",
            "source_code": "function date_add_minutes(date, minutes)\n{\n    date.setMinutes(date.getMinutes() + minutes);\n    return date;\n}\n\nmodule.exports = date_add_minutes;\n",
            "markdown": null
        },
        {
            "id": "date_add_months",
            "name": "date_add_months",
            "file": "src/date_add_months.js",
            "require": "const date_add_months = require('@vbarbarosh/node-helpers/src/date_add_months');",
            "source_code": "/**\n * @link https://stackoverflow.com/a/7937257\n */\nfunction date_add_months(d, months)\n{\n    if (!months) {\n        return d;\n    }\n\n    // https://github.com/briannesbitt/Carbon/blob/f01cfa96468f4c38325f507ab81a4f1d2cd93cfe/src/Carbon/Traits/Units.php#L360C1-L361C1\n    // > } elseif (isset($canOverflow, $day) && $canOverflow && $day !== $date?->day) {\n    // >     $date = $date?->modify('last day of previous month');\n    // > }\n\n    const date0 = d.getDate();\n    d.setMonth(d.getMonth() + months);\n    if (d.getDate() !== date0) {\n        d.setDate(0);\n    }\n\n    return d;\n}\n\nmodule.exports = date_add_months;\n",
            "markdown": null
        },
        {
            "id": "date_add_seconds",
            "name": "date_add_seconds",
            "file": "src/date_add_seconds.js",
            "require": "const date_add_seconds = require('@vbarbarosh/node-helpers/src/date_add_seconds');",
            "source_code": "function date_add_seconds(date, seconds)\n{\n    date.setSeconds(date.getSeconds() + seconds);\n    return date;\n}\n\nmodule.exports = date_add_seconds;\n",
            "markdown": null
        },
        {
            "id": "date_diff_seconds",
            "name": "date_diff_seconds",
            "file": "src/date_diff_seconds.js",
            "require": "const date_diff_seconds = require('@vbarbarosh/node-helpers/src/date_diff_seconds');",
            "source_code": "function date_diff_seconds(a, b)\n{\n    return Math.floor((a.getTime() - b.getTime())/1000);\n}\n\nmodule.exports = date_diff_seconds;\n",
            "markdown": null
        },
        {
            "id": "date_is_leap_year",
            "name": "date_is_leap_year",
            "file": "src/date_is_leap_year.js",
            "require": "const date_is_leap_year = require('@vbarbarosh/node-helpers/src/date_is_leap_year');",
            "source_code": "/**\n * @link https://github.com/moment/moment/blob/18aba135ab927ffe7f868ee09276979bed6993a6/src/lib/utils/is-leap-year.js\n * @link https://en.wikipedia.org/wiki/Leap_year\n * > Each leap year has 366 days instead of 365. This extra leap day\n * > occurs in each year that is a multiple of 4, except for years\n * > evenly divisible by 100 but not by 400.\n */\nfunction date_is_leap_year(d)\n{\n    const year = d.getFullYear();\n    // return (year % 4 === 0) && !(year % 100 === 0 && year % 400 !== 0);\n    return (year % 4 === 0 && year % 100 !== 0) || (year % 400 === 0);\n}\n\nmodule.exports = date_is_leap_year;\n",
            "markdown": null
        },
        {
            "id": "escape_content_disposition",
            "name": "escape_content_disposition",
            "file": "src/escape_content_disposition.js",
            "require": "const escape_content_disposition = require('@vbarbarosh/node-helpers/src/escape_content_disposition');",
            "source_code": "/**\n * @link https://stackoverflow.com/a/72823174\n * @link https://github.com/jshttp/content-disposition/tree/master\n */\nfunction escape_content_disposition(s)\n{\n    const out = s.replaceAll('\\\\', '\\\\\\\\')\n        .replaceAll('\"', '\\\\\"')\n        .replaceAll('%', '\\\\%')\n        .replaceAll('\\n', '%x0A')\n        .replaceAll('\\0', '%x00');\n    if (out.match(/\\s|;/)) {\n        return `\"${out}\"`;\n    }\n    return out;\n}\n\nmodule.exports = escape_content_disposition;\n",
            "markdown": null
        },
        {
            "id": "escape_regexp",
            "name": "escape_regexp",
            "file": "src/escape_regexp.js",
            "require": "const escape_regexp = require('@vbarbarosh/node-helpers/src/escape_regexp');",
            "source_code": "/**\n * @link https://stackoverflow.com/a/6969486/23502239\n */\nfunction escape_regexp(s)\n{\n    return s.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n}\n\nmodule.exports = escape_regexp;\n",
            "markdown": null
        },
        {
            "id": "eta",
            "name": "eta",
            "file": "src/eta.js",
            "require": "const eta = require('@vbarbarosh/node-helpers/src/eta');",
            "source_code": "const format_seconds = require('./format_seconds');\n\nfunction eta(time0, total, done, resumed = 0)\n{\n    const seconds = (Date.now() - time0)/1000;\n    const remained = total - done;\n    const bps = (done - resumed)/seconds;\n    return format_seconds(remained/bps);\n}\n\nmodule.exports = eta;\n",
            "markdown": null
        },
        {
            "id": "factorize_ms",
            "name": "factorize_ms",
            "file": "src/factorize_ms.js",
            "require": "const factorize_ms = require('@vbarbarosh/node-helpers/src/factorize_ms');",
            "source_code": "function factorize_ms(v)\n{\n    const h = Math.floor(v / 3600000);\n    const m = Math.floor(v % 3600000 / 60000);\n    const s = Math.floor(v % 60000 / 1000);\n    const ms = v % 1000;\n    return [h, m, s, ms];\n}\n\nmodule.exports = factorize_ms;\n",
            "markdown": null
        },
        {
            "id": "fastdl",
            "name": "fastdl",
            "file": "src/fastdl.js",
            "require": "const fastdl = require('@vbarbarosh/node-helpers/src/fastdl');",
            "source_code": "const UserFriendlyError = require('./errors/UserFriendlyError');\nconst format_bytes = require('./format_bytes');\nconst format_progress_bytes = require('./format_progress_bytes');\nconst format_thousands = require('./format_thousands');\nconst fs = require('fs');\nconst fs_path_basename = require('./fs_path_basename');\nconst ignore = require('./ignore');\nconst make_progress = require('./make_progress');\nconst parallel = require('./parallel');\nconst stream = require('stream');\n\n/**\n * Download a file in several connections in parallel.\n *\n * await fastdl({\n *     file: fs_path_basename(new URL(url).pathname),\n *     read_stream_with_range: (first, last) => http_get_stream_range(url, first, last),\n * });\n */\nasync function fastdl({file, read_stream_with_range, concurrency = 60, user_friendly_status = v => console.log(v)})\n{\n    const M = 1024*1024;\n    const chunk_min_bytes = M;\n    const chunk_max_bytes = 50*M;\n\n    user_friendly_status(`Truncating destination file [${fs_path_basename(file)}]...`);\n    await fs.promises.writeFile(file, '');\n\n    user_friendly_status('Requesting first chunk to determine total size...');\n    const rs0 = await read_stream_with_range(0, chunk_min_bytes);\n\n    const total = rs0.content_range.total;\n    const chunk_size = Math.max(chunk_min_bytes, Math.min(chunk_max_bytes, Math.trunc(total/concurrency)));\n    const progress = make_progress(total);\n\n    let connections = 0;\n    let next_first = 0;\n    let total_written = 0;\n\n    const timer = setInterval(tick, 1000);\n    function tick() {\n        progress.refresh();\n        user_friendly_status(`${format_progress_bytes(progress)} connections=${connections}`);\n    }\n\n    user_friendly_status(`${format_bytes(total)} [${format_thousands(total)} bytes] to download`);\n\n    try {\n        await parallel({concurrency, spawn});\n    }\n    finally {\n        tick();\n        clearInterval(timer);\n    }\n\n    if (total !== total_written) {\n        throw new UserFriendlyError(`Total bytes written differs from expected size of a file: total[${total}] - total_written[${total_written}] = ${total - total_written}`);\n    }\n\n    function spawn() {\n        if (next_first >= total) {\n            return;\n        }\n        let first = next_first;\n        const last = Math.min(total - 1, first + (first === 0 ? rs0.content_range.last : chunk_size));\n        next_first = last + 1;\n        connections++;\n        return Promise.resolve(run()).catch(run).catch(run).finally(() => connections--);\n        async function run() {\n            if (first > last) {\n                return;\n            }\n            const rs = (first === 0) ? rs0 : await read_stream_with_range(first, last);\n            if (rs.content_range.total !== total) {\n                rs.once('error', ignore);\n                rs.destroy();\n                throw new UserFriendlyError('Size of a file changed during download');\n            }\n            const acc = new stream.PassThrough({\n                transform(buf, encoding, next) {\n                    first += buf.length;\n                    total_written += buf.length;\n                    progress.add(buf.length);\n                    next(null, buf);\n                }\n            });\n            const ws = fs.createWriteStream(file, {\n                flags: fs.constants.O_WRONLY, // |fs.constants.O_CREAT,\n                start: first,\n            });\n            await stream.promises.pipeline(rs, acc, ws);\n        }\n    }\n}\n\nmodule.exports = fastdl;\n",
            "markdown": "Download a file in several connections in parallel.\n\n```js\nawait fastdl({\n    file: fs_path_basename(new URL(url).pathname),\n    read_stream_with_range: (first, last) => http_get_stream_range(url, first, last),\n});\n```\n"
        },
        {
            "id": "fcmp_dates",
            "name": "fcmp_dates",
            "file": "src/fcmp_dates.js",
            "require": "const fcmp_dates = require('@vbarbarosh/node-helpers/src/fcmp_dates');",
            "source_code": "function fcmp_dates(a, b)\n{\n    return a.getTime() - b.getTime();\n}\n\nmodule.exports = fcmp_dates;\n",
            "markdown": null
        },
        {
            "id": "fcmp_default",
            "name": "fcmp_default",
            "file": "src/fcmp_default.js",
            "require": "const fcmp_default = require('@vbarbarosh/node-helpers/src/fcmp_default');",
            "source_code": "function fcmp_default(a, b)\n{\n    if (a < b) {\n        return -1;\n    }\n    if (a > b) {\n        return 1;\n    }\n    return 0;\n}\n\nmodule.exports = fcmp_default;\n",
            "markdown": null
        },
        {
            "id": "fcmp_default_desc",
            "name": "fcmp_default_desc",
            "file": "src/fcmp_default_desc.js",
            "require": "const fcmp_default_desc = require('@vbarbarosh/node-helpers/src/fcmp_default_desc');",
            "source_code": "function fcmp_default_desc(b, a)\n{\n    if (a < b) {\n        return -1;\n    }\n    if (a > b) {\n        return 1;\n    }\n    return 0;\n}\n\nmodule.exports = fcmp_default_desc;\n",
            "markdown": null
        },
        {
            "id": "fcmp_from_spec",
            "name": "fcmp_from_spec",
            "file": "src/fcmp_from_spec.js",
            "require": "const fcmp_from_spec = require('@vbarbarosh/node-helpers/src/fcmp_from_spec');",
            "source_code": "/**\n * Create fcmp from an array of props. For desc order a prop should be prefixed\n * with minus sign (e.g. -price).\n *\n * @deprecated Deprecated in favor of fcmpx\n */\nfunction fcmp_from_spec(props)\n{\n    const fcmp = props.map(one);\n    switch (fcmp.length) {\n    case 0:\n        return () => 0;\n    case 1:\n        return fcmp[0];\n    case 2:\n        return function (a, b) {\n            return fcmp[0](a, b) || fcmp[1](a, b);\n        };\n    case 3:\n        return function (a, b) {\n            return fcmp[0](a, b) || fcmp[1](a, b) || fcmp[2](a, b);\n        };\n    default:\n        return function (a, b) {\n            for (let i = 0; i < fcmp.length; ++i) {\n                const tmp = fcmp[i](a, b);\n                if (tmp) {\n                    return tmp;\n                }\n            }\n            return 0;\n        };\n    }\n}\n\nfunction one(prop)\n{\n    if (prop[0] === '-') {\n        prop = prop.slice(1);\n        return function (b, a) {\n            return comp_types(a[prop], b[prop]);\n        };\n    }\n    return function (a, b) {\n        return comp_types(a[prop], b[prop]);\n    };\n}\n\nfunction comp_types(a, b)\n{\n    if (typeof a === 'string' && typeof b === 'string') {\n        return a.localeCompare(b);\n    }\n    return a - b;\n}\n\nmodule.exports = fcmp_from_spec;\n",
            "markdown": null
        },
        {
            "id": "fcmp_numbers",
            "name": "fcmp_numbers",
            "file": "src/fcmp_numbers.js",
            "require": "const fcmp_numbers = require('@vbarbarosh/node-helpers/src/fcmp_numbers');",
            "source_code": "function fcmp_numbers(a, b)\n{\n    return a - b;\n}\n\nmodule.exports = fcmp_numbers;\n",
            "markdown": null
        },
        {
            "id": "fcmp_tuples",
            "name": "fcmp_tuples",
            "file": "src/fcmp_tuples.js",
            "require": "const fcmp_tuples = require('@vbarbarosh/node-helpers/src/fcmp_tuples');",
            "source_code": "const fcmp_default = require('./fcmp_default');\n\nfunction fcmp_tuples(a, b, fcmp = fcmp_default)\n{\n    const end = Math.min(a.length, b.length);\n    for (let i = 0; i < end; ++i) {\n        const tmp = fcmp(a[i], b[i]);\n        if (tmp) {\n            return tmp;\n        }\n    }\n    return 0;\n}\n\nmodule.exports = fcmp_tuples;\n",
            "markdown": null
        },
        {
            "id": "fcmp_utf8_bin",
            "name": "fcmp_utf8_bin",
            "file": "src/fcmp_utf8_bin.js",
            "require": "const fcmp_utf8_bin = require('@vbarbarosh/node-helpers/src/fcmp_utf8_bin');",
            "source_code": "// Strict binary (codepoint) comparison, like MySQL's utf8_bin collation\nfunction fcmp_utf8_bin(a, b)\n{\n    if (a < b) {\n        return -1;\n    }\n    if (a > b) {\n        return 1;\n    }\n    return 0;\n}\n\nmodule.exports = fcmp_utf8_bin;\n",
            "markdown": null
        },
        {
            "id": "fcmp_utf8_ci",
            "name": "fcmp_utf8_ci",
            "file": "src/fcmp_utf8_ci.js",
            "require": "const fcmp_utf8_ci = require('@vbarbarosh/node-helpers/src/fcmp_utf8_ci');",
            "source_code": "// Locale-aware, case-insensitive, like utf8_ci or utf8mb4_ci\nfunction fcmp_utf8_ci(a, b)\n{\n    return a.localeCompare(b, undefined, {sensitivity: 'base'});\n}\n\nmodule.exports = fcmp_utf8_ci;\n",
            "markdown": null
        },
        {
            "id": "fcmp_utf8_cs",
            "name": "fcmp_utf8_cs",
            "file": "src/fcmp_utf8_cs.js",
            "require": "const fcmp_utf8_cs = require('@vbarbarosh/node-helpers/src/fcmp_utf8_cs');",
            "source_code": "// Locale-aware, case-sensitive, like utf8_cs or utf8mb4_cs (but using system locale)\nfunction fcmp_utf8_cs(a, b)\n{\n    return a.localeCompare(b, undefined, {sensitivity: 'variant'});\n}\n\nmodule.exports = fcmp_utf8_cs;\n",
            "markdown": null
        },
        {
            "id": "fcmp_utf8_natural_ci",
            "name": "fcmp_utf8_natural_ci",
            "file": "src/fcmp_utf8_natural_ci.js",
            "require": "const fcmp_utf8_natural_ci = require('@vbarbarosh/node-helpers/src/fcmp_utf8_natural_ci');",
            "source_code": "// Natural sort (numeric), case-insensitive\nfunction fcmp_utf8_natural_ci(a, b)\n{\n    return a.localeCompare(b, undefined, {numeric: true, sensitivity: 'base'});\n}\n\nmodule.exports = fcmp_utf8_natural_ci;\n",
            "markdown": null
        },
        {
            "id": "fcmp_utf8_natural_cs",
            "name": "fcmp_utf8_natural_cs",
            "file": "src/fcmp_utf8_natural_cs.js",
            "require": "const fcmp_utf8_natural_cs = require('@vbarbarosh/node-helpers/src/fcmp_utf8_natural_cs');",
            "source_code": "// Natural sort (numeric), case-sensitive\nfunction fcmp_utf8_natural_cs(a, b)\n{\n    return a.localeCompare(b, undefined, {numeric: true, sensitivity: 'variant'});\n}\n\nmodule.exports = fcmp_utf8_natural_cs;\n",
            "markdown": null
        },
        {
            "id": "fcmpx",
            "name": "fcmpx",
            "file": "src/fcmpx.js",
            "require": "const fcmpx = require('@vbarbarosh/node-helpers/src/fcmpx');",
            "source_code": "const fcmp_default = require('./fcmp_default');\nconst fcmp_default_desc = require('./fcmp_default_desc');\nconst identity = require('./identity');\n\nconst MISSING = Symbol('fcmpx.missing');\n\n/**\n * Comparator builder using compact expressions.\n *\n * fcmp expression — Creates an `fcmp` function from an expression, suitable for use with `[].sort()`.\n *\n * fcmpx('user.email')\n * fcmpx('-user.age,user.email')\n * fcmpx(v => v.user.email)\n * fcmpx(['user.age', 'user.email'])\n * fcmpx(['-user.age', 'user.email'])\n */\nfunction fcmpx(expr)\n{\n    if (typeof expr === 'string') {\n        if (expr.includes(',')) {\n            return fcmpx(expr.split(','));\n        }\n        return fcmpx_compile(expr);\n    }\n    if (!Array.isArray(expr)) {\n        return fcmpx_compile(expr);\n    }\n    const fcmp_items = expr.map(fcmpx_parse);\n    return function (a, b) {\n        const tuple1 = fcmp_items.map(v => v.read(a));\n        const tuple2 = fcmp_items.map(v => v.read(b));\n        for (let i = 0; i < fcmp_items.length; ++i) {\n            const tmp = fcmp_items[i].fcmp(tuple1[i], tuple2[i]);\n            if (tmp) {\n                return tmp;\n            }\n        }\n        return 0;\n    };\n}\n\nfunction fcmpx_compile(expr)\n{\n    const {read, fcmp} = fcmpx_parse(expr);\n    return function (a, b) {\n        return fcmp(read(a), read(b));\n    };\n}\n\nfunction fcmpx_parse(expr)\n{\n    if (typeof expr === 'function') {\n        return {read: fcmpx_compile_read(expr), fcmp: fcmp_wrapper(fcmp_default)};\n    }\n    if (typeof expr === 'string') {\n        const desc = expr.startsWith('-');\n        const read = desc ? fcmpx_compile_read(expr.slice(1)) : fcmpx_compile_read(expr);\n        const fcmp = fcmp_wrapper(desc ? fcmp_default_desc : fcmp_default);\n        return {read, fcmp};\n    }\n    const fcmp_user = expr.fcmp;\n    const read = fcmpx_compile_read(expr.read);\n    const desc = expr.desc ?? false;\n    const fcmp = fcmp_wrapper(desc ? (fcmp_user ? (b, a) => fcmp_user(a, b) : fcmp_default_desc) : (fcmp_user ?? fcmp_default));\n    if (Array.isArray(expr.top)) {\n        const priority = new Map(expr.top.map((v, i) => [v, i]));\n        return {read: v => priority.get(read(v)) ?? priority.size, fcmp};\n    }\n    if (Array.isArray(expr.bottom)) {\n        const priority = new Map(expr.bottom.map((v, i) => [v, i]));\n        return {read: v => priority.get(read(v)) ?? -1, fcmp};\n    }\n    return {read, fcmp};\n}\n\nfunction fcmpx_compile_read(read)\n{\n    if (read === undefined || read === '' || read === '.') {\n        return identity;\n    }\n    if (typeof read === 'function') {\n        return function (value) {\n            return read(value) ?? MISSING;\n        };\n    }\n    if (typeof read === 'string') {\n        const props = read.split('.');\n        const [a, b, c, d, e] = props;\n        switch (props.length) {\n        case 1: return v => v?.[a] ?? MISSING;\n        case 2: return v => v?.[a]?.[b] ?? MISSING;\n        case 3: return v => v?.[a]?.[b]?.[c] ?? MISSING;\n        case 4: return v => v?.[a]?.[b]?.[c]?.[d] ?? MISSING;\n        case 5: return v => v?.[a]?.[b]?.[c]?.[d]?.[e] ?? MISSING;\n        default: return v => props.reduce((a,p) => a?.[p], v) ?? MISSING;\n        }\n    }\n    return v => v?.[read] ?? MISSING;\n}\n\n// Sorting rule: Missing values are considered greater than any defined value\n// and are therefore placed after all defined values.\nfunction fcmp_wrapper(fcmp)\n{\n    return function (a, b) {\n        if (a === MISSING) {\n            if (b === MISSING) {\n                return 0;\n            }\n            return 1;\n        }\n        if (b === MISSING) {\n            return -1;\n        }\n        return fcmp(a, b);\n    };\n}\n\nmodule.exports = fcmpx;\n",
            "markdown": "Comparator builder using compact expressions.\n\nfcmp expression — Creates an `fcmp` function from an expression, suitable for use with `[].sort()`.\n\n```js\nfcmpx('user.email')\nfcmpx('-user.age,user.email')\nfcmpx(v => v.user.email)\nfcmpx(['user.age', 'user.email'])\nfcmpx(['-user.age', 'user.email'])\n```\n\nSorting rule: Missing values are considered greater than any defined value\nand are therefore placed after all defined values.\n\n- YouTube: [Сортировка объектов в JavaScript](https://www.youtube.com/watch?v=rHEH_JfQjL4)\n- https://github.com/vbarbarosh/speaking/tree/master/20250822-js-sort-fcmpx\n"
        },
        {
            "id": "filter1_from_spec",
            "name": "filter1_from_spec",
            "file": "src/filter1_from_spec.js",
            "require": "const filter1_from_spec = require('@vbarbarosh/node-helpers/src/filter1_from_spec');",
            "source_code": "/**\n * Creates a filtering function based on the following spec:\n * 1. Substrings are separated by `/`.\n * 2. Each substring may have special characters:\n *    - `^`: Substring must appear at the beginning.\n *    - `$`: Substring must appear at the end.\n *    - `!`: Negates the condition (substring must not appear).\n */\nfunction filter1_from_spec(spec)\n{\n    let a, b, c, d;\n    const parts = parse_spec(spec);\n    switch (parts.length) {\n    case 0:\n        // No filters, always true\n        return () => true;\n    case 1:\n        return parts[0];\n    case 2:\n        [a, b] = parts;\n        return s => a(s) && b(s);\n    case 3:\n        [a, b, c] = parts;\n        return s => a(s) && b(s) && c(s);\n    case 4:\n        [a, b, c, d] = parts;\n        return s => a(s) && b(s) && c(s) && d(s);\n    default:\n        return s => parts.every(fn => fn(s));\n    }\n}\n\nfunction parse_spec(spec)\n{\n    return spec.split('/').filter(v => v).map(parse_expr);\n}\n\n// convert expr into an array of objects {substr, starts, ends}\nfunction parse_expr(expr)\n{\n    let substr;\n    let starts = false; // ^\n    let ends = false; // $\n    substr = expr.replaceAll('^', '');\n    starts = (substr.length !== expr.length);\n    expr = substr;\n    substr = expr.replaceAll('$', '');\n    ends = (substr.length !== expr.length);\n    expr = substr;\n    substr = expr.replaceAll('!', '');\n    if ((expr.length - substr.length) % 2) { // not\n        if (starts && ends) {\n            return s => !s.startsWith(substr) && !s.endsWith(substr);\n        }\n        if (starts) {\n            return s => !s.startsWith(substr);\n        }\n        if (ends) {\n            return s => !s.endsWith(substr);\n        }\n        return s => !s.includes(substr);\n    }\n    if (starts && ends) {\n        return s => s.startsWith(substr) && s.endsWith(substr);\n    }\n    if (starts) {\n        return s => s.startsWith(substr);\n    }\n    if (ends) {\n        return s => s.endsWith(substr);\n    }\n    return s => s.includes(substr);\n}\n\nmodule.exports = filter1_from_spec;\n",
            "markdown": "Creates a filtering function based on the following spec:\n\n1. Substrings are separated by `/`.\n2. Each substring may have special characters:\n   - `^`: Substring must appear at the beginning.\n   - `$`: Substring must appear at the end.\n   - `!`: Negates the condition (substring must not appear).\n"
        },
        {
            "id": "format_bytes",
            "name": "format_bytes",
            "file": "src/format_bytes.js",
            "require": "const format_bytes = require('@vbarbarosh/node-helpers/src/format_bytes');",
            "source_code": "/**\n * @link https://stackoverflow.com/a/18650828\n */\nfunction format_bytes(bytes)\n{\n    const sizes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB'];\n    if (typeof bytes !== 'number' || Number.isNaN(bytes)) {\n        return 'n/a';\n    }\n    if (!bytes) {\n        return '0KB';\n    }\n    if (bytes < 1024) {\n        return '1KB';\n    }\n    const i = Math.floor(Math.log(bytes) / Math.log(1024));\n    return `${(bytes / (1024 ** i)).toFixed(bytes > 1024*1024 ? 2 : 0)}${sizes[i]}`.replace(/\\.00/, '.0');\n}\n\nmodule.exports = format_bytes;\n\n// https://wiki.ubuntu.com/UnitsPolicy\n// > Applications must use SI standard for base-10 units:\n// >\n// > 1 kB = 1,000 bytes (Note: small k)\n// > 1 MB = 1,000 kB = 1,000,000 bytes\n// > 1 GB = 1,000 MB = 1,000,000 kB = 1,000,000,000 bytes\n// > 1 TB = 1,000 GB = 1,000,000 MB = 1,000,000,000 kB = 1,000,000,000,000 bytes\n",
            "markdown": null
        },
        {
            "id": "format_date",
            "name": "format_date",
            "file": "src/format_date.js",
            "require": "const format_date = require('@vbarbarosh/node-helpers/src/format_date');",
            "source_code": "function format_date(d)\n{\n    return d.getFullYear() + `/0${d.getMonth()+1}/0${d.getDate()} 0${d.getHours()}:0${d.getMinutes()}:0${d.getSeconds()}`.replace(/0(\\d\\d)/g, '$1');\n}\n\nmodule.exports = format_date;\n",
            "markdown": null
        },
        {
            "id": "format_date_fs",
            "name": "format_date_fs",
            "file": "src/format_date_fs.js",
            "require": "const format_date_fs = require('@vbarbarosh/node-helpers/src/format_date_fs');",
            "source_code": "function format_date_fs(d)\n{\n    const ymd = d.getFullYear() + dd(d.getMonth() + 1) + dd(d.getDate());\n    const hms = dd(d.getHours()) + dd(d.getMinutes()) + dd(d.getSeconds());\n    return ymd + '_' + hms;\n}\n\nfunction dd(v)\n{\n    return v > 9 ? `${v}` : `0${v}`;\n}\n\nmodule.exports = format_date_fs;\n",
            "markdown": null
        },
        {
            "id": "format_date_human",
            "name": "format_date_human",
            "file": "src/format_date_human.js",
            "require": "const format_date_human = require('@vbarbarosh/node-helpers/src/format_date_human');",
            "source_code": "function format_date_human(d)\n{\n    const ymd = d.getFullYear() + '/' + dd(d.getMonth() + 1) + '/' + dd(d.getDate());\n    const hms = dd(d.getHours()) + ':' + dd(d.getMinutes()) + ':' + dd(d.getSeconds());\n    return ymd + ' ' + hms;\n}\n\nfunction dd(v)\n{\n    return v > 9 ? `${v}` : `0${v}`;\n}\n\nmodule.exports = format_date_human;\n",
            "markdown": null
        },
        {
            "id": "format_date_ymd",
            "name": "format_date_ymd",
            "file": "src/format_date_ymd.js",
            "require": "const format_date_ymd = require('@vbarbarosh/node-helpers/src/format_date_ymd');",
            "source_code": "function format_date_ymd(d)\n{\n    return d.getFullYear() + `/0${d.getMonth()+1}/0${d.getDate()}`.replace(/0(\\d\\d)/g, '$1');\n}\n\nmodule.exports = format_date_ymd;\n",
            "markdown": null
        },
        {
            "id": "format_error_report",
            "name": "format_error_report",
            "file": "src/format_error_report.js",
            "require": "const format_error_report = require('@vbarbarosh/node-helpers/src/format_error_report');",
            "source_code": "const json_stringify_safe = require('./json_stringify_safe');\n\nfunction format_error_report(error)\n{\n    if (!error) {\n        return json_stringify_safe({error: error === undefined ? '---undefined---' : error});\n    }\n\n    if (error.response?.status && error.response?.statusText && error.response?.config) {\n        return fm_axios_response(error);\n    }\n\n    if (error.config) {\n        return fm_axios_config(error);\n    }\n\n    return json_stringify_safe({\n        code: error.code,\n        name: error.name,\n        message: error.message ?? 'n/a',\n        stack: error.stack && error.stack.split(/\\n\\s*/)\n    }, null, 4);\n}\n\nfunction fm_axios_response(error)\n{\n    return `\n${error.message ?? 'n/a'}\n\n--- REQUEST ---\n\n${(error.response.config.method||'').toUpperCase()} ${error.response.config.url}\n\n${JSON.stringify(error.response.config.headers||{}, null, 4).slice(1, -1).replace(/^\\s+|,$/mg, '').trim()}\n\n--- RESPONSE ---\n\n${error.response.status} ${error.response.statusText}\n\n${(error.response.data.toString()||'').slice(0, 10240) || 'n/a'}\n\n--- STACK ---\n\n${error.stack ? error.stack.split(/\\\\n\\\\s*/) : 'n/a'}\n`.trimStart();\n}\n\nfunction fm_axios_config(error)\n{\n    return `\n${error.message ?? 'n/a'}\n\n--- REQUEST ---\n\n${(error.config.method||'').toUpperCase()} ${error.config.url}\n\n${JSON.stringify(error.config.headers||{}, null, 4).slice(1, -1).replace(/^\\s+|,$/mg, '').trim()}\n\n--- STACK ---\n\n${error.stack ? error.stack.split(/\\\\n\\\\s*/) : 'n/a'}\n`.trimStart();\n}\n\nmodule.exports = format_error_report;\n",
            "markdown": null
        },
        {
            "id": "format_hrtime",
            "name": "format_hrtime",
            "file": "src/format_hrtime.js",
            "require": "const format_hrtime = require('@vbarbarosh/node-helpers/src/format_hrtime');",
            "source_code": "/**\n * Return a human-readable representation of hrtime (the return value from `process.hrtime(hrtime0)`).\n */\nfunction format_hrtime(hrtime, digits = 6)\n{\n    const [u, v] = hrtime; // process.hrtime(hrtime0)\n    return (u + v/1E9).toFixed(digits) + 's';\n}\n\nmodule.exports = format_hrtime;\n",
            "markdown": "Return a human-readable representation of hrtime (the return value from `process.hrtime(hrtime0)`).\n"
        },
        {
            "id": "format_kilo",
            "name": "format_kilo",
            "file": "src/format_kilo.js",
            "require": "const format_kilo = require('@vbarbarosh/node-helpers/src/format_kilo');",
            "source_code": "function format_kilo(num)\n{\n    const sizes = ['', 'K', 'M', 'G', 'T', 'P'];\n    if (typeof num !== 'number' || Number.isNaN(num)) {\n        return 'n/a';\n    }\n    if (!num) {\n        return '0';\n    }\n    if (num < 1000) {\n        return num.toFixed(0);\n    }\n    const i = parseInt(Math.floor(Math.log(num) / Math.log(1000)), 10);\n    return `${(num / (1000 ** i)).toFixed(2)}${sizes[i]}`;\n}\n\nmodule.exports = format_kilo;\n",
            "markdown": null
        },
        {
            "id": "format_ms",
            "name": "format_ms",
            "file": "src/format_ms.js",
            "require": "const format_ms = require('@vbarbarosh/node-helpers/src/format_ms');",
            "source_code": "const factorize_ms = require('./factorize_ms');\n\n/**\n * Format milliseconds\n */\nfunction format_ms(ms)\n{\n    if (!ms) {\n        ms = 0;\n    }\n\n    // 00:05\n    const [h, m, s] = factorize_ms(ms);\n    if (h) {\n        return `0${h}:0${m}:0${s}`.replace(/0+(?=\\d\\d)/g, '');\n    }\n    return `0${m}:0${s}`.replace(/0+(?=\\d\\d)/g, '');\n}\n\nmodule.exports = format_ms;\n",
            "markdown": null
        },
        {
            "id": "format_ms2",
            "name": "format_ms2",
            "file": "src/format_ms2.js",
            "require": "const format_ms2 = require('@vbarbarosh/node-helpers/src/format_ms2');",
            "source_code": "const factorize_ms = require('./factorize_ms');\n\n/**\n * Format milliseconds\n */\nfunction format_ms2(ms)\n{\n    if (!ms) {\n        ms = 0;\n    }\n\n    // 00:05.45\n    const [h, m, s, xx] = factorize_ms(ms);\n    if (h) {\n        return `0${h}:0${m}:0${s}.0${Math.round(xx/10)}`.replace(/0+(?=\\d\\d)/g, '');\n    }\n    return `0${m}:0${s}.0${Math.round(xx/10)}`.replace(/0+(?=\\d\\d)/g, '');\n}\n\nmodule.exports = format_ms2;\n",
            "markdown": null
        },
        {
            "id": "format_ms3",
            "name": "format_ms3",
            "file": "src/format_ms3.js",
            "require": "const format_ms3 = require('@vbarbarosh/node-helpers/src/format_ms3');",
            "source_code": "const factorize_ms = require('./factorize_ms');\n\n/**\n * Format milliseconds\n */\nfunction format_ms3(ms)\n{\n    if (!ms) {\n        ms = 0;\n    }\n\n    // 00:05.445\n    const [h, m, s, xx] = factorize_ms(ms);\n    if (h) {\n        return `0${h}:0${m}:0${s}.00${xx}`.replace(/0+(?=\\d\\d+[:.]|\\d\\d\\d)/g, '');\n    }\n    return `0${m}:0${s}.00${xx}`.replace(/0+(?=\\d\\d+[:.]|\\d\\d\\d)/g, '')\n}\n\nmodule.exports = format_ms3;\n",
            "markdown": null
        },
        {
            "id": "format_percents",
            "name": "format_percents",
            "file": "src/format_percents.js",
            "require": "const format_percents = require('@vbarbarosh/node-helpers/src/format_percents');",
            "source_code": "function format_percents(v)\n{\n    return (v*100).toFixed(2).replace(/^(0|100).00$/, '$1') + '%';\n}\n\nmodule.exports = format_percents;\n",
            "markdown": null
        },
        {
            "id": "format_progress_bytes",
            "name": "format_progress_bytes",
            "file": "src/format_progress_bytes.js",
            "require": "const format_progress_bytes = require('@vbarbarosh/node-helpers/src/format_progress_bytes');",
            "source_code": "const format_bytes = require('./format_bytes');\nconst format_percents = require('./format_percents');\nconst format_seconds = require('./format_seconds');\nconst is_num_gt = require('@vbarbarosh/type-helpers/src/is_num_gt');\n\nfunction format_progress_bytes({percents, total, done, rate, eta, duration})\n{\n    const bps = is_num_gt(rate, 0) ? `${format_bytes(rate)}/s` : '~';\n    if (done > total) {\n        return `${format_bytes(done)} at ${bps} duration=${format_seconds(duration)}`;\n    }\n    if (is_num_gt(total, 0)) {\n        const eta_str = is_num_gt(eta, 0) ? format_seconds(eta) : '~';\n        return `${format_percents(percents)} | ${format_bytes(done)} of ${format_bytes(total)} at ${bps} ETA ${eta_str} duration=${format_seconds(duration)}`;\n    }\n    if (is_num_gt(done, 0)) {\n        return `${format_bytes(done)} of ~ at ${bps} duration=${format_seconds(duration)}`;\n    }\n    if (is_num_gt(duration, 0)) {\n        return `~ duration=${format_seconds(duration)}`;\n    }\n    return '~';\n}\n\nmodule.exports = format_progress_bytes;\n",
            "markdown": null
        },
        {
            "id": "format_progress_kilo",
            "name": "format_progress_kilo",
            "file": "src/format_progress_kilo.js",
            "require": "const format_progress_kilo = require('@vbarbarosh/node-helpers/src/format_progress_kilo');",
            "source_code": "const format_kilo = require('./format_kilo');\nconst format_percents = require('./format_percents');\nconst format_seconds = require('./format_seconds');\nconst is_num_gt = require('@vbarbarosh/type-helpers/src/is_num_gt');\n\nfunction format_progress_kilo({percents, total, done, rate, eta, duration})\n{\n    const speed = is_num_gt(rate, 0) ? `${format_kilo(rate)}/s` : '~';\n    if (done > total) {\n        return `${format_kilo(done)} at ${speed} duration=${format_seconds(duration)}`;\n    }\n    if (is_num_gt(total, 0)) {\n        const eta_str = is_num_gt(eta, 0) ? format_seconds(eta) : '~';\n        return `${format_percents(percents)} | ${format_kilo(done)} of ${format_kilo(total)} at ${speed} ETA ${eta_str} duration=${format_seconds(duration)}`;\n    }\n    if (is_num_gt(done, 0)) {\n        return `${format_kilo(done)} of ~ at ${speed} duration=${format_seconds(duration)}`;\n    }\n    if (is_num_gt(duration, 0)) {\n        return `~ duration=${format_seconds(duration)}`;\n    }\n    return '~';\n}\n\nmodule.exports = format_progress_kilo;\n",
            "markdown": null
        },
        {
            "id": "format_seconds",
            "name": "format_seconds",
            "file": "src/format_seconds.js",
            "require": "const format_seconds = require('@vbarbarosh/node-helpers/src/format_seconds');",
            "source_code": "function format_seconds(seconds)\n{\n    const v = Math.abs(Math.trunc(seconds));\n    const hh = Math.floor(v / 60 / 60);\n    const mm = Math.floor(v / 60) % 60;\n    const ss = v % 60;\n    const tmp = `0${hh}:0${mm}:0${ss}`.replace(/0(\\d\\d)/g, '$1');\n    return (seconds <= -1) ? ('-' + tmp) : tmp;\n}\n\nmodule.exports = format_seconds;\n",
            "markdown": null
        },
        {
            "id": "format_thousands",
            "name": "format_thousands",
            "file": "src/format_thousands.js",
            "require": "const format_thousands = require('@vbarbarosh/node-helpers/src/format_thousands');",
            "source_code": "// https://stackoverflow.com/a/2901298\nfunction format_thousands(x)\n{\n    return x.toString().replace(/\\B(?<!\\.\\d*)(?=(\\d{3})+(?!\\d))/g, ',');\n}\n\nmodule.exports = format_thousands;\n",
            "markdown": null
        },
        {
            "id": "fs_append",
            "name": "fs_append",
            "file": "src/fs_append.js",
            "require": "const fs_append = require('@vbarbarosh/node-helpers/src/fs_append');",
            "source_code": "const fs = require('fs');\n\nfunction fs_append(file, data, options)\n{\n    return fs.promises.appendFile(file, data, options);\n}\n\nmodule.exports = fs_append;\n",
            "markdown": null
        },
        {
            "id": "fs_append_json",
            "name": "fs_append_json",
            "file": "src/fs_append_json.js",
            "require": "const fs_append_json = require('@vbarbarosh/node-helpers/src/fs_append_json');",
            "source_code": "const fs_append = require('./fs_append');\nconst json_stringify_stable = require('./json_stringify_stable');\n\nfunction fs_append_json(file, value)\n{\n    return fs_append(file, json_stringify_stable(value) + '\\n');\n}\n\nmodule.exports = fs_append_json;\n",
            "markdown": null
        },
        {
            "id": "fs_append_utf8",
            "name": "fs_append_utf8",
            "file": "src/fs_append_utf8.js",
            "require": "const fs_append_utf8 = require('@vbarbarosh/node-helpers/src/fs_append_utf8');",
            "source_code": "const fs = require('fs');\n\nfunction fs_append_utf8(file, text, options)\n{\n    return fs.promises.appendFile(file, text, options);\n}\n\nmodule.exports = fs_append_utf8;\n",
            "markdown": null
        },
        {
            "id": "fs_assert_file_exists",
            "name": "fs_assert_file_exists",
            "file": "src/fs_assert_file_exists.js",
            "require": "const fs_assert_file_exists = require('@vbarbarosh/node-helpers/src/fs_assert_file_exists');",
            "source_code": "const fs_fi = require('./fs_fi');\n\nasync function fs_assert_file_exists(file)\n{\n    const fi = await fs_fi(file);\n    if (!fi.isFile()) {\n        throw new Error(`Not a file: ${file}`);\n    }\n}\n\nmodule.exports = fs_assert_file_exists;\n",
            "markdown": null
        },
        {
            "id": "fs_assert_file_readable",
            "name": "fs_assert_file_readable",
            "file": "src/fs_assert_file_readable.js",
            "require": "const fs_assert_file_readable = require('@vbarbarosh/node-helpers/src/fs_assert_file_readable');",
            "source_code": "const fs_fi = require('./fs_fi');\n\nasync function fs_assert_file_readable(file)\n{\n    const fi = await fs_fi(file);\n    if (!fi.isFile()) {\n        throw new Error(`Not a file: ${file}`);\n    }\n    if (fi.mode & 0o111) {\n        throw new Error(`File is not readable by all: ${file}`);\n    }\n}\n\nmodule.exports = fs_assert_file_readable;\n",
            "markdown": null
        },
        {
            "id": "fs_copy",
            "name": "fs_copy",
            "file": "src/fs_copy.js",
            "require": "const fs_copy = require('@vbarbarosh/node-helpers/src/fs_copy');",
            "source_code": "const fs = require('fs');\n\nfunction fs_copy(src, dest, mode)\n{\n    return fs.promises.copyFile(src, dest, mode);\n}\n\nmodule.exports = fs_copy;\n",
            "markdown": null
        },
        {
            "id": "fs_copy_excl",
            "name": "fs_copy_excl",
            "file": "src/fs_copy_excl.js",
            "require": "const fs_copy_excl = require('@vbarbarosh/node-helpers/src/fs_copy_excl');",
            "source_code": "const fs = require('fs');\n\nfunction fs_copy_excl(src, dest)\n{\n    return fs.promises.copyFile(src, dest, fs.constants.COPYFILE_EXCL);\n}\n\nmodule.exports = fs_copy_excl;\n",
            "markdown": null
        },
        {
            "id": "fs_exists",
            "name": "fs_exists",
            "file": "src/fs_exists.js",
            "require": "const fs_exists = require('@vbarbarosh/node-helpers/src/fs_exists');",
            "source_code": "const fs = require('fs');\n\nasync function fs_exists(path)\n{\n    return new Promise(function (resolve) {\n        fs.access(path, error => resolve(!error));\n    });\n}\n\nmodule.exports = fs_exists;\n",
            "markdown": null
        },
        {
            "id": "fs_fclose",
            "name": "fs_fclose",
            "file": "src/fs_fclose.js",
            "require": "const fs_fclose = require('@vbarbarosh/node-helpers/src/fs_fclose');",
            "source_code": "const fs = require('fs');\n\nfunction fs_fclose(fp)\n{\n    return new Promise(function (resolve, reject) {\n        fs.close(fp, function (error) {\n            error ? reject(error) : resolve();\n        });\n    });\n}\n\nmodule.exports = fs_fclose;\n",
            "markdown": null
        },
        {
            "id": "fs_fi",
            "name": "fs_fi",
            "file": "src/fs_fi.js",
            "require": "const fs_fi = require('@vbarbarosh/node-helpers/src/fs_fi');",
            "source_code": "const fs_lstat = require('./fs_lstat');\nconst fs_path_basename = require('./fs_path_basename');\nconst fs_path_dirname = require('./fs_path_dirname');\nconst fs_path_resolve = require('./fs_path_resolve');\nconst fs_readlink = require('./fs_readlink');\n\nasync function fs_fi(pathname)\n{\n    const basename = fs_path_basename(pathname);\n    const fi = await fs_lstat(pathname);\n    fi.pathname = pathname;\n    fi.basename = basename;\n    flags(fi);\n    if (fi.isSymbolicLink()) {\n        const target = await fs_readlink(fi.pathname);\n        const target_pathname = fs_path_resolve(fs_path_dirname(pathname), target);\n        fi.target = target;\n        fi.target_fi = await fs_lstat(target_pathname);\n        fi.target_fi.pathname = target_pathname;\n        fi.target_fi.basename = fs_path_basename(target_pathname);\n        flags(fi.target_fi);\n    }\n    return fi;\n}\n\nfunction flags(fi)\n{\n    const tmp = [];\n    if (fi.isFile()) {\n        tmp.push('is_file');\n    }\n    if (fi.isDirectory()) {\n        tmp.push('is_directory');\n    }\n    if (fi.isBlockDevice()) {\n        tmp.push('is_block_device');\n    }\n    if (fi.isCharacterDevice()) {\n        tmp.push('is_character_device');\n    }\n    if (fi.isSymbolicLink()) {\n        tmp.push('is_symbolic_link');\n    }\n    if (fi.isFIFO()) {\n        tmp.push('is_fifo');\n    }\n    if (fi.isSocket()) {\n        tmp.push('is_socket');\n    }\n    fi.flags = tmp;\n    fi.flags_map = {};\n    tmp.forEach(key => fi.flags_map[key] = true);\n}\n\nmodule.exports = fs_fi;\n",
            "markdown": null
        },
        {
            "id": "fs_file_md5",
            "name": "fs_file_md5",
            "file": "src/fs_file_md5.js",
            "require": "const fs_file_md5 = require('@vbarbarosh/node-helpers/src/fs_file_md5');",
            "source_code": "const crypto = require('crypto');\nconst fs = require('fs');\n\nasync function fs_file_md5(file, encoding = 'hex')\n{\n    const md5 = crypto.createHash('md5');\n    const rs = fs.createReadStream(file);\n    await rs.forEach(v => md5.update(v));\n    return md5.digest(encoding);\n}\n\nmodule.exports = fs_file_md5;\n",
            "markdown": null
        },
        {
            "id": "fs_find",
            "name": "fs_find",
            "file": "src/fs_find.js",
            "require": "const fs_find = require('@vbarbarosh/node-helpers/src/fs_find');",
            "source_code": "const Promise = require('bluebird');\nconst fs_fi = require('./fs_fi');\nconst fs_path_resolve = require('./fs_path_resolve');\nconst fs_readdir = require('./fs_readdir');\n\nasync function fs_find(pathname = '.')\n{\n    const fi = await fs_fi(fs_path_resolve(pathname));\n    if (fi.isDirectory()) {\n        const names = await fs_readdir(pathname);\n        const rows = await Promise.all(names.map(v => fs_find(fs_path_resolve(pathname, v))));\n        const out = [fi];\n        for (let i = 0, end = rows.length; i < end; ++i) {\n            out.push(...rows[i]);\n        }\n        return out;\n    }\n    return [fi];\n}\n\nmodule.exports = fs_find;\n",
            "markdown": null
        },
        {
            "id": "fs_fopen",
            "name": "fs_fopen",
            "file": "src/fs_fopen.js",
            "require": "const fs_fopen = require('@vbarbarosh/node-helpers/src/fs_fopen');",
            "source_code": "const fs = require('fs');\n\nfunction fs_fopen(file, flags = 'r', mode = 0o666)\n{\n    return new Promise(function (resolve, reject) {\n        fs.open(file, flags, mode, function (error, out) {\n            error ? reject(error) : resolve(out);\n        });\n    });\n}\n\nmodule.exports = fs_fopen;\n",
            "markdown": null
        },
        {
            "id": "fs_fopen_update",
            "name": "fs_fopen_update",
            "file": "src/fs_fopen_update.js",
            "require": "const fs_fopen_update = require('@vbarbarosh/node-helpers/src/fs_fopen_update');",
            "source_code": "const fs_fopen = require('./fs_fopen');\n\n/**\n * The main use case is uploading files in chunks.\n * Each time a chunk is uploaded, update the target file.\n * By the end, you will have a ready-to-use file.\n */\nasync function fs_fopen_update(pathname)\n{\n    try {\n        // Open a file for updating...\n        return await fs_fopen(pathname, 'r+');\n    }\n    catch (error) {\n        if (error.code !== 'ENOENT') {\n            throw error;\n        }\n    }\n\n    try {\n        // There is no such file; try to create it...\n        return await fs_fopen(pathname, 'wx');\n    }\n    catch (error) {\n        if (error.code !== 'EEXIST') {\n            throw error;\n        }\n    }\n\n    // Another process might have already created it; try opening it for updating\n    return fs_fopen(pathname, 'r+');\n}\n\nmodule.exports = fs_fopen_update;\n",
            "markdown": "The main use case is uploading files in chunks.\n\nEach time a chunk is uploaded, update the target file.\n\nBy the end, you will have a ready-to-use file.\n"
        },
        {
            "id": "fs_fread",
            "name": "fs_fread",
            "file": "src/fs_fread.js",
            "require": "const fs_fread = require('@vbarbarosh/node-helpers/src/fs_fread');",
            "source_code": "const fs = require('fs');\n\n/**\n * The main use case is reading chunks of data from a file.\n */\nasync function fs_fread(fp, buffer, offset = null, size = buffer.length)\n{\n    const {bytesRead} = await new Promise(function (resolve, reject) {\n        fs.read(fp, buffer, 0, size, offset, function (error, out) {\n            error ? reject(error) : resolve(out);\n        });\n    });\n    return (bytesRead === buffer.length) ? buffer : buffer.subarray(0, bytesRead);\n}\n\nmodule.exports = fs_fread;\n",
            "markdown": null
        },
        {
            "id": "fs_fsize",
            "name": "fs_fsize",
            "file": "src/fs_fsize.js",
            "require": "const fs_fsize = require('@vbarbarosh/node-helpers/src/fs_fsize');",
            "source_code": "const fs_fstat = require('./fs_fstat');\n\nfunction fs_fsize(fp)\n{\n    return fs_fstat(fp).then(v => v.size);\n}\n\nmodule.exports = fs_fsize;\n",
            "markdown": null
        },
        {
            "id": "fs_fstat",
            "name": "fs_fstat",
            "file": "src/fs_fstat.js",
            "require": "const fs_fstat = require('@vbarbarosh/node-helpers/src/fs_fstat');",
            "source_code": "const fs = require('fs');\n\nfunction fs_fstat(fp, options = {})\n{\n    return new Promise(function (resolve, reject) {\n        fs.fstat(fp, options, function (error, out) {\n            error ? reject(error) : resolve(out);\n        });\n    })\n}\n\nmodule.exports = fs_fstat;\n",
            "markdown": null
        },
        {
            "id": "fs_fwrite",
            "name": "fs_fwrite",
            "file": "src/fs_fwrite.js",
            "require": "const fs_fwrite = require('@vbarbarosh/node-helpers/src/fs_fwrite');",
            "source_code": "const fs = require('fs');\n\n/**\n * The main use case is writing chunks of data to a file.\n */\nasync function fs_fwrite(fp, buffer, offset = null)\n{\n    const {bytesWritten} = await new Promise(function (resolve, reject) {\n        fs.write(fp, buffer, 0, buffer.length, offset, function (error, out) {\n            error ? reject(error) : resolve(out);\n        });\n    });\n    return bytesWritten;\n}\n\nmodule.exports = fs_fwrite;\n",
            "markdown": null
        },
        {
            "id": "fs_list",
            "name": "fs_list",
            "file": "src/fs_list.js",
            "require": "const fs_list = require('@vbarbarosh/node-helpers/src/fs_list');",
            "source_code": "const Promise = require('bluebird');\nconst fs_fi = require('./fs_fi');\nconst fs_path_join = require('./fs_path_join');\nconst fs_readdir = require('./fs_readdir');\n\nasync function fs_list(pathname = '.')\n{\n    const fi = await fs_fi(pathname);\n    if (fi.isDirectory()) {\n        const names = await fs_readdir(pathname);\n        return Promise.all(names.map(v => fs_fi(fs_path_join(pathname, v))));\n    }\n    return [fi];\n}\n\nmodule.exports = fs_list;\n",
            "markdown": null
        },
        {
            "id": "fs_list_deep",
            "name": "fs_list_deep",
            "file": "src/fs_list_deep.js",
            "require": "const fs_list_deep = require('@vbarbarosh/node-helpers/src/fs_list_deep');",
            "source_code": "const fs_fi = require('./fs_fi');\nconst fs_path_join = require('./fs_path_join');\nconst fs_readdir = require('./fs_readdir');\n\nasync function fs_list_deep(path = '.')\n{\n    const out = [];\n    const queue = [path];\n    while (queue.length) {\n        const fi = await fs_fi(queue.pop());\n        out.push(fi);\n        if (fi.isDirectory()) {\n            const names = await fs_readdir(fi.pathname);\n            queue.push(...names.map(v => fs_path_join(fi.pathname, v)));\n        }\n    }\n    return out;\n}\n\nmodule.exports = fs_list_deep;\n",
            "markdown": null
        },
        {
            "id": "fs_ls",
            "name": "fs_ls",
            "file": "src/fs_ls.js",
            "require": "const fs_ls = require('@vbarbarosh/node-helpers/src/fs_ls');",
            "source_code": "const Promise = require('bluebird');\nconst fs_fi = require('./fs_fi');\nconst fs_path_join = require('./fs_path_join');\nconst fs_readdir = require('./fs_readdir');\n\n/**\n * @deprecated Deprecated in favor or fs_list\n */\nasync function fs_ls(pathname = '.')\n{\n    const fi = await fs_fi(pathname);\n    if (fi.isDirectory()) {\n        const names = await fs_readdir(pathname);\n        return Promise.all(names.map(v => fs_fi(fs_path_join(pathname, v))));\n    }\n    return [fi];\n}\n\nmodule.exports = fs_ls;\n",
            "markdown": null
        },
        {
            "id": "fs_lsr",
            "name": "fs_lsr",
            "file": "src/fs_lsr.js",
            "require": "const fs_lsr = require('@vbarbarosh/node-helpers/src/fs_lsr');",
            "source_code": "const Promise = require('bluebird');\nconst fs_fi = require('./fs_fi');\nconst fs_path_join = require('./fs_path_join');\nconst fs_readdir = require('./fs_readdir');\n\nasync function fs_lsr(pathname = '.')\n{\n    const fi = await fs_fi(pathname);\n    const ret = [fi];\n    if (fi.isDirectory()) {\n        fi.content_size = 0;\n        const names = await fs_readdir(pathname);\n        const all = await Promise.all(names.map(v => fs_lsr(fs_path_join(pathname, v))));\n        for (let i = 0, end = all.length; i < end; ++i) {\n            const rows = all[i];\n            ret.push(...rows);\n            fi.content_size += rows[0].content_size;\n        }\n    }\n    else {\n        fi.content_size = fi.isFile() ? fi.size : 0;\n    }\n    return ret;\n}\n\nmodule.exports = fs_lsr;\n",
            "markdown": null
        },
        {
            "id": "fs_lstat",
            "name": "fs_lstat",
            "file": "src/fs_lstat.js",
            "require": "const fs_lstat = require('@vbarbarosh/node-helpers/src/fs_lstat');",
            "source_code": "const fs = require('fs');\n\nfunction fs_lstat(path, options)\n{\n    return fs.promises.lstat(path, options);\n}\n\nmodule.exports = fs_lstat;\n",
            "markdown": null
        },
        {
            "id": "fs_mkdir",
            "name": "fs_mkdir",
            "file": "src/fs_mkdir.js",
            "require": "const fs_mkdir = require('@vbarbarosh/node-helpers/src/fs_mkdir');",
            "source_code": "const fs = require('fs');\n\nfunction fs_mkdir(path, options)\n{\n    return fs.promises.mkdir(path, options);\n}\n\nmodule.exports = fs_mkdir;\n",
            "markdown": null
        },
        {
            "id": "fs_mkdirp",
            "name": "fs_mkdirp",
            "file": "src/fs_mkdirp.js",
            "require": "const fs_mkdirp = require('@vbarbarosh/node-helpers/src/fs_mkdirp');",
            "source_code": "const fs_exists = require('./fs_exists');\nconst fs_mkdir = require('./fs_mkdir');\nconst fs_path_dirname = require('./fs_path_dirname');\n\nasync function fs_mkdirp(pathname)\n{\n    const parents = [];\n\n    for (let p = pathname; p && p !== '/'; p = fs_path_dirname(p)) {\n        if (await fs_exists(p)) {\n            break;\n        }\n        parents.push(p);\n    }\n\n    while (parents.length) {\n        try {\n            await fs_mkdir(parents.pop());\n        }\n        catch (error) {\n            // Error: EEXIST: file already exists, mkdir [...]\n            if (error.code === 'EEXIST') {\n                // Exiting here is not correct. When two processes are running in parallel,\n                // one tries to create `a/b/c` and another `a`. When second process creates\n                // `a`, the first process will get `EEXIST` and stops (break) creating any\n                // nested directories, which is not correct.\n                // break;\n                continue;\n            }\n            throw error;\n        }\n    }\n\n    return pathname;\n}\n\nmodule.exports = fs_mkdirp;\n",
            "markdown": null
        },
        {
            "id": "fs_path_basename",
            "name": "fs_path_basename",
            "file": "src/fs_path_basename.js",
            "require": "const fs_path_basename = require('@vbarbarosh/node-helpers/src/fs_path_basename');",
            "source_code": "const path = require('path');\n\nfunction fs_path_basename(p)\n{\n    return path.basename(p);\n}\n\nmodule.exports = fs_path_basename;\n",
            "markdown": null
        },
        {
            "id": "fs_path_dirname",
            "name": "fs_path_dirname",
            "file": "src/fs_path_dirname.js",
            "require": "const fs_path_dirname = require('@vbarbarosh/node-helpers/src/fs_path_dirname');",
            "source_code": "const path = require('path');\n\nfunction fs_path_dirname(p)\n{\n    return path.dirname(p);\n}\n\nmodule.exports = fs_path_dirname;\n",
            "markdown": null
        },
        {
            "id": "fs_path_extname",
            "name": "fs_path_extname",
            "file": "src/fs_path_extname.js",
            "require": "const fs_path_extname = require('@vbarbarosh/node-helpers/src/fs_path_extname');",
            "source_code": "const path = require('path');\n\nfunction fs_path_extname(p)\n{\n    return path.extname(p);\n}\n\n// function extname(s)\n// {\n//     const i = s.lastIndexOf('.');\n//     return (i > 0) ? s.slice(i) : null;\n// }\n\nmodule.exports = fs_path_extname;\n",
            "markdown": null
        },
        {
            "id": "fs_path_join",
            "name": "fs_path_join",
            "file": "src/fs_path_join.js",
            "require": "const fs_path_join = require('@vbarbarosh/node-helpers/src/fs_path_join');",
            "source_code": "const path = require('path');\n\nfunction fs_path_join(...parts)\n{\n    return path.join(...parts);\n}\n\nmodule.exports = fs_path_join;\n",
            "markdown": null
        },
        {
            "id": "fs_path_relative",
            "name": "fs_path_relative",
            "file": "src/fs_path_relative.js",
            "require": "const fs_path_relative = require('@vbarbarosh/node-helpers/src/fs_path_relative');",
            "source_code": "const path = require('path');\n\nfunction fs_path_relative(from, to)\n{\n    return path.relative(from, to);\n}\n\nmodule.exports = fs_path_relative;\n",
            "markdown": null
        },
        {
            "id": "fs_path_resolve",
            "name": "fs_path_resolve",
            "file": "src/fs_path_resolve.js",
            "require": "const fs_path_resolve = require('@vbarbarosh/node-helpers/src/fs_path_resolve');",
            "source_code": "const path = require('path');\n\nfunction fs_path_resolve(...parts)\n{\n    return path.resolve(...parts);\n}\n\nmodule.exports = fs_path_resolve;\n",
            "markdown": null
        },
        {
            "id": "fs_path_tempdir",
            "name": "fs_path_tempdir",
            "file": "src/fs_path_tempdir.js",
            "require": "const fs_path_tempdir = require('@vbarbarosh/node-helpers/src/fs_path_tempdir');",
            "source_code": "const os = require('os');\n\nfunction fs_path_tempdir()\n{\n    return os.tmpdir();\n}\n\nmodule.exports = fs_path_tempdir;\n",
            "markdown": null
        },
        {
            "id": "fs_path_untildify",
            "name": "fs_path_untildify",
            "file": "src/fs_path_untildify.js",
            "require": "const fs_path_untildify = require('@vbarbarosh/node-helpers/src/fs_path_untildify');",
            "source_code": "const os = require('os');\nconst homedir = os.homedir();\n\n/**\n * @link https://github.com/sindresorhus/untildify/blob/a901e25ef782d93df1eba04ed48f56c79d157c74/index.js\n */\nfunction fs_path_untildify(path)\n{\n    return homedir ? path.replace(/^~(?=$|\\/|\\\\)/, homedir) : path;\n}\n\nmodule.exports = fs_path_untildify;\n",
            "markdown": null
        },
        {
            "id": "fs_read",
            "name": "fs_read",
            "file": "src/fs_read.js",
            "require": "const fs_read = require('@vbarbarosh/node-helpers/src/fs_read');",
            "source_code": "const fs = require('fs');\n\nfunction fs_read(path, options)\n{\n    return fs.promises.readFile(path, options);\n}\n\nmodule.exports = fs_read;\n",
            "markdown": null
        },
        {
            "id": "fs_read_buffer",
            "name": "fs_read_buffer",
            "file": "src/fs_read_buffer.js",
            "require": "const fs_read_buffer = require('@vbarbarosh/node-helpers/src/fs_read_buffer');",
            "source_code": "const fs_read = require('./fs_read');\n\n/**\n * Read the entire contents of a file into a buffer.\n */\nfunction fs_read_buffer(file)\n{\n    return fs_read(file);\n}\n\nmodule.exports = fs_read_buffer;\n",
            "markdown": null
        },
        {
            "id": "fs_read_json",
            "name": "fs_read_json",
            "file": "src/fs_read_json.js",
            "require": "const fs_read_json = require('@vbarbarosh/node-helpers/src/fs_read_json');",
            "source_code": "const fs_read = require('./fs_read');\n\n// XXX Should support catchReturn, e.g.\n//     fs_read_json(file).catchReturn(default_value)\nfunction fs_read_json(file)\n{\n    return fs_read(file, {encoding: 'utf8'}).then(JSON.parse);\n}\n\nmodule.exports = fs_read_json;\n",
            "markdown": null
        },
        {
            "id": "fs_read_lines",
            "name": "fs_read_lines",
            "file": "src/fs_read_lines.js",
            "require": "const fs_read_lines = require('@vbarbarosh/node-helpers/src/fs_read_lines');",
            "source_code": "const fs_read = require('./fs_read');\n\n// XXX Should support catchReturn, e.g.\n//     fs_read_lines(file).catchReturn(default_value)\nfunction fs_read_lines(file)\n{\n    return fs_read(file, {encoding: 'utf8'}).then(v => v.split('\\n'));\n}\n\nmodule.exports = fs_read_lines;\n",
            "markdown": null
        },
        {
            "id": "fs_read_stream",
            "name": "fs_read_stream",
            "file": "src/fs_read_stream.js",
            "require": "const fs_read_stream = require('@vbarbarosh/node-helpers/src/fs_read_stream');",
            "source_code": "const fs = require('fs');\n\nfunction fs_read_stream(path, options)\n{\n    return fs.createReadStream(path, options);\n}\n\nmodule.exports = fs_read_stream;\n",
            "markdown": null
        },
        {
            "id": "fs_read_utf8",
            "name": "fs_read_utf8",
            "file": "src/fs_read_utf8.js",
            "require": "const fs_read_utf8 = require('@vbarbarosh/node-helpers/src/fs_read_utf8');",
            "source_code": "const fs_read = require('./fs_read');\n\n/**\n * Read the entire contents of a file into a UTF-8 encoded string.\n */\nfunction fs_read_utf8(file)\n{\n    return fs_read(file, {encoding: 'utf8'});\n}\n\nmodule.exports = fs_read_utf8;\n",
            "markdown": null
        },
        {
            "id": "fs_readdir",
            "name": "fs_readdir",
            "file": "src/fs_readdir.js",
            "require": "const fs_readdir = require('@vbarbarosh/node-helpers/src/fs_readdir');",
            "source_code": "const fs = require('fs');\n\nfunction fs_readdir(path, options)\n{\n    return fs.promises.readdir(path, options);\n}\n\nmodule.exports = fs_readdir;\n",
            "markdown": null
        },
        {
            "id": "fs_readlink",
            "name": "fs_readlink",
            "file": "src/fs_readlink.js",
            "require": "const fs_readlink = require('@vbarbarosh/node-helpers/src/fs_readlink');",
            "source_code": "const fs = require('fs');\nconst util = require('util');\n\n// https://nodejs.org/api/util.html#util_util_promisify_original\nmodule.exports = util.promisify(fs.readlink);\n",
            "markdown": null
        },
        {
            "id": "fs_rename",
            "name": "fs_rename",
            "file": "src/fs_rename.js",
            "require": "const fs_rename = require('@vbarbarosh/node-helpers/src/fs_rename');",
            "source_code": "const fs = require('fs');\nconst util = require('util');\n\n// https://nodejs.org/api/util.html#util_util_promisify_original\nmodule.exports = util.promisify(fs.rename);\n",
            "markdown": null
        },
        {
            "id": "fs_rm",
            "name": "fs_rm",
            "file": "src/fs_rm.js",
            "require": "const fs_rm = require('@vbarbarosh/node-helpers/src/fs_rm');",
            "source_code": "const fs = require('fs');\n\n/**\n * Remove a file\n */\nfunction fs_rm(path)\n{\n    return fs.promises.unlink(path);\n}\n\nmodule.exports = fs_rm;\n",
            "markdown": null
        },
        {
            "id": "fs_rmdir",
            "name": "fs_rmdir",
            "file": "src/fs_rmdir.js",
            "require": "const fs_rmdir = require('@vbarbarosh/node-helpers/src/fs_rmdir');",
            "source_code": "const fs = require('fs');\n\nfunction fs_rmdir(path)\n{\n    return fs.promises.rmdir(path);\n}\n\nmodule.exports = fs_rmdir;\n",
            "markdown": null
        },
        {
            "id": "fs_rmf",
            "name": "fs_rmf",
            "file": "src/fs_rmf.js",
            "require": "const fs_rmf = require('@vbarbarosh/node-helpers/src/fs_rmf');",
            "source_code": "const fs_rm = require('./fs_rm');\n\n/**\n * Remove the file if it exists.\n */\nasync function fs_rmf(path)\n{\n    try {\n        await fs_rm(path);\n    }\n    catch (error) {\n        if (error.code !== 'ENOENT') {\n            throw error;\n        }\n    }\n}\n\nmodule.exports = fs_rmf;\n",
            "markdown": null
        },
        {
            "id": "fs_rmrf",
            "name": "fs_rmrf",
            "file": "src/fs_rmrf.js",
            "require": "const fs_rmrf = require('@vbarbarosh/node-helpers/src/fs_rmrf');",
            "source_code": "const Promise = require('bluebird');\nconst fs_lstat = require('./fs_lstat');\nconst fs_path_join = require('./fs_path_join');\nconst fs_readdir = require('./fs_readdir');\nconst fs_rm = require('./fs_rm');\nconst fs_rmdir = require('./fs_rmdir');\nconst ignore = require('./ignore');\n\n/**\n * Remove a file or directory, along with all nested files and directories, recursively.\n */\nasync function fs_rmrf(path, progress = ignore)\n{\n    const lstat = await fs_lstat(path).catch(() => null);\n    if (lstat === null) {\n        return;\n    }\n\n    if (lstat.isDirectory()) {\n        const names = await fs_readdir(path);\n        await Promise.all(names.map(v => fs_rmrf(fs_path_join(path, v), progress)));\n        progress('rmdir', path);\n        await fs_rmdir(path);\n    }\n    else {\n        progress('rm', path);\n        await fs_rm(path);\n    }\n}\n\nmodule.exports = fs_rmrf;\n",
            "markdown": null
        },
        {
            "id": "fs_size",
            "name": "fs_size",
            "file": "src/fs_size.js",
            "require": "const fs_size = require('@vbarbarosh/node-helpers/src/fs_size');",
            "source_code": "const fs_stat = require('./fs_stat');\n\nasync function fs_size(file)\n{\n    const stat = await fs_stat(file);\n    return stat.size;\n}\n\nmodule.exports = fs_size;\n",
            "markdown": null
        },
        {
            "id": "fs_size_enoent",
            "name": "fs_size_enoent",
            "file": "src/fs_size_enoent.js",
            "require": "const fs_size_enoent = require('@vbarbarosh/node-helpers/src/fs_size_enoent');",
            "source_code": "const fs = require('fs');\n\n/**\n * Returns the size of a file, or 0 if the file is not present.\n * It was created for cases when you need to resume a download.\n */\nasync function fs_size_enoent(path)\n{\n    try {\n        const stat = await fs.promises.stat(path);\n        return stat.size;\n    }\n    catch (error) {\n        if (error.code === 'ENOENT') {\n            return 0;\n        }\n        throw error;\n    }\n}\n\nmodule.exports = fs_size_enoent;\n",
            "markdown": "Returns the size of a file, or 0 if the file is not present.\n\nIt was created for cases when you need to resume a download.\n"
        },
        {
            "id": "fs_stat",
            "name": "fs_stat",
            "file": "src/fs_stat.js",
            "require": "const fs_stat = require('@vbarbarosh/node-helpers/src/fs_stat');",
            "source_code": "const fs = require('fs');\n\nfunction fs_stat(path, options = {})\n{\n    return fs.promises.stat(path, options);\n}\n\nmodule.exports = fs_stat;\n",
            "markdown": null
        },
        {
            "id": "fs_tempdir",
            "name": "fs_tempdir",
            "file": "src/fs_tempdir.js",
            "require": "const fs_tempdir = require('@vbarbarosh/node-helpers/src/fs_tempdir');",
            "source_code": "const fs = require('fs');\nconst fs_path_resolve = require('./fs_path_resolve');\nconst fs_path_tempdir = require('./fs_path_tempdir');\nconst fs_rmrf = require('./fs_rmrf');\nconst util = require('util');\n\n// https://nodejs.org/api/util.html#util_util_promisify_original\nconst mkdtemp = util.promisify(fs.mkdtemp);\n\n// * https://www.cons.org/cracauer/sigint.html from https://stackoverflow.com/q/14031763/1478566\n// * http://www.tldp.org/LDP/abs/html/exitcodes.html from https://stackoverflow.com/q/14031763/1478566\n// * https://www.exratione.com/2013/05/die-child-process-die/\n\nasync function fs_tempdir(fn)\n{\n    process.on('SIGINT', sigint);\n\n    let d = null, out;\n    try {\n        d = await mkdtemp(fs_path_resolve(fs_path_tempdir(), 'vbtemp'));\n        out = await fn(d);\n    }\n    finally {\n        await clean();\n    }\n    return out;\n\n    async function clean() {\n        process.removeListener('SIGINT', sigint);\n        if (d) {\n            await fs_rmrf(d);\n        }\n    }\n\n    async function sigint() {\n        await clean().catch(function () {/* ignore */});\n        // https://stackoverflow.com/questions/14031763/doing-a-cleanup-action-just-before-node-js-exits#comment68567869_21947851\n        process.kill(process.pid, 'SIGINT');\n    }\n}\n\nmodule.exports = fs_tempdir;\n",
            "markdown": "```js\nawait fs_tempdir(async function (d) {\n    await fs_write(`${d}/input.txt`, 'hello');\n    await shell(['ls', '-alh'], {cwd: d});\n});\n```\n"
        },
        {
            "id": "fs_touch",
            "name": "fs_touch",
            "file": "src/fs_touch.js",
            "require": "const fs_touch = require('@vbarbarosh/node-helpers/src/fs_touch');",
            "source_code": "const fs = require('fs');\n\nfunction fs_touch(file)\n{\n    return new Promise(function (resolve, reject) {\n        fs.open(file, 'a', function (error, fd) {\n            if (error) {\n                if (error.code === 'EISDIR') {\n                    reject(new Error(`Cannot touch a directory: ${file}`));\n                }\n                else {\n                    reject(error);\n                }\n                return;\n            }\n            fs.close(fd, function (error) {\n                if (error) {\n                    reject(error);\n                    return;\n                }\n                const now = new Date();\n                fs.utimes(file, now, now, function (error) {\n                    error ? reject(error) : resolve();\n                });\n            });\n        });\n    });\n}\n\nmodule.exports = fs_touch;\n",
            "markdown": null
        },
        {
            "id": "fs_write",
            "name": "fs_write",
            "file": "src/fs_write.js",
            "require": "const fs_write = require('@vbarbarosh/node-helpers/src/fs_write');",
            "source_code": "const fs = require('fs');\n\nfunction fs_write(file, data, options)\n{\n    return fs.promises.writeFile(file, data, options);\n}\n\nmodule.exports = fs_write;\n",
            "markdown": null
        },
        {
            "id": "fs_write_json",
            "name": "fs_write_json",
            "file": "src/fs_write_json.js",
            "require": "const fs_write_json = require('@vbarbarosh/node-helpers/src/fs_write_json');",
            "source_code": "const fs = require('fs');\n\nfunction fs_write_json(file, data)\n{\n    return fs.promises.writeFile(file, JSON.stringify(data, null, 4));\n}\n\nmodule.exports = fs_write_json;\n",
            "markdown": null
        },
        {
            "id": "fs_write_stream",
            "name": "fs_write_stream",
            "file": "src/fs_write_stream.js",
            "require": "const fs_write_stream = require('@vbarbarosh/node-helpers/src/fs_write_stream');",
            "source_code": "const fs = require('fs');\n\nfunction fs_write_stream(path, options)\n{\n    return fs.createWriteStream(path, options);\n}\n\nmodule.exports = fs_write_stream;\n",
            "markdown": null
        },
        {
            "id": "gettype",
            "name": "gettype",
            "file": "src/gettype.js",
            "require": "const gettype = require('@vbarbarosh/node-helpers/src/gettype');",
            "source_code": "const const_type = require('./const_type');\n\n/**\n * @similar https://github.com/locutusjs/locutus/tree/master/src/php/var\n */\nfunction gettype(value)\n{\n    if (value === null) {\n        return const_type.null;\n    }\n    if (Array.isArray(value)) {\n        return const_type.array;\n    }\n    if (Number.isNaN(value)) {\n        return const_type.nan;\n    }\n    if (value === Number.NEGATIVE_INFINITY) {\n        return const_type.neg_inf;\n    }\n    if (value === Number.POSITIVE_INFINITY) {\n        return const_type.pos_inf;\n    }\n    return typeof value;\n}\n\nmodule.exports = gettype;\n",
            "markdown": null
        },
        {
            "id": "http_delete",
            "name": "http_delete",
            "file": "src/http_delete.js",
            "require": "const http_delete = require('@vbarbarosh/node-helpers/src/http_delete');",
            "source_code": "const axios = require('axios');\n\nfunction http_delete(url, options)\n{\n    return axios.delete(url, {responseType: 'json', ...options}).then(v => v.data);\n}\n\nmodule.exports = http_delete;\n",
            "markdown": null
        },
        {
            "id": "http_get_blob",
            "name": "http_get_blob",
            "file": "src/http_get_blob.js",
            "require": "const http_get_blob = require('@vbarbarosh/node-helpers/src/http_get_blob');",
            "source_code": "const axios = require('axios');\n\nfunction http_get_blob(url, options)\n{\n    return axios.get(url, {responseType: 'blob', ...options}).then(v => v.data);\n}\n\nmodule.exports = http_get_blob;\n",
            "markdown": null
        },
        {
            "id": "http_get_buffer",
            "name": "http_get_buffer",
            "file": "src/http_get_buffer.js",
            "require": "const http_get_buffer = require('@vbarbarosh/node-helpers/src/http_get_buffer');",
            "source_code": "const axios = require('axios');\n\nfunction http_get_buffer(url, options)\n{\n    return axios.get(url, {responseType: 'arraybuffer', ...options}).then(v => v.data);\n}\n\nmodule.exports = http_get_buffer;\n",
            "markdown": null
        },
        {
            "id": "http_get_file",
            "name": "http_get_file",
            "file": "src/http_get_file.js",
            "require": "const http_get_file = require('@vbarbarosh/node-helpers/src/http_get_file');",
            "source_code": "const axios = require('axios');\nconst fs = require('fs');\nconst stream = require('stream');\nconst util = require('util');\n\nconst stream_finished = util.promisify(stream.finished);\n\n// https://stackoverflow.com/a/61269447\nfunction http_get_file(url, out_file, options)\n{\n    const ws = fs.createWriteStream(out_file);\n    return axios.get(url, {responseType: 'stream', ...options}).then(function (response) {\n        return stream_finished(response.data.pipe(ws));\n    });\n}\n\nmodule.exports = http_get_file;\n",
            "markdown": null
        },
        {
            "id": "http_get_json",
            "name": "http_get_json",
            "file": "src/http_get_json.js",
            "require": "const http_get_json = require('@vbarbarosh/node-helpers/src/http_get_json');",
            "source_code": "const axios = require('axios');\n\nfunction http_get_json(url, options)\n{\n    return axios.get(url, {responseType: 'json', ...options}).then(v => v.data);\n}\n\nmodule.exports = http_get_json;\n",
            "markdown": null
        },
        {
            "id": "http_get_stream",
            "name": "http_get_stream",
            "file": "src/http_get_stream.js",
            "require": "const http_get_stream = require('@vbarbarosh/node-helpers/src/http_get_stream');",
            "source_code": "const axios = require('axios');\nconst make_int = require('@vbarbarosh/type-helpers/src/make_int');\n\nasync function http_get_stream(url, options)\n{\n    const res = await axios.get(url, {responseType: 'stream', ...options});\n    const out = res.data;\n    out.headers = res.headers;\n    out.total = make_int(res.headers['content-length'], null, 0);\n    return out;\n}\n\nmodule.exports = http_get_stream;\n",
            "markdown": null
        },
        {
            "id": "http_get_stream_range",
            "name": "http_get_stream_range",
            "file": "src/http_get_stream_range.js",
            "require": "const http_get_stream_range = require('@vbarbarosh/node-helpers/src/http_get_stream_range');",
            "source_code": "const axios = require('axios');\nconst format_thousands = require('./format_thousands');\nconst parse_http_content_range = require('./parse_http_content_range');\n\nasync function http_get_stream_range(url, first, last)\n{\n    const a = Number.isInteger(first) ? first : '';\n    const b = Number.isInteger(last) ? last : '';\n    const headers = {Range: `bytes=${a}-${b}`};\n    const res = await axios.get(url, {responseType: 'stream', headers});\n    const out = res.data;\n    out.headers = res.headers;\n    if (res.headers['content-range']) {\n        out.content_range = parse_http_content_range(res.headers['content-range']);\n    }\n    else {\n        const len = res.headers['content-length'];\n        out.content_range = parse_http_content_range(`${res.headers['accept-ranges']} 0-${len}/${len}`);\n    }\n    if (a && out.content_range.first !== a) {\n        out.destroy(new Error(`First byte of a returned range (${format_thousands(out.content_range.first)}) is not as expected: [${format_thousands(a)}]`));\n    }\n    else if (b && out.content_range.last !== b) {\n        out.destroy(new Error(`Last byte of a returned range (${format_thousands(out.content_range.last)}) is not as expected: [${format_thousands(b)}]`));\n    }\n    out.total = out.content_range.total;\n    return out;\n}\n\nmodule.exports = http_get_stream_range;\n",
            "markdown": null
        },
        {
            "id": "http_get_utf8",
            "name": "http_get_utf8",
            "file": "src/http_get_utf8.js",
            "require": "const http_get_utf8 = require('@vbarbarosh/node-helpers/src/http_get_utf8');",
            "source_code": "const axios = require('axios');\n\nfunction http_get_utf8(url, options)\n{\n    return axios.get(url, {responseType: 'text', responseEncoding: 'utf8', ...options}).then(v => v.data);\n}\n\nmodule.exports = http_get_utf8;\n",
            "markdown": null
        },
        {
            "id": "http_head",
            "name": "http_head",
            "file": "src/http_head.js",
            "require": "const http_head = require('@vbarbarosh/node-helpers/src/http_head');",
            "source_code": "const axios = require('axios');\n\nfunction http_head(url, options)\n{\n    return axios.head(url, options).then(v => v.request.res.headers);\n}\n\nmodule.exports = http_head;\n",
            "markdown": null
        },
        {
            "id": "http_patch_json",
            "name": "http_patch_json",
            "file": "src/http_patch_json.js",
            "require": "const http_patch_json = require('@vbarbarosh/node-helpers/src/http_patch_json');",
            "source_code": "const axios = require('axios');\n\nfunction http_patch_json(url, body, options)\n{\n    return axios.patch(url, body, options).then(v => v.data);\n}\n\nmodule.exports = http_patch_json;\n",
            "markdown": null
        },
        {
            "id": "http_post_json",
            "name": "http_post_json",
            "file": "src/http_post_json.js",
            "require": "const http_post_json = require('@vbarbarosh/node-helpers/src/http_post_json');",
            "source_code": "const axios = require('axios');\n\nfunction http_post_json(url, body, options)\n{\n    return axios.post(url, body, options).then(v => v.data);\n}\n\nmodule.exports = http_post_json;\n",
            "markdown": null
        },
        {
            "id": "http_post_multipart",
            "name": "http_post_multipart",
            "file": "src/http_post_multipart.js",
            "require": "const http_post_multipart = require('@vbarbarosh/node-helpers/src/http_post_multipart');",
            "source_code": "const FormData = require('form-data');\nconst axios = require('axios');\n\n// Provide examples for the following common tasks:\n//\n// * send plain text\n// * send json\n// * send image\n// * send attachment\n\n// import fetch from 'node-fetch';\n//\n// async function http_post_multipart(url, rows)\n// {\n//     const form = new FormData();\n//     for (let i = 0, end = rows.length; i < end; ++i) {\n//         const {name, body} = rows[i];\n//         form.append(name, body);\n//     }\n//     return await fetch(url, {method: 'POST', body: form});\n// }\n//\n// Example:\n//\n// const rows = [];\n// rows.push({name: 'from', body: MAILGUN_FROM});\n// rows.push({name: 'to', body: to});\n// rows.push({name: 'subject', body: subject});\n// rows.push({name: 'text', body: text});\n// rows.push({name: 'attachment', body: fs_read_stream(__filename), options: {filename: 'hello.txt'}});\n// return http_post_multipart(`${MAILGUN_BASE}/messages`, rows, options);\n\n// https://github.com/axios/axios/issues/318#issuecomment-344620216\n// https://github.com/axios/axios/issues/1006#issuecomment-320165427\nfunction http_post_multipart(url, items, options)\n{\n    const form = new FormData();\n    for (let i = 0, end = items.length; i < end; ++i) {\n        const item = items[i];\n        // Without this, all string vales (ordinary fields) will\n        // be empty in _Chrome 59.0.3071.86 (Official Build) (64-bit)_\n        if (item.options) {\n            form.append(item.name, item.body, item.options);\n        }\n        else {\n            form.append(item.name, item.body);\n        }\n    }\n    // For Node\n    // import FormData from 'form-data'\n    // noinspection JSUnresolvedVariable\n    if (form.getHeaders) {\n        const options2 = {...options};\n        options2.headers = {...options2.headers, ...form.getHeaders()};\n        return Promise.resolve(axios.post(url, form, options2)).then(v => v.data);\n    }\n    // For Browser\n    // webpack.config.js\n    //   externals: {\"form-data\": \"FormData\"}\n    return Promise.resolve(axios.post(url, form, options)).then(v => v.data);\n}\n\nmodule.exports = http_post_multipart;\n",
            "markdown": null
        },
        {
            "id": "http_post_urlencoded",
            "name": "http_post_urlencoded",
            "file": "src/http_post_urlencoded.js",
            "require": "const http_post_urlencoded = require('@vbarbarosh/node-helpers/src/http_post_urlencoded');",
            "source_code": "const axios = require('axios');\nconst qs = require('querystring');\n\nfunction http_post_urlencoded(url, body, options)\n{\n    return axios.post(url, qs.stringify(body), options).then(v => v.data);\n}\n\nmodule.exports = http_post_urlencoded;\n",
            "markdown": null
        },
        {
            "id": "http_put_buffer",
            "name": "http_put_buffer",
            "file": "src/http_put_buffer.js",
            "require": "const http_put_buffer = require('@vbarbarosh/node-helpers/src/http_put_buffer');",
            "source_code": "const axios = require('axios');\n\nfunction http_put_buffer(url, body, options)\n{\n    return axios.put(url, body, options).then(v => v.data);\n}\n\nmodule.exports = http_put_buffer;\n",
            "markdown": null
        },
        {
            "id": "http_put_file",
            "name": "http_put_file",
            "file": "src/http_put_file.js",
            "require": "const http_put_file = require('@vbarbarosh/node-helpers/src/http_put_file');",
            "source_code": "const fs = require('fs');\nconst fs_size = require('./fs_size');\nconst http = require('http');\nconst https = require('https');\n\nasync function http_put_file(url, file, options = {})\n{\n    // <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n    // <Error>\n    //   <Code>NotImplemented</Code>\n    //   <Message>A header you provided implies functionality that is not implemented</Message>\n    //   <Header>Transfer-Encoding</Header>\n    //   <RequestId>XXXXXXXXXX</RequestId>\n    //   <HostId>YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY</HostId>\n    // </Error>\n\n    const total = await fs_size(file);\n    return new Promise(function (resolve, reject) {\n        const chunks = [];\n        const request = (url.startsWith('http:') ? http : https).request(url, {method: 'PUT', headers: {...options.headers, 'Content-Length': total}}, function (response) {\n            response.on('error', reject);\n            if (options.progress_download) {\n                const total_download = response.headers['content-length'] ? parseInt(response.headers['content-length']) : null;\n                let ready = 0;\n                response.on('data', function (chunk) {\n                    const delta = chunk.length;\n                    ready += delta;\n                    options.progress_download(delta, ready, total_download);\n                });\n            }\n            response.on('data', function (chunk) {\n                chunks.push(chunk);\n            });\n            response.on('end', function () {\n                switch (response.statusCode) {\n                case 200:\n                    resolve({request, response, data: Buffer.concat(chunks)});\n                    break;\n                default:\n                    reject(new Error(`${response.statusCode} ${response.statusMessage}\\n\\n${Buffer.concat(chunks).toString('utf8')}`));\n                    break;\n                }\n            });\n        });\n        request.on('error', reject);\n        // https://stackoverflow.com/a/39492211/1478566\n        if (options.progress_upload) {\n            let prev = 0;\n            request.on('drain', function () {\n                const ready = request.socket.bytesWritten;\n                const delta = ready - prev;\n                options.progress_upload(delta, ready, total);\n                prev = ready;\n            });\n        }\n        fs.createReadStream(file).pipe(request);\n    });\n}\n\nmodule.exports = http_put_file;\n",
            "markdown": null
        },
        {
            "id": "http_put_json",
            "name": "http_put_json",
            "file": "src/http_put_json.js",
            "require": "const http_put_json = require('@vbarbarosh/node-helpers/src/http_put_json');",
            "source_code": "const axios = require('axios');\n\nfunction http_put_json(url, body, options)\n{\n    return axios.put(url, body, options).then(v => v.data);\n}\n\nmodule.exports = http_put_json;\n",
            "markdown": null
        },
        {
            "id": "http_put_utf8",
            "name": "http_put_utf8",
            "file": "src/http_put_utf8.js",
            "require": "const http_put_utf8 = require('@vbarbarosh/node-helpers/src/http_put_utf8');",
            "source_code": "const axios = require('axios');\n\nasync function http_put_utf8(url, utf8, options)\n{\n    return axios.put(url, utf8, options).then(v => v.data);\n}\n\nmodule.exports = http_put_utf8;\n",
            "markdown": null
        },
        {
            "id": "http_range_parse",
            "name": "http_range_parse",
            "file": "src/http_range_parse.js",
            "require": "const http_range_parse = require('@vbarbarosh/node-helpers/src/http_range_parse');",
            "source_code": "/**\n * @link https://github.com/jshttp/range-parser\n */\nfunction http_range_parse(range, total)\n{\n    const m = range.match(/^bytes\\s*=\\s*(\\d*)-(\\d*)$/);\n\n    if (!m || (!m[1] && !m[2])) {\n        throw new Error(`Cannot parse range \"${range}\". Only \"bytes=FIRST-LAST\", \"bytes=FIRST-\", or \"bytes=-LAST\" are supported.`);\n    }\n\n    let first = +m[1];\n    let last = +m[2];\n\n    if (!m[1]) { // -LAST\n        first = total - last;\n        last = total - 1;\n    }\n    else if (!m[2]) { // FIRST-\n        last = total - 1;\n    }\n\n    if (first < 0 || first > last || first >= total || last < 0 || last < first || last >= total) {\n        throw new Error(`Invalid range: first=${first}, last=${last}, total=${total}, expr=\"${range}\"`);\n    }\n\n    return {first, last};\n}\n\nmodule.exports = http_range_parse;\n",
            "markdown": null
        },
        {
            "id": "http_stream_range",
            "name": "http_stream_range",
            "file": "src/http_stream_range.js",
            "require": "const http_stream_range = require('@vbarbarosh/node-helpers/src/http_stream_range');",
            "source_code": "const escape_content_disposition = require('./escape_content_disposition');\nconst fs_fclose = require('./fs_fclose');\nconst fs_fopen = require('./fs_fopen');\nconst fs_fread = require('./fs_fread');\nconst fs_path_basename = require('./fs_path_basename');\nconst fs_size = require('./fs_size');\nconst http_range_parse = require('./http_range_parse');\nconst mime_types = require('mime-types');\n\n// https://stackoverflow.com/questions/63649387/get-vs-head-methods-in-express-example#comment120040338_63649698\n// > Note: the app.get() function is automatically called for the HTTP HEAD\n// > method in addition to the GET method if app.head() was not called for the\n// > path before app.get().\n//\n// https://expressjs.com/en/api.html#router.METHOD\n// > The router.get() function is automatically called for the HTTP HEAD method\n// > in addition to the GET method if router.head() was not called for the path\n// > before router.get().\n//\n// https://www.npmjs.com/package/send\n\nasync function http_stream_range(req, res, file)\n{\n    // req.log(`[http_stream_range_begin] ${JSON.stringify(req.headers)}`);\n\n    const total = await fs_size(file);\n    const mime = mime_types.lookup(file);\n\n    if (req.method === 'HEAD') {\n        res.header('Content-Type', mime);\n        res.header('Content-Length', total);\n        res.header('Content-Disposition', `inline; filename=${escape_content_disposition(fs_path_basename(file))};`);\n        res.status(200);\n        res.end();\n        return;\n    }\n\n    if (req.method !== 'GET') {\n        res.status(405).end();\n        return;\n    }\n\n    const fp = await fs_fopen(file);\n    const buf = Buffer.alloc(2*1024*1024);\n\n    try {\n        let req_close = false;\n        req.once('close', () => req_close = true);\n\n        let first, last;\n\n        // bytes=0-\n        // bytes=-100\n        if (req.headers.range) {\n            const range = http_range_parse(req.headers.range, total);\n            first = range.first;\n            last = range.last;\n            // req.log(`[http_stream_range_range] ${JSON.stringify({range: req.headers.range, first, last, total, orig: req.headers.range})}`);\n            // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Range\n            res.status(206);\n            res.header('Content-Type', mime);\n            res.header('Content-Range', `bytes ${first}-${last}/${total}`);\n            res.header('Content-Length', last - first + 1);\n        }\n        else {\n            first = 0;\n            last = total - 1;\n            res.header('Content-Type', mime);\n            res.header('Content-Length', last - first + 1);\n        }\n\n        let total_read = 0;\n        for (let offset = first; offset <= last && !req_close; ) {\n            const chunk = await fs_fread(fp, buf, offset, Math.min(buf.length, last - offset + 1));\n            offset += chunk.length;\n            total_read += chunk.length;\n            if (res.write(chunk)) {\n                // req.log(`[http_stream_range_write] ${chunk.length}`);\n                continue;\n            }\n            await new Promise(function (resolve) {\n                res.on('drain', drain);\n                res.on('close', close);\n                function drain() {\n                    // req.log('[http_stream_range_drain]');\n                    res.off('drain', drain);\n                    res.off('close', close);\n                    resolve();\n                }\n                function close() {\n                    // req.log('[http_stream_range_close]');\n                    res.off('drain', drain);\n                    res.off('close', close);\n                    resolve();\n                }\n            });\n        }\n\n        // req.log(`[http_stream_range_end_ok] ${JSON.stringify({req_close, total_read})}`);\n        res.end();\n    }\n    finally {\n        await fs_fclose(fp);\n    }\n}\n\nmodule.exports = http_stream_range;\n",
            "markdown": null
        },
        {
            "id": "identity",
            "name": "identity",
            "file": "src/identity.js",
            "require": "const identity = require('@vbarbarosh/node-helpers/src/identity');",
            "source_code": "function identity(value)\n{\n    return value;\n}\n\nmodule.exports = identity;\n",
            "markdown": null
        },
        {
            "id": "ignore",
            "name": "ignore",
            "file": "src/ignore.js",
            "require": "const ignore = require('@vbarbarosh/node-helpers/src/ignore');",
            "source_code": "function ignore()\n{\n}\n\nmodule.exports = ignore;\n",
            "markdown": null
        },
        {
            "id": "json_stringify_safe",
            "name": "json_stringify_safe",
            "file": "src/json_stringify_safe.js",
            "require": "const json_stringify_safe = require('@vbarbarosh/node-helpers/src/json_stringify_safe');",
            "source_code": "const json_stringify_safe = require('json-stringify-safe');\n\nmodule.exports = json_stringify_safe;\n",
            "markdown": null
        },
        {
            "id": "json_stringify_stable",
            "name": "json_stringify_stable",
            "file": "src/json_stringify_stable.js",
            "require": "const json_stringify_stable = require('@vbarbarosh/node-helpers/src/json_stringify_stable');",
            "source_code": "const json_stringify_stable = require('json-stable-stringify');\n\nmodule.exports = json_stringify_stable;\n",
            "markdown": null
        },
        {
            "id": "logger",
            "name": "logger",
            "file": "src/logger.js",
            "require": "const logger = require('@vbarbarosh/node-helpers/src/logger');",
            "source_code": "const NotImplemented = require('./errors/NotImplemented');\n\n// grep_cle1grnu10000tu72diepbfet\nconst re = /^((?:\\[\\s*[^\\]]*\\])*)\\s*(.*)$/m;\n\n/**\n * log = logger();\n * log.add('hey')\n * log.add('[tag] heyhey')\n */\nfunction logger(options = {})\n{\n    function out(message) {\n        const v = typeof message === 'string' ? JSON.stringify(message.trim()).slice(1, -1) : JSON.stringify(message);\n        const [, a, m] = v.match(re);\n        const time = new Date().toJSON();\n        console.log(`${a} ${m}`.trim());\n    };\n    out.spawn = function () {\n        throw new NotImplemented();\n    };\n    return out;\n}\n\nmodule.exports = logger;\n",
            "markdown": null
        },
        {
            "id": "make_progress",
            "name": "make_progress",
            "file": "src/make_progress.js",
            "require": "const make_progress = require('@vbarbarosh/node-helpers/src/make_progress');",
            "source_code": "// - update progress by delta\n// - update progress by replacing total amount\n// - render eta\n// - render items/second\n// - render percents\n// - time spent\n//\n// https://bramcohen.livejournal.com/24122.html\nfunction make_progress(total)\n{\n    const history = [];\n    const time0 = Date.now();\n    const out = {\n        done: 0,\n        total,\n        eta: null,\n        // `rate` instead of `bps` (bytes per speed) because this function could count any values (e.g.\n        // copied bytes over time, or handled jobs over time, or created object over time, etc.)\n        rate: null,\n        duration: 0,\n        progress: null,\n        percents: null,\n        add: function (delta = 0) {\n            const now_minus_10sec = Date.now() - 10000;\n            history.splice(0, history.findLastIndex(v => v.time < now_minus_10sec));\n            history.push({time: Date.now(), delta});\n            out.done += delta;\n            out.refresh();\n        },\n        update: function (done) {\n            out.add(done - out.done);\n        },\n        refresh: function () {\n            out.duration = (Date.now() - time0)/1000;\n            out.percents = !out.total ? null : out.done/out.total;\n            out.eta = !out.total ? null : (out.total - out.done)/out.rate;\n            if (history.length) {\n                const delta = history.reduce((a,v) => a + v.delta, 0);\n                const time_sec = (Date.now() - history[0].time)/1000;\n                out.rate = delta/time_sec;\n            }\n            else {\n                out.rate = out.done/out.duration;\n            }\n        },\n    };\n    return out;\n}\n\nmodule.exports = make_progress;\n",
            "markdown": null
        },
        {
            "id": "mongo_stream_upsert",
            "name": "mongo_stream_upsert",
            "file": "src/mongo_stream_upsert.js",
            "require": "const mongo_stream_upsert = require('@vbarbarosh/node-helpers/src/mongo_stream_upsert');",
            "source_code": "const Promise = require('bluebird');\nconst stream = require('stream');\nconst wait_while = require('./wait_while');\n\n/**\n * Returns a writable stream for inserting or replacing documents in mongo collection.\n */\nfunction mongo_stream_upsert({collection, concurrency = 1})\n{\n    const errors = [];\n    return new stream.Writable({\n        objectMode: true,\n        construct(next) {\n            this.running = 0;\n            next();\n        },\n        destroy: async function (error, next) {\n            await wait_while(() => this.running > 0);\n            next();\n        },\n        write: async function (items, enc, next) {\n            if (errors.length) {\n                next(errors[0]);\n                return;\n            }\n            try {\n                if (!Array.isArray(items)) {\n                    next(new Error('An array of objects is expected.'));\n                    return;\n                }\n                await wait_while(() => this.running >= concurrency);\n                const operations = items.map(function (item) {\n                    return {\n                        replaceOne: {\n                            filter: {_id: item._id},\n                            replacement: item,\n                            upsert: true,\n                        },\n                    };\n                });\n                this.running++;\n                Promise.resolve(collection.bulkWrite(operations)).catch(e => errors.push(e)).finally(() => this.running--);\n                next();\n            }\n            catch (error) {\n                next(error);\n            }\n        },\n        final: async function (next) {\n            if (errors.length) {\n                next(errors[0]);\n                return;\n            }\n            await wait_while(() => this.running > 0);\n            next();\n        },\n    });\n}\n\nmodule.exports = mongo_stream_upsert;\n",
            "markdown": null
        },
        {
            "id": "mongo_stream_write",
            "name": "mongo_stream_write",
            "file": "src/mongo_stream_write.js",
            "require": "const mongo_stream_write = require('@vbarbarosh/node-helpers/src/mongo_stream_write');",
            "source_code": "const Promise = require('bluebird');\nconst stream = require('stream');\nconst wait_while = require('./wait_while');\n\n/**\n * Returns a writable stream for `bulkWrite` operations.\n */\nfunction mongo_stream_write({collection, concurrency = 1})\n{\n    const errors = [];\n    return new stream.Writable({\n        objectMode: true,\n        construct(next) {\n            this.running = 0;\n            next();\n        },\n        destroy: async function (error, next) {\n            await wait_while(() => this.running > 0);\n            next();\n        },\n        write: async function (operations, enc, next) {\n            if (errors.length) {\n                next(errors[0]);\n                return;\n            }\n            try {\n                if (!Array.isArray(operations)) {\n                    next(new Error('An array of objects is expected.'));\n                    return;\n                }\n                await wait_while(() => this.running >= concurrency);\n                this.running++;\n                Promise.resolve(collection.bulkWrite(operations)).catch(e => errors.push(e)).finally(() => this.running--);\n                next();\n            }\n            catch (error) {\n                next(error);\n            }\n        },\n        final: async function (next) {\n            if (errors.length) {\n                next(errors[0]);\n                return;\n            }\n            await wait_while(() => this.running > 0);\n            next();\n        },\n    });\n}\n\nmodule.exports = mongo_stream_write;\n",
            "markdown": null
        },
        {
            "id": "msval",
            "name": "msval",
            "file": "src/msval.js",
            "require": "const msval = require('@vbarbarosh/node-helpers/src/msval');",
            "source_code": "function msval(h, m, s, ms)\n{\n    return h*3600000 + m*60000 + s*1000 + ms;\n}\n\nmodule.exports = msval;\n",
            "markdown": null
        },
        {
            "id": "now_atom",
            "name": "now_atom",
            "file": "src/now_atom.js",
            "require": "const now_atom = require('@vbarbarosh/node-helpers/src/now_atom');",
            "source_code": "/**\n * Return the current date in ATOM format (e.g. \"2021-07-17T23:27:01.030Z\")\n *\n * @returns {string}\n * @link https://www.php.net/manual/en/class.datetimeinterface.php#datetime.constants.atom\n */\nfunction now_atom()\n{\n    return (new Date()).toJSON();\n}\n\nmodule.exports = now_atom;\n",
            "markdown": "Return the current date in ATOM format (e.g. \"2021-07-17T23:27:01.030Z\")\n"
        },
        {
            "id": "now_fs",
            "name": "now_fs",
            "file": "src/now_fs.js",
            "require": "const now_fs = require('@vbarbarosh/node-helpers/src/now_fs');",
            "source_code": "const format_date_fs = require('./format_date_fs');\n\nfunction now_fs()\n{\n    return format_date_fs(new Date());\n}\n\nmodule.exports = now_fs;\n",
            "markdown": null
        },
        {
            "id": "now_human",
            "name": "now_human",
            "file": "src/now_human.js",
            "require": "const now_human = require('@vbarbarosh/node-helpers/src/now_human');",
            "source_code": "const format_date_human = require('./format_date_human');\n\nfunction now_human()\n{\n    return format_date_human(new Date());\n}\n\nmodule.exports = now_human;\n",
            "markdown": null
        },
        {
            "id": "object_defaults",
            "name": "object_defaults",
            "file": "src/object_defaults.js",
            "require": "const object_defaults = require('@vbarbarosh/node-helpers/src/object_defaults');",
            "source_code": "function object_defaults(obj, defaults)\n{\n    Object.entries(defaults).forEach(function ([key, value]) {\n        if (obj[key] === undefined) {\n            obj[key] = value;\n        }\n    });\n    return obj;\n}\n\nmodule.exports = object_defaults;\n",
            "markdown": null
        },
        {
            "id": "object_schema",
            "name": "object_schema",
            "file": "src/object_schema.js",
            "require": "const object_schema = require('@vbarbarosh/node-helpers/src/object_schema');",
            "source_code": "const const_type = require('./const_type');\nconst gettype = require('./gettype');\nconst json_stringify_stable = require('./json_stringify_stable');\n\nfunction object_schema(obj)\n{\n    const type = gettype(obj);\n    switch (type) {\n    case const_type.array:\n        return obj.map(object_schema).map(v => json_stringify_stable(v)).sort().filter((v,i,a) => a[i-1] !== v).map(v => JSON.parse(v));\n    case const_type.object:\n        const out = {};\n        Object.keys(obj).forEach(function (key) {\n            out[key] = object_schema(obj[key]);\n        });\n        return out;\n    default:\n        return type;\n    }\n}\n\nmodule.exports = object_schema;\n",
            "markdown": null
        },
        {
            "id": "object_walk_preorder",
            "name": "object_walk_preorder",
            "file": "src/object_walk_preorder.js",
            "require": "const object_walk_preorder = require('@vbarbarosh/node-helpers/src/object_walk_preorder');",
            "source_code": "function object_walk_preorder(value, fn, path = [])\n{\n    if (path.length) {\n        fn(value, path);\n    }\n    if (value === null) {\n        return;\n    }\n    if (Array.isArray(value)) {\n        for (let i = 0, end = value.length; i < end; ++i) {\n            object_walk_preorder(value[i], fn, path.concat('*'));\n        }\n    }\n    else if (typeof value === 'object') {\n        const keys = Object.keys(value);\n        for (let i = 0, end = keys.length; i < end; ++i) {\n            const key = keys[i];\n            object_walk_preorder(value[key], fn, path.concat(key));\n        }\n    }\n}\n\nmodule.exports = object_walk_preorder;\n",
            "markdown": null
        },
        {
            "id": "parallel",
            "name": "parallel",
            "file": "src/parallel.js",
            "require": "const parallel = require('@vbarbarosh/node-helpers/src/parallel');",
            "source_code": "const NotImplemented = require('./errors/NotImplemented');\nconst Promise = require('bluebird');\nconst is_fn_async = require('@vbarbarosh/type-helpers/src/is_fn_async');\nconst is_fn_gen_async = require('@vbarbarosh/type-helpers/src/is_fn_gen_async');\n\n/**\n * - Run until `spawn` return `null`.\n * - Keep no more than `concurrency` number of workers at a time.\n *\n * ⚠️ Warning: `spawn` should not be async function (async functions are always return `promise`).\n *    Instead, it should be a simple function returning either `null` or a `promise`.\n */\nasync function parallel({concurrency, spawn, progress})\n{\n    if (is_fn_async(spawn) || is_fn_gen_async(spawn)) {\n        throw new Error('[spawn] should not be async function. Instead, it should be a simple function returning either [null] or a [promise].');\n    }\n    const running = [];\n    return new Promise(function (resolve, reject) {\n        let failed = false;\n        const timer = setInterval(tick, 1000);\n        schedule();\n        if (running.length) {\n            tick();\n        }\n        function schedule() {\n            while (running.length < concurrency) {\n                if (failed) {\n                    break;\n                }\n                const w = spawn();\n                if (!w) {\n                    break;\n                }\n                const item = Promise.resolve(w).then(resolved, rejected);\n                running.push(item);\n                function resolved() {\n                    if (failed) {\n                        return;\n                    }\n                    const i = running.indexOf(item);\n                    if (i === -1) {\n                        throw new NotImplemented();\n                    }\n                    running.splice(i, 1);\n                    schedule();\n                }\n                function rejected(error) {\n                    if (failed) {\n                        return;\n                    }\n                    running.splice(0, running.length);\n                    reject(error);\n                }\n            }\n            if (running.length === 0) {\n                tick();\n                clearInterval(timer);\n                resolve();\n            }\n        }\n        function tick() {\n            if (progress) {\n                progress(running);\n            }\n        }\n    });\n}\n\nmodule.exports = parallel;\n",
            "markdown": "- Run until `spawn` return `null`.\n- Keep no more than `concurrency` number of workers at a time.\n\n⚠️ Warning: `spawn` should not be async function (async functions are always return `promise`).\nInstead, it should be a simple function returning either `null` or a `promise`.\n"
        },
        {
            "id": "parse_bytes",
            "name": "parse_bytes",
            "file": "src/parse_bytes.js",
            "require": "const parse_bytes = require('@vbarbarosh/node-helpers/src/parse_bytes');",
            "source_code": "function parse_bytes(bytes)\n{\n    const sizes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB'];\n    if (typeof bytes !== 'string') {\n        return Number.NaN;\n    }\n    const m = bytes.toUpperCase().match(/(\\d+([.]?\\d+)?)(([KMGTP]I?)?B)/);\n    if (!m) {\n        return Number.NaN;\n    }\n    return Math.floor(m[1]*Math.pow(1024, sizes.indexOf(m[3].replace('I', ''))));\n}\n\nmodule.exports = parse_bytes;\n",
            "markdown": null
        },
        {
            "id": "parse_http_content_range",
            "name": "parse_http_content_range",
            "file": "src/parse_http_content_range.js",
            "require": "const parse_http_content_range = require('@vbarbarosh/node-helpers/src/parse_http_content_range');",
            "source_code": "function parse_http_content_range(value)\n{\n    // Content-Range: bytes 262144000-272629759/5037662208\n    const m = value.match(/^(\\w+)\\s+(\\d+)-(\\d+)[/](\\d+)$/);\n    if (!m) {\n        throw new Error(`Invalid Content-Range: [${value}]`);\n    }\n    const type = m[1];\n    const first = +m[2];\n    const last = +m[3];\n    const total = +m[4];\n    return {type, first, last, total};\n}\n\nmodule.exports = parse_http_content_range;\n",
            "markdown": null
        },
        {
            "id": "perf_end_human",
            "name": "perf_end_human",
            "file": "src/perf_end_human.js",
            "require": "const perf_end_human = require('@vbarbarosh/node-helpers/src/perf_end_human');",
            "source_code": "const format_hrtime = require('./format_hrtime');\n\nfunction perf_end_human(time0, digits = 4)\n{\n    return format_hrtime(process.hrtime(time0), digits);\n}\n\nmodule.exports = perf_end_human;\n",
            "markdown": null
        },
        {
            "id": "perf_end_ms",
            "name": "perf_end_ms",
            "file": "src/perf_end_ms.js",
            "require": "const perf_end_ms = require('@vbarbarosh/node-helpers/src/perf_end_ms');",
            "source_code": "function perf_end_ms(time0)\n{\n    const [u, v] = process.hrtime(time0);\n    return Math.round((u + v/1E9)*1000);\n}\n\nmodule.exports = perf_end_ms;\n",
            "markdown": null
        },
        {
            "id": "perf_measure",
            "name": "perf_measure",
            "file": "src/perf_measure.js",
            "require": "const perf_measure = require('@vbarbarosh/node-helpers/src/perf_measure');",
            "source_code": "const format_hrtime = require('./format_hrtime');\nconst perf_start = require('./perf_start');\n\nasync function perf_measure(fn, digits = 4)\n{\n    const time0 = perf_start();\n    const out = {\n        value: await fn(),\n    };\n    const [u, v] = process.hrtime(time0);\n    out.time_ms = Math.round((u + v/1E9)*1000);\n    out.time_human = format_hrtime([u ,v], digits)\n    return out;\n}\n\nmodule.exports = perf_measure;\n",
            "markdown": null
        },
        {
            "id": "perf_measure_human",
            "name": "perf_measure_human",
            "file": "src/perf_measure_human.js",
            "require": "const perf_measure_human = require('@vbarbarosh/node-helpers/src/perf_measure_human');",
            "source_code": "const perf_end_human = require('./perf_end_human');\nconst perf_start = require('./perf_start');\n\nasync function perf_measure_human(fn, digits = 4)\n{\n    const time0 = perf_start();\n    await fn();\n    return perf_end_human(time0, digits);\n}\n\nmodule.exports = perf_measure_human;\n",
            "markdown": null
        },
        {
            "id": "perf_start",
            "name": "perf_start",
            "file": "src/perf_start.js",
            "require": "const perf_start = require('@vbarbarosh/node-helpers/src/perf_start');",
            "source_code": "function perf_start()\n{\n    return process.hrtime();\n}\n\nmodule.exports = perf_start;\n",
            "markdown": null
        },
        {
            "id": "pid_exists",
            "name": "pid_exists",
            "file": "src/pid_exists.js",
            "require": "const pid_exists = require('@vbarbarosh/node-helpers/src/pid_exists');",
            "source_code": "function pid_exists(pid)\n{\n    try {\n        process.kill(pid, 0);\n        return true;\n    }\n    catch {\n        return false;\n    }\n}\n\nmodule.exports = pid_exists;\n",
            "markdown": null
        },
        {
            "id": "pid_kill_grace",
            "name": "pid_kill_grace",
            "file": "src/pid_kill_grace.js",
            "require": "const pid_kill_grace = require('@vbarbarosh/node-helpers/src/pid_kill_grace');",
            "source_code": "const Promise = require('bluebird');\nconst format_thousands = require('./format_thousands');\nconst ignore = require('./ignore');\nconst pid_exists = require('./pid_exists');\n\nasync function pid_kill_grace(pid, {grace_timeout_ms = 5000, log = ignore} = {})\n{\n    log('Sending SIGTERM');\n    if (!process.kill(pid, 'SIGTERM')) {\n        throw new Error('SIGTERM Failed');\n    }\n\n    const end = Date.now() + grace_timeout_ms;\n    while (Date.now() < end) {\n        if (!pid_exists(pid)) {\n            return;\n        }\n        log(`Process is still there, waiting for 100ms, ${format_thousands(end - Date.now())}ms left`);\n        await Promise.delay(100);\n    }\n\n    log('Sending SIGKILL');\n    if (!process.kill(pid, 'SIGKILL')) {\n        throw new Error('SIGKILL Failed');\n    }\n}\n\nmodule.exports = pid_kill_grace;\n",
            "markdown": null
        },
        {
            "id": "ping_socket",
            "name": "ping_socket",
            "file": "src/ping_socket.js",
            "require": "const ping_socket = require('@vbarbarosh/node-helpers/src/ping_socket');",
            "source_code": "const Promise = require('bluebird');\nconst net = require('net');\n\n/**\n * - Always closes the socket.\n * - Throws on any error or timeout.\n * - Doesn’t hang if the server sends nothing.\n */\nfunction ping_socket(socket_path, data = 'PING', timeout_ms = 1000)\n{\n    return new Promise(function (resolve, reject) {\n        let done = false;\n        const buf = [];\n        const socket = net.connect(socket_path);\n        socket.setTimeout(timeout_ms, () => finish(new Error('Socket Timeout')));\n        socket.on('end', () => finish(null, Buffer.concat(buf)))\n        socket.on('error', finish);\n        socket.on('connect', () => socket.end(data));\n        socket.on('data', chunk => buf.push(chunk));\n        function finish(error, out) {\n            if (done) {\n                return;\n            }\n            done = true;\n            socket.removeAllListeners();\n            socket.destroy();\n            error ? reject(error) : resolve(out);\n        }\n    });\n}\n\nmodule.exports = ping_socket;\n",
            "markdown": "- Always closes the socket.\n- Throws on any error or timeout.\n- Doesn’t hang if the server sends nothing.\n"
        },
        {
            "id": "plural",
            "name": "plural",
            "file": "src/plural.js",
            "require": "const plural = require('@vbarbarosh/node-helpers/src/plural');",
            "source_code": "function plural(n, singular, plural, zero)\n{\n    if (n === 0 && typeof zero === 'string') {\n        return zero;\n    }\n    if (n % 10 === 1 && n % 100 !== 11) {\n        return singular.split('#').join(n);\n    }\n    return plural.split('#').join(n);\n}\n\nmodule.exports = plural;\n",
            "markdown": null
        },
        {
            "id": "random_hex",
            "name": "random_hex",
            "file": "src/random_hex.js",
            "require": "const random_hex = require('@vbarbarosh/node-helpers/src/random_hex');",
            "source_code": "const crypto = require('crypto');\n\n/**\n * Returns random bytes in hexadecimal format.\n */\nfunction random_hex(bytes = 32)\n{\n    return crypto.randomBytes(bytes).toString('hex');\n}\n\nmodule.exports = random_hex;\n",
            "markdown": null
        },
        {
            "id": "random_int",
            "name": "random_int",
            "file": "src/random_int.js",
            "require": "const random_int = require('@vbarbarosh/node-helpers/src/random_int');",
            "source_code": "function random_int(min, max)\n{\n    return Math.floor(Math.random()*(max - min + 1) + min);\n}\n\nmodule.exports = random_int;\n",
            "markdown": null
        },
        {
            "id": "redis_connect",
            "name": "redis_connect",
            "file": "src/redis_connect.js",
            "require": "const redis_connect = require('@vbarbarosh/node-helpers/src/redis_connect');",
            "source_code": "const redis = require('redis');\n\n// tcp://127.0.0.1:6379\n// tls://11.11.11.11:6378?password=xxx\n// tls://11.11.11.11:6378?password=xx-xx-xx&ssl[verify_peer]=0&ssl[verify_peer_name]=0\nasync function redis_connect(url)\n{\n    const tmp = new URL(url);\n    const password = tmp.password || tmp.searchParams.get('password');\n\n    if (url.match(/^tls:/)) {\n        const out = redis.createClient({\n            url: url.replace(/^tls:/, 'rediss:'),\n            password,\n            tls: {rejectUnauthorized: false},\n            socket: {tls: true, rejectUnauthorized: false},\n        });\n        await out.connect();\n        return out;\n    }\n    const out = await redis.createClient({\n        url: url.replace(/^tcp:/, 'redis:'),\n        password,\n    });\n    await out.connect();\n    return out;\n}\n\nmodule.exports = redis_connect;\n",
            "markdown": null
        },
        {
            "id": "redis_lshift",
            "name": "redis_lshift",
            "file": "src/redis_lshift.js",
            "require": "const redis_lshift = require('@vbarbarosh/node-helpers/src/redis_lshift');",
            "source_code": "async function redis_lshift(redis, queue, limit = 1)\n{\n    const last = limit - 1;\n    if (redis.lrange) {\n        const [items] = await new Promise(function (resolve, reject) {\n            redis.multi().lrange(queue, 0, last).ltrim(queue, limit, -1).exec(function (error, out) {\n                error ? reject(error) : resolve(out);\n            });\n        });\n        return items;\n    }\n    // redis@4\n    const [items] = await redis.multi().LRANGE(queue, 0, last).LTRIM(queue, limit, -1).exec();\n    return items;\n}\n\nmodule.exports = redis_lshift;\n",
            "markdown": null
        },
        {
            "id": "redis_poll",
            "name": "redis_poll",
            "file": "src/redis_poll.js",
            "require": "const redis_poll = require('@vbarbarosh/node-helpers/src/redis_poll');",
            "source_code": "const Promise = require('bluebird');\nconst random_int = require('./random_int');\nconst redis_zshift = require('./redis_zshift');\n\nasync function redis_poll(options)\n{\n    const {log, version} = options;\n    const {\n        poll_message,\n        push_response,\n        process_message,\n        log_waiter_begin,\n        log_waiter_end,\n        log_waiter_sleep,\n        log_waiter_rpush,\n        log_waiter_error,\n        log_waiter_error_parse,\n        log_waiter_error_no_uid,\n    } = options;\n\n    log(`[${log_waiter_begin}] v${version}`);\n    try {\n        for (let iter = 1; iter <= 24*60*60; ++iter) {\n\n            // const message_string = await redis.lpop_p(redis_input_queue);\n            const message = await poll_message();\n            if (!message) {\n                const ms = random_int(500, 1500);\n                log(`[${log_waiter_sleep}] ${ms}ms`);\n                await Promise.delay(ms);\n                continue;\n            }\n\n            try {\n                const uid = message.uid;\n\n                if (!uid) {\n                    log(`[${log_waiter_error_no_uid}] uid is missed; skipped`);\n                    continue;\n                }\n                if (!message.expires_at) {\n                    throw new Error('expires_at is missed');\n                }\n\n                // This is necessary because we use signed urls which has limited lifetime.\n                // Basically, `expires_at` tell when signed url will be expired.\n                if (new Date(message.expires_at).getTime() <= new Date().getTime()) {\n                    throw new Error('Expired');\n                }\n\n                const value = await worker(log.spawn(), message, options);\n                await push_response({uid: message.uid, version, type: 'resolve', value});\n\n                log(`[${log_waiter_rpush}]`);\n            }\n            catch (error) {\n                const response = {uid: message.uid, version, type: 'reject', value: `${(error && (error.stack || error.message)) || 'Error N/A'}`};\n                log(`[${log_waiter_error}] ${JSON.stringify({response})}`);\n                await push_response(response);\n            }\n        }\n    }\n    finally {\n        log(`[${log_waiter_end}]`);\n    }\n}\n\nasync function worker(log, message, options)\n{\n    const {redis, redis_output_queue, spawn_command, version} = options;\n    const {\n        callback,\n        log_worker_begin,\n        log_worker_end_ok,\n        log_worker_end_error,\n        log_worker_stdout,\n        log_worker_stderr,\n        log_worker_user_friendly_status,\n    } = options;\n\n    log(`[${log_worker_begin}] ${message.uid}`);\n\n    const uid = message.uid;\n\n    try {\n        // GOTCHA\n        // Promise won't update its status until at least one message would\n        // be taken from output queue. Pushing generic \"Started....\" message\n        // will tell the promise to refresh its status.\n        await user_friendly_status('Started...');\n        const out = await callback({message, log: log.spawn(), user_friendly_status});\n        log(`[${log_worker_end_ok}]`);\n        return out;\n    }\n    catch (error) {\n        log(`[${log_worker_end_error}] ${error.message}`);\n        throw error;\n    }\n\n    async function user_friendly_status(value) {\n        log(`[${log_worker_user_friendly_status}] ${value}`);\n        await redis.rpush_p(redis_output_queue, JSON.stringify({uid, version, type: 'user_friendly_status', value}));\n    }\n}\n\nmodule.exports = redis_poll;\n",
            "markdown": null
        },
        {
            "id": "redis_poll_zshift_callback_rpush",
            "name": "redis_poll_zshift_callback_rpush",
            "file": "src/redis_poll_zshift_callback_rpush.js",
            "require": "const redis_poll_zshift_callback_rpush = require('@vbarbarosh/node-helpers/src/redis_poll_zshift_callback_rpush');",
            "source_code": "const Promise = require('bluebird');\nconst random_int = require('./random_int');\nconst redis_zshift = require('./redis_zshift');\n\n/**\n * Poll redis for input messages, await for callback, rpush results and user friendly statuses.\n * @param options\n * @returns {Promise<void>}\n *\n *     const options = {\n *         log: logger_create(),\n *         redis: redis_connect2('redis://127.0.0.1'),\n *         redis_input_queue: 'mp4gif_input',\n *         redis_output_queue: 'mp4gif_output',\n *         callback: function (message) { ... },\n *         log_waiter_begin: 'mp4gif_waiter_begin',\n *         log_waiter_end: 'mp4gif_waiter_end',\n *         log_waiter_sleep: 'mp4gif_waiter_sleep',\n *         log_waiter_rpush: 'mp4gif_waiter_rpush',\n *         log_waiter_error: 'mp4gif_waiter_error',\n *         log_waiter_error_parse: 'mp4gif_waiter_error_parse',\n *         log_waiter_error_no_uid: 'mp4gif_waiter_error_no_uid',\n *         log_worker_begin: 'mp4gif_worker_begin',\n *         log_worker_end_ok: 'mp4gif_worker_end_ok',\n *         log_worker_end_error: 'mp4gif_worker_end_error',\n *         log_worker_stdout: 'mp4gif_worker_stdout',\n *         log_worker_stderr: 'mp4gif_worker_stderr',\n *         log_worker_user_friendly_status: 'mp4gif_worker_user_friendly_status',\n *     };\n *     await redis_poll_zshift_callback_rpush(options);\n */\nasync function redis_poll_zshift_callback_rpush(options)\n{\n    const {log, redis, redis_input_queue, redis_output_queue, version} = options;\n    const {\n        log_waiter_begin,\n        log_waiter_end,\n        log_waiter_sleep,\n        log_waiter_rpush,\n        log_waiter_error,\n        log_waiter_error_parse,\n        log_waiter_error_no_uid,\n    } = options;\n\n    log(`[${log_waiter_begin}] v${version}`);\n    try {\n        for (let iter = 1; iter <= 24*60*60; ++iter) {\n\n            // const message_string = await redis.lpop_p(redis_input_queue);\n            const [message_string] = await redis_zshift(redis, redis_input_queue);\n            if (!message_string) {\n                const ms = random_int(500, 1500);\n                log(`[${log_waiter_sleep}] ${ms}ms`);\n                await Promise.delay(ms);\n                continue;\n            }\n            console.log(message_string);\n\n            let message = null;\n            try {\n                message = JSON.parse(message_string);\n            }\n            catch (error) {\n                log(`[${log_waiter_error_parse}] ${error.message}`);\n                continue;\n            }\n\n            try {\n                const uid = message.uid;\n\n                if (!uid) {\n                    log(`[${log_waiter_error_no_uid}] uid is missed; skipped`);\n                    continue;\n                }\n                if (!message.expires_at) {\n                    throw new Error('expires_at is missed');\n                }\n\n                // This is necessary because we use signed urls which has limited lifetime.\n                // Basically, `expires_at` tell when signed url will be expired.\n                if (new Date(message.expires_at).getTime() <= new Date().getTime()) {\n                    throw new Error('Expired');\n                }\n\n                const value = await worker(log.spawn(), message, options);\n                const response = JSON.stringify({uid: message.uid, version, type: 'resolve', value});\n                await redis.rpush_p(redis_output_queue, response);\n\n                log(`[${log_waiter_rpush}]`);\n            }\n            catch (error) {\n                const response = JSON.stringify({uid: message.uid, version, type: 'reject', value: `${(error && (error.stack || error.message)) || 'Error N/A'}`});\n                log(`[${log_waiter_error}] ${response}`);\n                await redis.rpush_p(redis_output_queue, response);\n            }\n        }\n    }\n    finally {\n        log(`[${log_waiter_end}]`);\n    }\n}\n\nasync function worker(log, message, options)\n{\n    const {redis, redis_output_queue, spawn_command, version} = options;\n    const {\n        callback,\n        log_worker_begin,\n        log_worker_end_ok,\n        log_worker_end_error,\n        log_worker_stdout,\n        log_worker_stderr,\n        log_worker_user_friendly_status,\n    } = options;\n\n    log(`[${log_worker_begin}] ${message.uid}`);\n\n    const uid = message.uid;\n\n    try {\n        // GOTCHA\n        // Promise won't update its status until at least one message would\n        // be taken from output queue. Pushing generic \"Started....\" message\n        // will tell the promise to refresh its status.\n        await user_friendly_status('Started...');\n        const out = await callback({message, log: log.spawn(), user_friendly_status});\n        log(`[${log_worker_end_ok}]`);\n        return out;\n    }\n    catch (error) {\n        log(`[${log_worker_end_error}] ${error.message}`);\n        throw error;\n    }\n\n    async function user_friendly_status(value) {\n        log(`[${log_worker_user_friendly_status}] ${value}`);\n        await redis.rpush_p(redis_output_queue, JSON.stringify({uid, version, type: 'user_friendly_status', value}));\n    }\n}\n\nmodule.exports = redis_poll_zshift_callback_rpush;\n",
            "markdown": null
        },
        {
            "id": "redis_poll_zshift_spawn_rpush",
            "name": "redis_poll_zshift_spawn_rpush",
            "file": "src/redis_poll_zshift_spawn_rpush.js",
            "require": "const redis_poll_zshift_spawn_rpush = require('@vbarbarosh/node-helpers/src/redis_poll_zshift_spawn_rpush');",
            "source_code": "const Promise = require('bluebird');\nconst child_process = require('child_process');\nconst fs_path_resolve = require('./fs_path_resolve');\nconst fs_tempdir = require('./fs_tempdir');\nconst fs_write_json = require('./fs_write_json');\nconst random_int = require('./random_int');\nconst redis_zshift = require('./redis_zshift');\nconst stream_data_ln = require('./stream_data_ln');\n\n/**\n * Constantly monitors redis queue for incoming messages. After an incoming message was hit,\n * dumps it into `request.json` and executes `spawn_command`. The current directory will be set\n * to a new directory with just `request.json` inside. Result (`null`) and user-friendly\n * statuses will be `rpush`ed to the output queue.\n *\n * @param options\n * @returns {Promise<void>}\n *\n *     const options = {\n *         log: logger_create(),\n *         redis: redis_connect2('redis://127.0.0.1'),\n *         redis_input_queue: 'mp4gif_input',\n *         redis_output_queue: 'mp4gif_output',\n *         spawn_command: 'banner-export-mp4gif',\n *         log_waiter_begin: 'mp4gif_waiter_begin',\n *         log_waiter_end: 'mp4gif_waiter_end',\n *         log_waiter_sleep: 'mp4gif_waiter_sleep',\n *         log_waiter_rpush: 'mp4gif_waiter_rpush',\n *         log_waiter_error: 'mp4gif_waiter_error',\n *         log_waiter_error_parse: 'mp4gif_waiter_error_parse',\n *         log_waiter_error_no_uid: 'mp4gif_waiter_error_no_uid',\n *         log_worker_begin: 'mp4gif_worker_begin',\n *         log_worker_end_ok: 'mp4gif_worker_end_ok',\n *         log_worker_end_error: 'mp4gif_worker_end_error',\n *         log_worker_stdout: 'mp4gif_worker_stdout',\n *         log_worker_stderr: 'mp4gif_worker_stderr',\n *         log_worker_user_friendly_status: 'mp4gif_worker_user_friendly_status',\n *     };\n *     await redis_poll_zshift_spawn_rpush(options);\n */\nasync function redis_poll_zshift_spawn_rpush(options)\n{\n    const {log, redis, redis_input_queue, redis_output_queue, version} = options;\n    const {\n        log_waiter_begin,\n        log_waiter_end,\n        log_waiter_sleep,\n        log_waiter_rpush,\n        log_waiter_error,\n        log_waiter_error_parse,\n        log_waiter_error_no_uid,\n    } = options;\n\n    log(`[${log_waiter_begin}] v${version}`);\n    try {\n        for (let iter = 1; iter <= 24*60*60; ++iter) {\n\n            // const message_string = await redis.lpop_p(redis_input_queue);\n            const [message_string] = await redis_zshift(redis, redis_input_queue);\n            if (!message_string) {\n                const ms = random_int(500, 1500);\n                log(`[${log_waiter_sleep}] ${ms}ms`);\n                await Promise.delay(ms);\n                continue;\n            }\n\n            let message = null;\n            try {\n                message = JSON.parse(message_string);\n            }\n            catch (error) {\n                log(`[${log_waiter_error_parse}] ${error.message}`);\n                continue;\n            }\n\n            try {\n                const uid = message.uid;\n\n                if (!uid) {\n                    log(`[${log_waiter_error_no_uid}] uid is missed; skipped`);\n                    continue;\n                }\n                if (!message.expires_at) {\n                    throw new Error('expires_at is missed');\n                }\n\n                // This is necessary because we use signed urls which has limited lifetime.\n                // Basically, `expires_at` tell when signed url will be expired.\n                if (new Date(message.expires_at).getTime() <= new Date().getTime()) {\n                    throw new Error('Expired');\n                }\n\n                await worker(log.spawn(), message, options);\n                const response = JSON.stringify({uid: message.uid, version, type: 'resolve', value: null});\n                await redis.rpush_p(redis_output_queue, response);\n\n                log(`[${log_waiter_rpush}]`);\n            }\n            catch (error) {\n                const response = JSON.stringify({uid: message.uid, version, type: 'error', value: `${(error && (error.stack || error.message)) || 'Error N/A'}`});\n                log(`[${log_waiter_error}] ${response}`);\n                await redis.rpush_p(redis_output_queue, response);\n            }\n        }\n    }\n    finally {\n        log(`[${log_waiter_end}]`);\n    }\n}\n\nasync function worker(log, request, options)\n{\n    const {redis, redis_output_queue, spawn_command, version} = options;\n    const {\n        log_worker_begin,\n        log_worker_end_ok,\n        log_worker_end_error,\n        log_worker_stdout,\n        log_worker_stderr,\n        log_worker_user_friendly_status,\n    } = options;\n\n    log(`[${log_worker_begin}] ${request.uid}`);\n\n    try {\n        const uid = request.uid;\n        // GOTCHA\n        // Promise won't update its status until at least one request would\n        // be taken from the output queue. Pushing generic \"Started...\" request\n        // will tell the promise to refresh its status.\n        await redis.rpush_p(redis_output_queue, JSON.stringify({uid, version, type: 'user_friendly_status', value: 'Started...'}));\n        await fs_tempdir(async function (d) {\n            await fs_write_json(fs_path_resolve(d, 'request.json'), request);\n            const proc = child_process.spawn(spawn_command, [], {cwd: d, stdio: ['pipe', 'pipe', 'pipe', 'pipe']});\n            let end_stdout = function () {};\n            let end_stderr = function () {};\n            let end_user_friendly_status = function () {};\n            try {\n                await new Promise(function (resolve, reject) {\n                    proc.once('error', reject);\n                    proc.once('exit', code => code ? reject(new Error(`Process terminated with code ${code}`)) : resolve());\n                    end_stdout = stream_data_ln(proc.stdout, line => log(`[${log_worker_stdout}] ${line}`));\n                    end_stderr = stream_data_ln(proc.stderr, line => log(`[${log_worker_stderr}] ${line}`));\n                    end_user_friendly_status = stream_data_ln(proc.stdio[3], function (line) {\n                        log(`[${log_worker_user_friendly_status}] ${line}`);\n                        redis.rpush_p(redis_output_queue, JSON.stringify({uid, version, type: 'user_friendly_status', value: line}));\n                    });\n                });\n            }\n            finally {\n                end_stdout();\n                end_stderr();\n                end_user_friendly_status();\n            }\n        });\n    }\n    catch (error) {\n        log(`[${log_worker_end_error}] ${error.message}`);\n        throw error;\n    }\n    log(`[${log_worker_end_ok}]`);\n}\n\nmodule.exports = redis_poll_zshift_spawn_rpush;\n",
            "markdown": null
        },
        {
            "id": "redis_zshift",
            "name": "redis_zshift",
            "file": "src/redis_zshift.js",
            "require": "const redis_zshift = require('@vbarbarosh/node-helpers/src/redis_zshift');",
            "source_code": "async function redis_zshift(redis, queue, limit = 1)\n{\n    const last = limit - 1;\n    if (redis.zrange) {\n        const [items] = await new Promise(function (resolve, reject) {\n            redis.multi().zrange(queue, 0, last).zremrangebyrank(queue, 0, last).exec(function (error, out) {\n                error ? reject(error) : resolve(out);\n            });\n        });\n        return items;\n    }\n    // redis@4\n    const [items] = await redis.multi().ZRANGE(queue, 0, last).ZREMRANGEBYRANK(queue, 0, last).exec();\n    return items;\n}\n\nmodule.exports = redis_zshift;\n",
            "markdown": null
        },
        {
            "id": "sanitize_dash_name",
            "name": "sanitize_dash_name",
            "file": "src/sanitize_dash_name.js",
            "require": "const sanitize_dash_name = require('@vbarbarosh/node-helpers/src/sanitize_dash_name');",
            "source_code": "function sanitize_dash_name(s)\n{\n    // https://stackoverflow.com/a/37511463\n    return s.normalize('NFD').replace(/[\\u0300-\\u036f]/g, '').replace(/[^a-zA-Z0-9]/g, '-').replace(/-+/g, '-').replace(/^-+|-+$/g, '').toLowerCase();\n}\n\nmodule.exports = sanitize_dash_name;\n",
            "markdown": null
        },
        {
            "id": "sanitize_filename",
            "name": "sanitize_filename",
            "file": "src/sanitize_filename.js",
            "require": "const sanitize_filename = require('@vbarbarosh/node-helpers/src/sanitize_filename');",
            "source_code": "const lib = require('sanitize-filename');\n\nfunction sanitize_filename(filename)\n{\n    return lib(filename);\n}\n\nmodule.exports = sanitize_filename;\n",
            "markdown": null
        },
        {
            "id": "sanitize_var_name",
            "name": "sanitize_var_name",
            "file": "src/sanitize_var_name.js",
            "require": "const sanitize_var_name = require('@vbarbarosh/node-helpers/src/sanitize_var_name');",
            "source_code": "const sanitize_dash_name = require('./sanitize_dash_name');\nconst str_camel_to_snake = require('./str_camel_to_snake');\n\nfunction sanitize_var_name(var_name)\n{\n    const out = sanitize_dash_name(str_camel_to_snake(var_name)).replace(/[^a-z0-9]+/g, '_');\n    if (out.length === 0) {\n        return '_';\n    }\n    if (out[0].match(/[0-9]/)) {\n        return '_' + out;\n    }\n    return out;\n}\n\nmodule.exports = sanitize_var_name;\n",
            "markdown": null
        },
        {
            "id": "sftp_get_file_info",
            "name": "sftp_get_file_info",
            "file": "src/sftp_get_file_info.js",
            "require": "const sftp_get_file_info = require('@vbarbarosh/node-helpers/src/sftp_get_file_info');",
            "source_code": "const Promise = require('bluebird');\nconst ignore = require('./ignore');\nconst ssh2 = require('ssh2');\nconst waitcb = require('./waitcb');\n\nasync function sftp_get_file_info(url, {user_friendly_status = ignore})\n{\n    const u = new URL(url);\n    const host = u.host;\n    const port = +u.port || 22;\n    const username = decodeURIComponent(u.username);\n    const password = decodeURIComponent(u.password);\n    const pathname = u.pathname;\n\n    user_friendly_status('Establishing connection...');\n    const conn = new ssh2.Client();\n    try {\n        await new Promise(function (resolve, reject) {\n            conn.once('ready', resolve);\n            conn.once('error', reject);\n            conn.connect({host, port, username, password});\n        });\n\n        user_friendly_status('Asking for an sftp service...');\n        const sftp = await waitcb(cb => conn.sftp(cb));\n\n        user_friendly_status('Requesting file info...');\n        const [stat, lstat, readdir] = await Promise.all([\n            waitcb(cb => sftp.stat(pathname, cb)),\n            waitcb(cb => sftp.lstat(pathname, cb)),\n            waitcb(cb => sftp.readdir(pathname, cb)),\n        ]);\n        return {\n            stat,\n            lstat,\n            readdir,\n        };\n    }\n    finally {\n        conn.end();\n    }\n}\n\nmodule.exports = sftp_get_file_info;\n",
            "markdown": null
        },
        {
            "id": "sftp_get_stream_range",
            "name": "sftp_get_stream_range",
            "file": "src/sftp_get_stream_range.js",
            "require": "const sftp_get_stream_range = require('@vbarbarosh/node-helpers/src/sftp_get_stream_range');",
            "source_code": "const ignore = require('./ignore');\nconst ssh2 = require('ssh2');\nconst waitcb = require('./waitcb');\n\nasync function sftp_get_stream_range(url, first, last, {user_friendly_status = ignore} = {})\n{\n    const u = new URL(url);\n    const host = u.host;\n    const port = +u.port || 22;\n    const username = decodeURIComponent(u.username);\n    const password = decodeURIComponent(u.password);\n    const pathname = u.pathname;\n\n    user_friendly_status('Establishing connection...');\n    const conn = new ssh2.Client();\n    await new Promise(function (resolve, reject) {\n        conn.on('ready', resolve);\n        conn.on('error', reject);\n        conn.connect({host, port, username, password});\n    });\n\n    user_friendly_status('Asking for an sftp service...');\n    const sftp = await waitcb(cb => conn.sftp(cb));\n\n    user_friendly_status('Requesting file info...');\n    const stat = await waitcb(cb => sftp.stat(pathname, cb));\n\n    if (first < 0 || last >= stat.size) {\n        throw new Error(`Invalid range: [first=${first}][last=${last}]`);\n    }\n\n    const out = sftp.createReadStream(pathname, {start: first, end: last})\n    out.content_range = {\n        type: 'bytes',\n        first,\n        last,\n        total: stat.size,\n    };\n    out.total = out.content_range.total;\n    out.once('error', function () {\n        conn.destroy();\n    });\n    out.once('end', function () {\n        conn.destroy();\n    });\n    return out;\n}\n\nmodule.exports = sftp_get_stream_range;\n",
            "markdown": null
        },
        {
            "id": "shell",
            "name": "shell",
            "file": "src/shell.js",
            "require": "const shell = require('@vbarbarosh/node-helpers/src/shell');",
            "source_code": "const child_process = require('child_process');\n\nfunction shell(args, options)\n{\n    return new Promise(function (resolve, reject) {\n        child_process.execFile(args[0], args.slice(1), options, function (error, stdout, stderr) {\n            if (error) {\n                reject(error);\n            }\n            else if (stderr) {\n                reject(new Error(`Process terminated with the following STDERR:\\n\\n${stderr}`));\n            }\n            else {\n                resolve(stdout);\n            }\n        });\n    });\n}\n\nmodule.exports = shell;\n",
            "markdown": null
        },
        {
            "id": "shell_curl_progress",
            "name": "shell_curl_progress",
            "file": "src/shell_curl_progress.js",
            "require": "const shell_curl_progress = require('@vbarbarosh/node-helpers/src/shell_curl_progress');",
            "source_code": "const Promise = require('bluebird');\nconst child_process = require('child_process');\nconst stream = require('stream');\nconst stream_curl_progress = require('./stream_curl_progress');\nconst stream_each = require('./stream_each');\n\n// 🦋 TODO ...options\nasync function shell_curl_progress(args, {options, user_friendly_status})\n{\n    // $ man curl\n    // > If you want a progress meter for HTTP POST or PUT requests,\n    // > you need to redirect the response output to a file, using\n    // > shell redirect (>), -o, --output or similar.\n\n    const tmp = ['--no-silent', '--progress-meter'];\n    if (!args.includes('-o')) {\n        tmp.push('-o', '/dev/null');\n    }\n    const proc = child_process.spawn(args[0], args.slice(1).concat(tmp), {...options, stdio: ['inherit', 'inherit', 'pipe']});\n\n    const promises = [];\n    promises.push(new Promise(function (resolve, reject) {\n        proc.once('error', reject);\n        proc.once('exit', code => code ? reject(new Error(`Process terminated with code ${code}`)) : resolve());\n    }));\n    promises.push(stream.promises.pipeline(proc.stderr, stream_curl_progress(), stream_each(progress_fn)));\n\n    await Promise.all(promises);\n\n    function progress_fn(v) {\n        const speed = v.speed === '0' ? '~' : `${v.speed}/s`;\n        user_friendly_status(`${v.perc}% | ${v.done} of ${v.total} at ${speed} ETA ${v.eta} duration=${v.duration}`);\n    }\n}\n\nmodule.exports = shell_curl_progress;\n",
            "markdown": null
        },
        {
            "id": "shell_json",
            "name": "shell_json",
            "file": "src/shell_json.js",
            "require": "const shell_json = require('@vbarbarosh/node-helpers/src/shell_json');",
            "source_code": "const child_process = require('child_process');\n\nfunction shell_json(args, options)\n{\n    return new Promise(function (resolve, reject) {\n        child_process.execFile(args[0], args.slice(1), options, function (error, stdout, stderr) {\n            if (error) {\n                reject(error);\n            }\n            else if (stderr) {\n                reject(new Error(`Process terminated with the following STDERR:\\n\\n${stderr}`));\n            }\n            else {\n                try {\n                    resolve(JSON.parse(stdout));\n                }\n                catch (error) {\n                    reject(error);\n                }\n            }\n        });\n    });\n}\n\nmodule.exports = shell_json;\n",
            "markdown": null
        },
        {
            "id": "shell_lines",
            "name": "shell_lines",
            "file": "src/shell_lines.js",
            "require": "const shell_lines = require('@vbarbarosh/node-helpers/src/shell_lines');",
            "source_code": "const shell = require('./shell');\n\nasync function shell_lines(args, options)\n{\n    const s = await shell(args, options);\n    return s.trimEnd().split('\\n');\n}\n\nmodule.exports = shell_lines;\n",
            "markdown": null
        },
        {
            "id": "shell_spawn",
            "name": "shell_spawn",
            "file": "src/shell_spawn.js",
            "require": "const shell_spawn = require('@vbarbarosh/node-helpers/src/shell_spawn');",
            "source_code": "const Promise = require('bluebird');\nconst child_process = require('child_process');\n\nfunction shell_spawn(args, options)\n{\n    let init, promise;\n    const out = child_process.spawn(args[0], args.slice(1), options);\n    out.init = function () {\n        return init = init || new Promise(function (resolve, reject) {\n            out.once('error', init_error);\n            out.once('spawn', init_spawn);\n            function init_error(error) {\n                out.off('spawn', init_spawn);\n                reject(error);\n            }\n            function init_spawn() {\n                out.off('error', init_error);\n                resolve(out);\n            }\n        });\n    };\n    out.promise = function () {\n        return promise = promise || new Promise(function (resolve, reject) {\n            out.once('error', promise_error);\n            out.once('exit', promise_exit);\n            function promise_error(error) {\n                out.off('exit', promise_exit);\n                reject(error);\n            }\n            function promise_exit(code, signal) {\n                out.off('error', promise_error);\n                code ? reject(new Error(`Process terminated with code ${code}`)) : resolve(signal);\n            }\n        });\n    };\n    return out;\n}\n\nmodule.exports = shell_spawn;\n",
            "markdown": null
        },
        {
            "id": "shell_stdall",
            "name": "shell_stdall",
            "file": "src/shell_stdall.js",
            "require": "const shell_stdall = require('@vbarbarosh/node-helpers/src/shell_stdall');",
            "source_code": "const child_process = require('child_process');\n\nfunction shell_stdall(args, options)\n{\n    return new Promise(function (resolve, reject) {\n        child_process.execFile(args[0], args.slice(1), options, function (error, stdout, stderr) {\n            error ? reject(error) : resolve({stdout, stderr});\n        });\n    });\n}\n\nmodule.exports = shell_stdall;\n",
            "markdown": null
        },
        {
            "id": "shell_thru",
            "name": "shell_thru",
            "file": "src/shell_thru.js",
            "require": "const shell_thru = require('@vbarbarosh/node-helpers/src/shell_thru');",
            "source_code": "const shell_spawn = require('./shell_spawn');\n\nfunction shell_thru(args, options)\n{\n    return shell_spawn(args, {stdio: 'inherit', ...options});\n}\n\nmodule.exports = shell_thru;\n",
            "markdown": null
        },
        {
            "id": "shell_ytdlp_progress",
            "name": "shell_ytdlp_progress",
            "file": "src/shell_ytdlp_progress.js",
            "require": "const shell_ytdlp_progress = require('@vbarbarosh/node-helpers/src/shell_ytdlp_progress');",
            "source_code": "const child_process = require('child_process');\nconst format_seconds = require('./format_seconds');\nconst stream = require('stream');\nconst stream_each = require('./stream_each');\nconst stream_ytdlp_progress = require('./stream_ytdlp_progress');\n\nasync function shell_ytdlp_progress(args, {user_friendly_status, ...options})\n{\n    const proc = child_process.spawn('yt-dlp', ['--progress', ...args], {...options, stdio: 'pipe'});\n    const time0 = Date.now();\n\n    const promises = [];\n    promises.push(new Promise(function (resolve, reject) {\n        proc.once('error', reject);\n        proc.once('exit', code => code ? reject(new Error(`Process terminated with code ${code}`)) : resolve());\n    }));\n    promises.push(stream.promises.pipeline(proc.stdout, stream_ytdlp_progress(), stream_each(progress_fn)));\n    promises.push(stream.promises.pipeline(proc.stderr, stream_each(v => console.log(`[stderr] ${v}`))));\n\n    await Promise.all(promises);\n\n    function progress_fn(v) {\n        const duration = format_seconds((Date.now() - time0)/1000);\n        if (v.merging) {\n            user_friendly_status(`Merging... duration=${duration}`);\n        }\n        else {\n            user_friendly_status(`${v.perc} | [${v.current_part}/${v.total_parts}] ${v.done} of ${v.total} at ${v.speed} ETA ${v.eta} duration=${duration}`);\n        }\n    }\n}\n\nmodule.exports = shell_ytdlp_progress;\n",
            "markdown": null
        },
        {
            "id": "str_camel_to_snake",
            "name": "str_camel_to_snake",
            "file": "src/str_camel_to_snake.js",
            "require": "const str_camel_to_snake = require('@vbarbarosh/node-helpers/src/str_camel_to_snake');",
            "source_code": "function str_camel_to_snake(s)\n{\n    return s\n        .replace(/([a-z0-9])([A-Z])/g, '$1_$2')  // Insert underscore between lowercase/number and uppercase\n        .replace(/([A-Z]+)([A-Z][a-z])/g, '$1_$2') // Separate acronyms from regular CamelCase words\n        .toLowerCase();\n}\n\nmodule.exports = str_camel_to_snake;\n",
            "markdown": null
        },
        {
            "id": "str_parse_kv",
            "name": "str_parse_kv",
            "file": "src/str_parse_kv.js",
            "require": "const str_parse_kv = require('@vbarbarosh/node-helpers/src/str_parse_kv');",
            "source_code": "function str_parse_kv(str)\n{\n    const i = str.indexOf(':');\n    if (i === -1) {\n        return [str.trim(), ''];\n    }\n    return [str.slice(0, i).trim(), str.slice(i + 1).trim()];\n}\n\nmodule.exports = str_parse_kv;\n",
            "markdown": null
        },
        {
            "id": "stream_chunk",
            "name": "stream_chunk",
            "file": "src/stream_chunk.js",
            "require": "const stream_chunk = require('@vbarbarosh/node-helpers/src/stream_chunk');",
            "source_code": "const stream = require('stream');\n\n/**\n * Split a stream into chunks of objects.\n */\nfunction stream_chunk(chunk_size)\n{\n    const chunk = [];\n    return new stream.Transform({\n        objectMode: true,\n        transform: function (item, encoding, callback) {\n            chunk.push(item);\n            if (chunk.length >= chunk_size) {\n                this.push(chunk.splice(0));\n            }\n            callback();\n        },\n        flush: function (callback) {\n            if (chunk.length) {\n                this.push(chunk.splice(0));\n            }\n            callback();\n        },\n    });\n}\n\nmodule.exports = stream_chunk;\n",
            "markdown": "Split a stream into chunks of objects.\n"
        },
        {
            "id": "stream_curl_progress",
            "name": "stream_curl_progress",
            "file": "src/stream_curl_progress.js",
            "require": "const stream_curl_progress = require('@vbarbarosh/node-helpers/src/stream_curl_progress');",
            "source_code": "const stream = require('stream');\nconst stream_filter = require('./stream_filter');\nconst stream_lines = require('./stream_lines');\nconst stream_map = require('./stream_map');\nconst stream_skip = require('./stream_skip');\n\nfunction stream_curl_progress()\n{\n    return stream.compose(\n        stream_lines(),\n        stream_skip(2),\n        stream_map(function (v) {\n            // curl: (22) The requested URL returned error: 500\n            if (v.startsWith('curl:')) {\n                process.stderr.write(`${v}\\n`);\n                return null;\n            }\n\n            // % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n            //                                Dload  Upload   Total   Spent    Left  Speed\n            // 0 3217M    0     0    0  128k      0   205k  4:27:16 --:--:--  4:27:16  205k\n            // 0 3217M    0     0    0 6016k      0  3751k  0:14:38  0:00:01  0:14:37 3750k\n            // ...\n            // 18 3217M    0     0   18  587M      0  18.5M  0:02:53  0:00:31  0:02:22 19.0M\n            const [perc, total, perc2, recv, perc3, transferred, speed_down, speed_up, time_total, duration, eta, speed] = v.trim().split(/\\s+/);\n            return {\n                perc,\n                done: recv === '0' ? transferred : recv,\n                total,\n                perc2,\n                recv,\n                perc3,\n                transferred,\n                speed_down,\n                speed_up,\n                time_total: time_total === '--:--:--' ? '~' : time_total,\n                duration: duration === '--:--:--' ? '~' : duration,\n                eta: eta === '--:--:--' ? '~' : eta,\n                speed\n            };\n        }),\n        stream_filter(v => v),\n    );\n}\n\nmodule.exports = stream_curl_progress;\n",
            "markdown": null
        },
        {
            "id": "stream_data_ln",
            "name": "stream_data_ln",
            "file": "src/stream_data_ln.js",
            "require": "const stream_data_ln = require('@vbarbarosh/node-helpers/src/stream_data_ln');",
            "source_code": "/**\n * Split stream on each \\n and call `fn` for each line.\n *\n * @param stream\n * @param fn\n * @return function\n */\nfunction stream_data_ln(stream, fn)\n{\n    let utf8 = '';\n    stream.on('data', data);\n    stream.on('end', end);\n    return off;\n\n    function off() {\n        stream.off('data', data);\n        stream.off('end', end);\n    }\n    function end() {\n        off();\n        if (utf8) {\n            fn(utf8, true);\n        }\n    }\n    function data(buffer) {\n        utf8 += buffer.toString('utf8');\n        for (let iteration = 1; true; ++iteration) {\n            if (iteration == 1000000) {\n                throw new Error('Too many iterations');\n            }\n            const i = utf8.indexOf('\\n');\n            if (i == -1) {\n                break;\n            }\n            const line = utf8.substr(0, i);\n            utf8 = utf8.substr(i + 1);\n            fn(line, false);\n        }\n    }\n}\n\nmodule.exports = stream_data_ln;\n",
            "markdown": "Split stream on each `\\n` and call `fn` for each line.\n"
        },
        {
            "id": "stream_discard",
            "name": "stream_discard",
            "file": "src/stream_discard.js",
            "require": "const stream_discard = require('@vbarbarosh/node-helpers/src/stream_discard');",
            "source_code": "const stream = require('stream');\n\nfunction stream_discard({objectMode = false} = {})\n{\n    return new stream.Writable({\n        objectMode,\n        write: function (buffer, encoding, callback) {\n            callback();\n        },\n    });\n}\n\nmodule.exports = stream_discard;\n",
            "markdown": null
        },
        {
            "id": "stream_each",
            "name": "stream_each",
            "file": "src/stream_each.js",
            "require": "const stream_each = require('@vbarbarosh/node-helpers/src/stream_each');",
            "source_code": "const stream = require('stream');\n\n/**\n * Pass each item to a simple function. This is a final step.\n */\nfunction stream_each(fn)\n{\n    return stream.Writable({\n        objectMode: true,\n        write: async function (item, encoding, callback) {\n            try {\n                await fn(item);\n                callback();\n            }\n            catch (error) {\n                callback(error);\n            }\n        }\n    });\n}\n\nmodule.exports = stream_each;\n",
            "markdown": "Pass each item to a simple function. This is a final step.\n"
        },
        {
            "id": "stream_filter",
            "name": "stream_filter",
            "file": "src/stream_filter.js",
            "require": "const stream_filter = require('@vbarbarosh/node-helpers/src/stream_filter');",
            "source_code": "const stream = require('stream');\n\n/**\n * Pass down only those items passed user-defined criteria.\n */\nfunction stream_filter(fn)\n{\n    return new stream.Transform({\n        objectMode: true,\n        transform: async function (item, encoding, callback) {\n            try {\n                if (await fn(item)) {\n                    this.push(item);\n                }\n                callback();\n            }\n            catch (error) {\n                callback(error);\n            }\n        },\n    });\n}\n\nmodule.exports = stream_filter;\n",
            "markdown": "Pass down only those items passed user-defined criteria.\n"
        },
        {
            "id": "stream_group",
            "name": "stream_group",
            "file": "src/stream_group.js",
            "require": "const stream_group = require('@vbarbarosh/node-helpers/src/stream_group');",
            "source_code": "const stream_chunk = require('./stream_chunk');\n\n/**\n * Split a stream into chunks of objects.\n *\n * @deprecated Deprecated in favor of `stream_chunk`\n */\nfunction stream_group(chunk_size)\n{\n    return stream_chunk(chunk_size);\n}\n\nmodule.exports = stream_group;\n",
            "markdown": null
        },
        {
            "id": "stream_gunzip",
            "name": "stream_gunzip",
            "file": "src/stream_gunzip.js",
            "require": "const stream_gunzip = require('@vbarbarosh/node-helpers/src/stream_gunzip');",
            "source_code": "const zlib  = require('zlib');\n\nfunction stream_gunzip(options)\n{\n    return zlib.createGunzip(options);\n}\n\nmodule.exports = stream_gunzip;\n",
            "markdown": null
        },
        {
            "id": "stream_hash",
            "name": "stream_hash",
            "file": "src/stream_hash.js",
            "require": "const stream_hash = require('@vbarbarosh/node-helpers/src/stream_hash');",
            "source_code": "const crypto = require('crypto');\nconst stream = require('stream');\n\nfunction stream_hash(algorithm = 'md5', options)\n{\n    const hash = crypto.createHash(algorithm, options);\n    return new stream.Transform({\n        transform: function (chunk, encoding, callback) {\n            hash.update(chunk);\n            callback();\n        },\n        flush: function (callback) {\n            this.push(hash.digest('hex'));\n            callback();\n        },\n    });\n}\n\nmodule.exports = stream_hash;\n",
            "markdown": null
        },
        {
            "id": "stream_lines",
            "name": "stream_lines",
            "file": "src/stream_lines.js",
            "require": "const stream_lines = require('@vbarbarosh/node-helpers/src/stream_lines');",
            "source_code": "const stream_strpbrk = require('./stream_strpbrk');\n\n/**\n * Split stream into lines\n */\nfunction stream_lines()\n{\n    return stream_strpbrk('\\r\\n');\n}\n\nmodule.exports = stream_lines;\n",
            "markdown": "Split stream into lines.\n"
        },
        {
            "id": "stream_map",
            "name": "stream_map",
            "file": "src/stream_map.js",
            "require": "const stream_map = require('@vbarbarosh/node-helpers/src/stream_map');",
            "source_code": "const stream = require('stream');\n\n/**\n * Transform each item using a simple function.\n */\nfunction stream_map(fn)\n{\n    return new stream.Transform({\n        objectMode: true,\n        transform: async function (item, encoding, callback) {\n            try {\n                this.push(await fn(item));\n                callback();\n            }\n            catch (error) {\n                callback(error);\n            }\n        },\n    });\n}\n\nmodule.exports = stream_map;\n",
            "markdown": "Transform each item using a simple function.\n"
        },
        {
            "id": "stream_map_flatten",
            "name": "stream_map_flatten",
            "file": "src/stream_map_flatten.js",
            "require": "const stream_map_flatten = require('@vbarbarosh/node-helpers/src/stream_map_flatten');",
            "source_code": "const stream = require('stream');\n\n/**\n * Pass each item through a user-defined generator, passes down each yielded item.\n */\nfunction stream_map_flatten(fn)\n{\n    return new stream.Transform({\n        objectMode: true,\n        transform: async function (item, encoding, callback) {\n            try {\n                for await (const chunk of fn(item)) {\n                    this.push(chunk);\n                }\n                callback();\n            }\n            catch (error) {\n                callback(error);\n            }\n        },\n    });\n}\n\nmodule.exports = stream_map_flatten;\n",
            "markdown": "Pass each item through a user-defined generator, passes down each yielded item.\n"
        },
        {
            "id": "stream_map_parallel",
            "name": "stream_map_parallel",
            "file": "src/stream_map_parallel.js",
            "require": "const stream_map_parallel = require('@vbarbarosh/node-helpers/src/stream_map_parallel');",
            "source_code": "const Promise = require('bluebird');\nconst stream = require('stream');\n\n/**\n * Transform each item using a simple function in parallel.\n */\nfunction stream_map_parallel({handler, concurrency})\n{\n    let running = 0;\n    let callback_next = null;\n    let callback_flush = null;\n    const buf = [];\n    const buf_limit = 5*concurrency;\n    const out = new stream.Transform({\n        objectMode: true,\n        transform: async function (item, encoding, callback) {\n            try {\n                running++;\n                const promise = Promise.method(handler).call(null, item);\n                promise.then(ready).catch(fail);\n                buf.push(promise);\n                if (running < concurrency && buf.length < buf_limit) {\n                    callback(); // Ready to consume the next item\n                }\n                else if (callback_next) {\n                    throw new Error('Already pending');\n                }\n                else {\n                    callback_next = callback;\n                }\n            }\n            catch (error) {\n                callback(error);\n            }\n        },\n        flush: function (callback) {\n            if (buf.length === 0) {\n                callback();\n            }\n            else {\n                callback_flush = callback;\n            }\n        },\n    });\n    return out;\n    function ready() {\n        running--;\n        while (buf.length && buf[0].isFulfilled()) {\n            out.push(buf.shift().value());\n        }\n        if (callback_next && buf.length < buf_limit) {\n            const tmp = callback_next;\n            callback_next = null;\n            tmp();\n        }\n        if (callback_flush && !running) {\n            callback_flush();\n        }\n    }\n    function fail(error) {\n        out.destroy(error);\n    }\n}\n\nmodule.exports = stream_map_parallel;\n",
            "markdown": "Transform each item using a simple function in parallel.\n"
        },
        {
            "id": "stream_md5",
            "name": "stream_md5",
            "file": "src/stream_md5.js",
            "require": "const stream_md5 = require('@vbarbarosh/node-helpers/src/stream_md5');",
            "source_code": "const crypto = require('crypto');\nconst stream = require('stream');\n\n/**\n * TODO Rename to stream_hash_md5\n */\nfunction stream_md5()\n{\n    const md5 = crypto.createHash('md5');\n    return new stream.Transform({\n        transform: function (chunk, encoding, callback) {\n            md5.update(chunk, encoding);\n            callback();\n        },\n        flush: function (callback) {\n            this.push(md5.digest('hex'));\n            callback();\n        },\n    });\n}\n\nmodule.exports = stream_md5;\n",
            "markdown": null
        },
        {
            "id": "stream_multiplex",
            "name": "stream_multiplex",
            "file": "src/stream_multiplex.js",
            "require": "const stream_multiplex = require('@vbarbarosh/node-helpers/src/stream_multiplex');",
            "source_code": "const ignore = require('./ignore');\nconst stream = require('stream');\n\nfunction stream_multiplex(...streams)\n{\n    if (streams.length === 1) {\n        return streams[0];\n    }\n\n    // `new stream.Writable()` will ignore second, third, etc. calls to `destroy`\n    return stream.Writable({\n        objectMode: true,\n        construct: function (callback) {\n            streams.forEach(s => s.once('error', e => this.destroy(e)));\n            callback();\n        },\n        destroy: async function (error, callback) {\n            let done = 0;\n            streams.forEach(function (stream) {\n                stream.destroy(error, function () {\n                    if (++done === streams.length) {\n                        callback();\n                    }\n                });\n            });\n        },\n        write: async function (chunk, encoding, callback) {\n            let done = 0;\n            streams.forEach(function (stream) {\n                stream.write(chunk, encoding, function (error) {\n                    if (++done === streams.length || error) {\n                        callback(error);\n                        callback = ignore;\n                    }\n                });\n            });\n        },\n        final: async function (callback) {\n            let done = 0;\n            streams.forEach(function (stream) {\n                stream.end(function (error) {\n                    if (++done === streams.length || error) {\n                        callback(error);\n                        callback = ignore;\n                    }\n                });\n            });\n        },\n    });\n}\n\nmodule.exports = stream_multiplex;\n",
            "markdown": null
        },
        {
            "id": "stream_parse_csv",
            "name": "stream_parse_csv",
            "file": "src/stream_parse_csv.js",
            "require": "const stream_parse_csv = require('@vbarbarosh/node-helpers/src/stream_parse_csv');",
            "source_code": "const csv_parse = require('csv-parse');\n\n/**\n * Parse input stream as CSV data.\n *\n * @link https://csv.js.org/parse/options/\n */\nfunction stream_parse_csv({delimiter = ',', relax_column_count = false} = {})\n{\n    return csv_parse.parse({delimiter, relax_column_count, });\n}\n\nmodule.exports = stream_parse_csv;\n",
            "markdown": "Parse input stream as CSV data.\n\n- https://csv.js.org/parse/options/\n"
        },
        {
            "id": "stream_progress",
            "name": "stream_progress",
            "file": "src/stream_progress.js",
            "require": "const stream_progress = require('@vbarbarosh/node-helpers/src/stream_progress');",
            "source_code": "const format_progress_bytes = require('./format_progress_bytes');\nconst format_progress_kilo = require('./format_progress_kilo');\nconst make_progress = require('./make_progress');\nconst stream = require('stream');\n\n/**\n * Monitor the progress of data through a pipe, similar to the UNIX `pv` command.\n *\n * Requirements:\n * - should emit the first message as fast as possible\n * - should always emit 100% message\n *\n * @similar https://www.npmjs.com/package/progress-stream\n */\nfunction stream_progress({objectMode = false, interval = 1000, total, user_friendly_status = s => console.log(s)} = {})\n{\n    let done = 0;\n    const timer = setInterval(tick, interval);\n    const progress = make_progress(total);\n    const format_progress = objectMode ? format_progress_kilo : format_progress_bytes;\n    setTimeout(tick, 0);\n    return new stream.Transform({\n        objectMode,\n        destroy: function (error, callback) {\n            tick();\n            clearInterval(timer);\n            callback();\n        },\n        transform: function (buffer, encoding, callback) {\n            if (objectMode) {\n                done++;\n                this.push(buffer);\n            }\n            else {\n                done += buffer.length;\n                this.push(buffer, encoding);\n            }\n            callback();\n        },\n    });\n    function tick() {\n        progress.update(done);\n        user_friendly_status(format_progress(progress));\n    }\n}\n\nmodule.exports = stream_progress;\n",
            "markdown": "Monitor the progress of data through a pipe, similar to the UNIX `pv` command.\n\nRequirements:\n\n- should emit the first message as fast as possible\n- should always emit 100% message\n\n- Similar: https://www.npmjs.com/package/progress-stream\n"
        },
        {
            "id": "stream_skip",
            "name": "stream_skip",
            "file": "src/stream_skip.js",
            "require": "const stream_skip = require('@vbarbarosh/node-helpers/src/stream_skip');",
            "source_code": "const stream = require('stream');\n\n/**\n * Skip first `n` records.\n */\nfunction stream_skip(n)\n{\n    let current = 0;\n    return new stream.Transform({\n        objectMode: true,\n        transform: function (item, encoding, callback) {\n            try {\n                if (current++ >= n) {\n                    this.push(item);\n                }\n                callback();\n            }\n            catch (error) {\n                callback(error);\n            }\n        },\n    });\n}\n\nmodule.exports = stream_skip;\n",
            "markdown": "Skip first `n` records.\n"
        },
        {
            "id": "stream_strpbrk",
            "name": "stream_strpbrk",
            "file": "src/stream_strpbrk.js",
            "require": "const stream_strpbrk = require('@vbarbarosh/node-helpers/src/stream_strpbrk');",
            "source_code": "const stream = require('stream');\n\n/**\n * Split the input stream by consecutive delimiters in `chars`\n */\nfunction stream_strpbrk(chars = '\\r\\n')\n{\n    const pending = [];\n    return new stream.Transform({\n        objectMode: true,\n        transform: function (str, encoding, callback) {\n            str = Buffer.isBuffer(str) ? str.toString() : str;\n\n            let off = 0;\n            // leading delimiters\n            while (off < str.length) {\n                if (!chars.includes(str[off])) {\n                    break;\n                }\n                off++;\n            }\n\n            if (off && pending.length) {\n                this.push(''.concat(...pending.splice(0)));\n            }\n\n            while (off < str.length) {\n                // skip consecutive delimiters\n                while (off < str.length) {\n                    let stop = true;\n                    for (let i = 0, end = chars.length; i < end; ++i) {\n                        if (str[off] === chars[i]) {\n                            off++;\n                            stop = false;\n                            break;\n                        }\n                    }\n                    if (stop) {\n                        break;\n                    }\n                }\n\n                // find next delimiter\n                const delims = [];\n                for (let i = 0, end = chars.length; i < end; ++i) {\n                    const j = str.indexOf(chars[i], off);\n                    if (j !== -1) {\n                        delims.push(j);\n                    }\n                }\n\n                // no delimiters were found\n                if (!delims.length) {\n                    const tmp = str.slice(off);\n                    if (tmp.length) {\n                        pending.push(tmp);\n                    }\n                    callback();\n                    return;\n                }\n\n                delims.sort(fcmp);\n                pending.push(str.slice(off, delims[0]));\n                this.push(''.concat(...pending.splice(0)));\n                off = delims[0];\n            }\n            callback();\n        },\n        flush: function (callback) {\n            if (pending.length) {\n                this.push(''.concat(...pending.splice(0)));\n            }\n            callback();\n        },\n    });\n}\n\nfunction fcmp(a, b)\n{\n    return a - b;\n}\n\nmodule.exports = stream_strpbrk;\n",
            "markdown": "Split the input stream by consecutive delimiters in `chars`.\n"
        },
        {
            "id": "stream_tap",
            "name": "stream_tap",
            "file": "src/stream_tap.js",
            "require": "const stream_tap = require('@vbarbarosh/node-helpers/src/stream_tap');",
            "source_code": "const stream = require('stream');\n\n/**\n * Call `fn` on each item.\n */\nfunction stream_tap(fn)\n{\n    return new stream.Transform({\n        objectMode: true,\n        transform: async function (item, encoding, callback) {\n            try {\n                await fn(item);\n                this.push(item, encoding);\n                callback();\n            }\n            catch (error) {\n                callback(error);\n            }\n        },\n    });\n}\n\nmodule.exports = stream_tap;\n",
            "markdown": "Call `fn` on each item.\n"
        },
        {
            "id": "stream_through",
            "name": "stream_through",
            "file": "src/stream_through.js",
            "require": "const stream_through = require('@vbarbarosh/node-helpers/src/stream_through');",
            "source_code": "const stream_tap = require('./stream_tap');\n\n/**\n * Call `fn` on each item.\n *\n * @deprecated Deprecated in favor of `stream_tap`.\n */\nfunction stream_through(fn)\n{\n    return stream_tap(fn);\n}\n\nmodule.exports = stream_through;\n",
            "markdown": null
        },
        {
            "id": "stream_transform",
            "name": "stream_transform",
            "file": "src/stream_transform.js",
            "require": "const stream_transform = require('@vbarbarosh/node-helpers/src/stream_transform');",
            "source_code": "const stream_map = require('./stream_map');\n\n/**\n * @deprecated Deprecated in favor of `stream_map`\n */\nfunction stream_transform(fn)\n{\n    return stream_map(fn);\n}\n\nmodule.exports = stream_transform;\n",
            "markdown": null
        },
        {
            "id": "stream_xml_analyze",
            "name": "stream_xml_analyze",
            "file": "src/stream_xml_analyze.js",
            "require": "const stream_xml_analyze = require('@vbarbarosh/node-helpers/src/stream_xml_analyze');",
            "source_code": "const htmlparser2 = require('htmlparser2');\nconst stream = require('stream');\n\n/**\n * Consume XML, produce an object with analytics about provided xml stream.\n */\nfunction stream_xml_analyze()\n{\n    let out;\n    const path = [];\n    let path_str = '';\n    let analytics = {};\n\n    const options = {xmlMode: true};\n    const events = {\n        onopentag: function (name, attrs) {\n            path.push(name);\n            path_str = path.join(' > ');\n            analytics[path_str] ??= 0;\n            analytics[path_str]++;\n        },\n        onclosetag: function (name) {\n            path.pop();\n        },\n        ontext: function (text) {\n        },\n        onend: function () {\n            out.push(analytics);\n        },\n    };\n\n    const parser = new htmlparser2.Parser(events, options);\n    return out = new stream.Transform({\n        objectMode: true,\n        transform: function (buf, encoding, callback) {\n            parser.write(buf.toString());\n            callback();\n        },\n        flush: function (callback) {\n            parser.end();\n            callback();\n        },\n    });\n}\n\nmodule.exports = stream_xml_analyze;\n",
            "markdown": "Consume XML, produce an object with analytics about provided xml stream.\n"
        },
        {
            "id": "stream_xml_parse",
            "name": "stream_xml_parse",
            "file": "src/stream_xml_parse.js",
            "require": "const stream_xml_parse = require('@vbarbarosh/node-helpers/src/stream_xml_parse');",
            "source_code": "const assert = require('assert');\nconst const_stream = require('./const_stream');\nconst htmlparser2 = require('htmlparser2');\nconst stream = require('stream');\n\n/**\n * Consume XML, produce objects.\n */\nfunction stream_xml_parse(selector, mapper = stream_xml_parse.guess)\n{\n    let out;\n    let elem = {name: '#doc', parent: null, attrs: {}, text: [], children: [], raw: []};\n\n    const path = [];\n    const selector_str = selector.join('>');\n    let path_str = '';\n\n    const options = {xmlMode: true};\n    const events = {\n        onopentag: function (name, attrs) {\n            elem = {name, parent: elem, attrs, text: [], children: [], raw: []};\n            elem.parent.raw.push(elem);\n            elem.parent.children.push(elem);\n            path.push(elem.name);\n            path_str = path.join('>');\n        },\n        onclosetag: function (name) {\n            if (path_str === selector_str) {\n                const tmp = mapper(elem);\n                out.push((tmp === null ? const_stream.null : tmp));\n                elem.parent.raw.pop();\n                assert.strictEqual(elem.parent.children.pop(), elem);\n            }\n            elem = elem.parent;\n            path.pop();\n            path_str = path.join('>');\n        },\n        ontext: function (text) {\n            elem.raw.push(text);\n            elem.text.push(text);\n        },\n        onend: function () {\n            if (selector_str === '') {\n                const tmp = mapper(elem);\n                out.push((tmp === null ? const_stream.null : tmp));\n            }\n        },\n    };\n\n    const parser = new htmlparser2.Parser(events, options);\n    return out = new stream.Transform({\n        objectMode: true,\n        transform: function (buf, encoding, callback) {\n            parser.write(buf.toString());\n            callback();\n        },\n        flush: function (callback) {\n            parser.end();\n            callback();\n        },\n    });\n}\n\nfunction guess(node)\n{\n    const attrs = Object.keys(node.attrs);\n\n    if (attrs.length === 0) {\n        if (node.raw.length === 0) {\n            return null;\n        }\n        if (node.children.length === 0) {\n            return node.text.join('').trim();\n        }\n        if (node.children.length > 1) {\n            const tmp = node.children[0].name;\n            if (node.children.every(v => v.name === tmp)) {\n                return node.children.map(v => stream_xml_parse.guess(v));\n            }\n        }\n    }\n\n    const out = {...node.attrs};\n\n    if (node.text.length) {\n        const tmp = node.text.join('').trim();\n        if (tmp) {\n            out.value = tmp;\n        }\n    }\n\n    node.children.forEach(function (child) {\n        const tmp = stream_xml_parse.guess(child);\n        if (child.name in out) {\n            if (Array.isArray(out[child.name])) {\n                out[child.name].push(tmp);\n            }\n            else {\n                out[child.name] = [out[child.name], tmp];\n            }\n        }\n        else  {\n            out[child.name] = tmp;\n        }\n    });\n\n    return out;\n}\n\nfunction ashtml(node)\n{\n    return node.raw.map(fn).filter(v => v).join('').trim();\n    function fn(item) {\n        if (typeof item === 'string') {\n            return item.replace(/\\s+/g, ' ');\n        }\n        return `<${item.name}>${ashtml(item)}</${item.name}>` ;\n    }\n}\n\nstream_xml_parse.guess = guess;\nstream_xml_parse.ashtml = ashtml;\n\nmodule.exports = stream_xml_parse;\n",
            "markdown": "Consume XML, produce objects.\n"
        },
        {
            "id": "stream_ytdlp_progress",
            "name": "stream_ytdlp_progress",
            "file": "src/stream_ytdlp_progress.js",
            "require": "const stream_ytdlp_progress = require('@vbarbarosh/node-helpers/src/stream_ytdlp_progress');",
            "source_code": "const format_bytes = require('./format_bytes');\nconst format_percents = require('./format_percents');\nconst parse_bytes = require('./parse_bytes');\nconst stream = require('stream');\nconst stream_filter = require('./stream_filter');\nconst stream_lines = require('./stream_lines');\nconst stream_map = require('./stream_map');\n\n// [download]   0.0% of   15.71MiB at  Unknown B/s ETA Unknown\n// [download]   0.0% of   15.71MiB at  Unknown B/s ETA Unknown\n// [download]   0.0% of   15.71MiB at  Unknown B/s ETA Unknown\n// [download]   0.1% of   15.71MiB at  Unknown B/s ETA Unknown\n// [download]   0.2% of   15.71MiB at   21.76MiB/s ETA 00:00\n// [download]   0.4% of   15.71MiB at   16.48MiB/s ETA 00:00\n// [download]   0.8% of   15.71MiB at   25.54MiB/s ETA 00:00\n// [download]   1.6% of   15.71MiB at   30.65MiB/s ETA 00:00\n// [download]   3.2% of   15.71MiB at   42.99MiB/s ETA 00:00\n// [download]   6.4% of   15.71MiB at   66.25MiB/s ETA 00:00\n// [download]  12.7% of   15.71MiB at   81.24MiB/s ETA 00:00\n// [download]  25.5% of   15.71MiB at   55.11MiB/s ETA 00:00\n// [download]  50.9% of   15.71MiB at   33.83MiB/s ETA 00:00\n// [download]  61.7% of   15.71MiB at   33.98MiB/s ETA 00:00\n// [download]  61.7% of   15.71MiB at  Unknown B/s ETA Unknown\n// [download]  61.7% of   15.71MiB at  Unknown B/s ETA Unknown\n// [download]  61.7% of   15.71MiB at  Unknown B/s ETA Unknown\n// [download]  61.8% of   15.71MiB at  Unknown B/s ETA Unknown\n// [download]  61.9% of   15.71MiB at   12.32MiB/s ETA 00:00\n// [download]  62.1% of   15.71MiB at   14.26MiB/s ETA 00:00\n// [download]  62.5% of   15.71MiB at   25.10MiB/s ETA 00:00\n// [download]  63.3% of   15.71MiB at   34.18MiB/s ETA 00:00\n// [download]  64.9% of   15.71MiB at    8.95MiB/s ETA 00:00\n// [download]  68.1% of   15.71MiB at   16.75MiB/s ETA 00:00\n// [download]  74.4% of   15.71MiB at   29.10MiB/s ETA 00:00\n// [download]  87.2% of   15.71MiB at   40.45MiB/s ETA 00:00\n// [download] 100.0% of   15.71MiB at   47.64MiB/s ETA 00:00\n// [download] 100% of   15.71MiB in 00:00:00 at 29.07MiB/s\n// [Merger] Merging formats into \"xxxxxxxxxxxxxxx.webm\"\n// Deleting original file xxxxxxxxxxxxxxx.f251.webm (pass -k to keep)\n// Deleting original file xxxxxxxxxxxxxxx.f248.webm (pass -k to keep)\n\nfunction stream_ytdlp_progress()\n{\n    let last = {};\n    let current_part = 1;\n    const downloading_formats = [];\n    return stream.compose(\n        stream_lines(),\n        stream_map(function (line) {\n            let m;\n            if (m = line.match(/^\\[info] \\S+: Downloading \\d+ format\\(s\\): (.+)$/)) {\n                downloading_formats.push(...m[1].split('+'));\n                return false;\n            }\n            if (m = line.match(/^\\[download] Destination: .*f(\\d+)\\.[^.]+/)) {\n                current_part = downloading_formats.indexOf(m[1]) + 1;\n                return false;\n            }\n            if (m = line.match(/^\\[Merger]/i)) {\n                last.merging = true;\n                return last;\n            }\n            if (m = line.match(/^\\[download] (.*) of (.*) at (.*) ETA (.*)$/)) {\n                const percentage = parseFloat(m[1].trim())/100;\n                const total = parse_bytes(m[2].trim());\n                const speed = m[3].trim().replace('i', '');\n                const eta = m[4].trim();\n                return last = {\n                    current_part,\n                    total_parts: downloading_formats.length,\n                    perc: format_percents(percentage),\n                    done: format_bytes(percentage*total),\n                    total: format_bytes(total),\n                    speed: speed.toLowerCase().includes('unknown') ? '~' : speed,\n                    eta: eta.toLowerCase().includes('unknown') ? '~' : eta,\n                    merging: false,\n                };\n            }\n            return false;\n        }),\n        stream_filter(v => v),\n    );\n}\n\nmodule.exports = stream_ytdlp_progress;\n",
            "markdown": null
        },
        {
            "id": "throttle",
            "name": "throttle",
            "file": "src/throttle.js",
            "require": "const throttle = require('@vbarbarosh/node-helpers/src/throttle');",
            "source_code": "/**\n * Ensure that only one event was fired for each ms.\n *\n * @link https://stackoverflow.com/questions/25991367/difference-between-throttling-and-debouncing-a-function\n */\nfunction throttle(ms, fn)\n{\n    let timer = null;\n    let last_value = undefined;\n    run.fire = fire;\n    return run;\n    function run(value) {\n        last_value = value;\n        if (timer === null) {\n            timer = setTimeout(fire, ms)\n        }\n    }\n    function fire() {\n        if (timer === null) {\n            return;\n        }\n        clearTimeout(timer);\n        timer = null;\n        const tmp = last_value;\n        last_value = undefined;\n        return fn(tmp);\n    }\n}\n\nmodule.exports = throttle;\n",
            "markdown": "Ensure that only one event was fired for each ms.\n\n- https://stackoverflow.com/questions/25991367/difference-between-throttling-and-debouncing-a-function\n"
        },
        {
            "id": "urlclean",
            "name": "urlclean",
            "file": "src/urlclean.js",
            "require": "const urlclean = require('@vbarbarosh/node-helpers/src/urlclean');",
            "source_code": "const querystring = require('querystring');\n\n/**\n * Replace unnecessary encodes symbols with chars. The returned url will be\n * more human-friendly, at the same time it will still be valid url.\n */\nfunction urlclean(url)\n{\n    const i = url.indexOf('?') + 1;\n    if (i) {\n        const s = querystring.stringify(querystring.parse(url.slice(i)), '&', '=', {\n            encodeURIComponent: function (v) {\n                return encodeURIComponent(v).replaceAll('%3A', ':').replaceAll('%2F', '/');\n            },\n        });\n        return url.slice(0, i) + s;\n    }\n    return url;\n}\n\nmodule.exports = urlclean;\n",
            "markdown": "Replace unnecessary encodes symbols with chars. The returned url will be\nmore human-friendly, at the same time it will still be valid url.\n"
        },
        {
            "id": "urlmod",
            "name": "urlmod",
            "file": "src/urlmod.js",
            "require": "const urlmod = require('@vbarbarosh/node-helpers/src/urlmod');",
            "source_code": "/**\n * Set, change, or remove query string parameters.\n *\n * urlmod('', {a: 1})           '?a=1'  set\n * urlmod('?a=1', {a: 2})       '?a=2'  change\n * urlmod('?a=1', {a: null})    ''      remove\n */\nfunction urlmod(url, params)\n{\n    const tmp_url = new URL(url||'', 'xxx://___base___/');\n    const tmp_search = tmp_url.searchParams;\n    Object.entries(params || {}).forEach(function ([key, value]) {\n        switch (value) {\n        case null:\n        case undefined:\n            tmp_search.delete(key);\n            break;\n        case true:\n            tmp_search.set(key, 1);\n            break;\n        case false:\n            tmp_search.set(key, 0);\n            break;\n        default:\n            tmp_search.set(key, value);\n            break;\n        }\n    });\n    if (url && url[0] === '/') {\n        return tmp_url.toString().replace(/^xxx:\\/\\/___base___/, '');\n    }\n    return tmp_url.toString().replace(/^xxx:\\/\\/___base___\\//, '');\n}\n\nmodule.exports = urlmod;\n",
            "markdown": "Set, change, or remove query string parameters.\n\n```js\nurlmod('', {a: 1})          // '?a=1'  set\nurlmod('?a=1', {a: 2})      // '?a=2'  change\nurlmod('?a=1', {a: null})   // ''      remove\n```\n"
        },
        {
            "id": "user_friendly_status",
            "name": "user_friendly_status",
            "file": "src/user_friendly_status.js",
            "require": "const user_friendly_status = require('@vbarbarosh/node-helpers/src/user_friendly_status');",
            "source_code": "/**\n * Concept. Represents a way to display a status of a currently running task to the end-user.\n *\n * @see countdown\n * @see progress\n */\nfunction user_friendly_status(s)\n{\n    console.log(s);\n}\n\nmodule.exports = user_friendly_status;\n",
            "markdown": "Concept. Represents a way to display a status of a currently running task to the end-user.\n\n@see countdown\n@see progress\n"
        },
        {
            "id": "wait_while",
            "name": "wait_while",
            "file": "src/wait_while.js",
            "require": "const wait_while = require('@vbarbarosh/node-helpers/src/wait_while');",
            "source_code": "const Promise = require('bluebird');\n\n/**\n * Wait until `fn` returns `true`.\n *\n * W A R N I N G\n * This method was designed mainly for prototyping (where code cleanliness is important).\n * It might drastically decrease performance.\n */\nfunction wait_while(fn)\n{\n    return new Promise(function (resolve, reject) {\n        setTimeout(tick, 1);\n        async function tick() {\n            try {\n                if (await fn()) {\n                    setTimeout(tick, 1);\n                }\n                else {\n                    resolve();\n                }\n            }\n            catch (error) {\n                reject(error);\n            }\n        }\n    });\n}\n\nmodule.exports = wait_while;\n",
            "markdown": "Wait until `fn` returns `true`.\n\nW A R N I N G\nThis method was designed mainly for prototyping (where code cleanliness is important).\nIt might drastically decrease performance.\n"
        },
        {
            "id": "waitcb",
            "name": "waitcb",
            "file": "src/waitcb.js",
            "require": "const waitcb = require('@vbarbarosh/node-helpers/src/waitcb');",
            "source_code": "const Promise = require('bluebird');\n\n/**\n * Wait for a Node-like function to finish (which will call `callback`\n * with 2 arguments: `error` and `value`).\n *\n * await waitcb(cb => fs.writeFile('a', 'hello\\n', cb));\n */\nfunction waitcb(fn)\n{\n    return new Promise(function (resolve, reject) {\n        fn(function (error, out) {\n            error ? reject(error) : resolve(out);\n        });\n    });\n}\n\nmodule.exports = waitcb;\n",
            "markdown": "Wait for a Node-like function to finish (which will call `callback`\nwith 2 arguments: `error` and `value`).\n\n```js\nawait waitcb(cb => fs.writeFile('a', 'hello\\n', cb));\n```\n\nThe same as:\n\n```js\nconst [promise, resolve, reject] = (a => [new Promise((...v) => a = v), ...a])();\n```\n"
        }
    ]
}